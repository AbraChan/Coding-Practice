{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><font color=maroon size=6><b>Introduction to TorchScript</b></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>References:</b></font>\n",
    "1. Pytorch official tutorials: <a href=\"https://pytorch.org/tutorials/index.html\" style=\"text-decoration:none;\">WELCOME TO PYTORCH TUTORIALS</a>\n",
    "    * `Tutorials > `<a href=\"https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html\" style=\"text-decoration:none;\">Introduction to TorchScript</a>\n",
    "    * \n",
    "    * Docs > <a href=\"https://pytorch.org/docs/stable/jit.html\" style=\"text-decoration:none;\">TorchScript</a>\n",
    "    * Docs > <a href=\"https://pytorch.org/cppdocs/\" style=\"text-decoration:none;\">PyTorch C++ API</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>James Reed (jamesreed@fb.com), Michael Suo (suo@fb.com), rev2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is an introduction to <u><font size=3 color=blue><b>TorchScript</b></font>, an intermediate representation of a PyTorch model (subclass of `nn.Module`) that can then be run in a high-performance environment such as C++.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The basics of model authoring in PyTorch, including:\n",
    "    * Modules\n",
    "\n",
    "    * Defining `forward` functions\n",
    "\n",
    "    * Composing modules into a hierarchy of modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Specific methods for converting PyTorch modules to TorchScript, our high-performance deployment runtime\n",
    "    * Tracing an existing module\n",
    "    * Using scripting to directly compile a module\n",
    "    * How to compose both approaches\n",
    "    * Saving and loading TorchScript modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"\" style=\"text-decoration:none;\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope that after you complete this tutorial, you will proceed to go through <a href=\"https://pytorch.org/tutorials/advanced/cpp_export.html\" style=\"text-decoration:none;\">the follow-on tutorial</a> which will walk you through an example of actually calling a TorchScript model from C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all you need to use both PyTorch and TorchScript!\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of PyTorch Model Authoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start out be defining a simple Module. A Module is the basic unit of composition in PyTorch. It contains:\n",
    "\n",
    "* A constructor, which prepares the module for invocation\n",
    "* A set of `Parameters` and sub-`Modules`. These are initialized by the constructor and can be used by the module during invocation.\n",
    "* A `forward` function. <font color=maroon>This is the code that is run when the module is invoked.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s examine a small example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "       \n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(x + h)\n",
    "        \n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7989, 0.6132, 0.6792, 0.5400],\n",
       "         [0.8511, 0.9035, 0.8611, 0.6989],\n",
       "         [0.8547, 0.6441, 0.6022, 0.8200]]),\n",
       " tensor([[0.7989, 0.6132, 0.6792, 0.5400],\n",
       "         [0.8511, 0.9035, 0.8611, 0.6989],\n",
       "         [0.8547, 0.6441, 0.6022, 0.8200]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "\n",
    "mycell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we’ve:\n",
    "\n",
    "* Created a class that subclasses `torch.nn.Module`.\n",
    "* Defined a constructor. The constructor doesn’t do much, just calls the constructor for `super`.\n",
    "* Defined a `forward` function, which takes two inputs and returns two outputs. The actual contents of the `forward` function are not really important, but it’s sort of a fake <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" style=\"text-decoration:none;\">RNN cell</a>–that is–it’s a function that is applied on a loop.\n",
    "\n",
    "\n",
    "We instantiated the module, and made `x` and `h`, which are just `3x4` matrices of random values. Then we invoked the cell with `my_cell(x, h)`. This in turn calls our `forward` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s do something a little more interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        \n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1444, -0.0906,  0.6671,  0.6956],\n",
       "         [ 0.2240,  0.3039,  0.7659,  0.8195],\n",
       "         [ 0.0999, -0.4597,  0.5132,  0.9275]], grad_fn=<TanhBackward0>),\n",
       " tensor([[ 0.1444, -0.0906,  0.6671,  0.6956],\n",
       "         [ 0.2240,  0.3039,  0.7659,  0.8195],\n",
       "         [ 0.0999, -0.4597,  0.5132,  0.9275]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "\n",
    "my_cell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... ... \n",
    "\n",
    "What exactly is happening here? `torch.nn.Linear` is a `Module` from the PyTorch standard library. Just like `MyCell`, it can be invoked using the call syntax. <font color=maroon>We are building a hierarchy of `Modules`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=maroon>`print` on a `Module` will give a visual representation of the Module’s subclass hierarchy. In our example, we can see our `Linear` subclass and its parameters.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By composing `Modules` in this way, we can succintly and readably <font color=maroon>author models with reusable components.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed `grad_fn` on the outputs. <font color=maroon>This is a detail of PyTorch’s method of automatic differentiation, called <a href=\"\" style=\"text-decoration:none;\"><font size=3><b>autograd</b></font></a>. In short, this system allows us to compute derivatives through potentially complex programs. The design allows for a massive amount of flexibility in model authoring.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s examine said flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (dg): MyDecisionGate()\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2316, 0.3318, 0.6326, 0.1353],\n",
       "         [0.7614, 0.7721, 0.7870, 0.2646],\n",
       "         [0.4776, 0.0963, 0.4394, 0.6265]], grad_fn=<TanhBackward0>),\n",
       " tensor([[0.2316, 0.3318, 0.6326, 0.1353],\n",
       "         [0.7614, 0.7721, 0.7870, 0.2646],\n",
       "         [0.4776, 0.0963, 0.4394, 0.6265]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "\n",
    "my_cell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve once again redefined our MyCell class, but here we’ve defined MyDecisionGate. This module utilizes **control flow**. Control flow consists of things like loops and if-statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Many frameworks take the approach of `computing symbolic derivatives` given a full program representation. However, in PyTorch, we use a `gradient tape`. <font color=maroon>We record operations as they occur, and replay them backwards in computing derivatives. In this way, the framework does not have to explicitly define derivatives for all constructs in the language.</font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/How autograd works.png\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><font size=2>How autograd works</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s take our running example and see how we can apply TorchScript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, TorchScript provides tools to capture the definition of your model, even in light of the flexible and dynamic nature of PyTorch. Let’s begin by examining what we call <font size=3 color=maroon><b>tracing</b></font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:red;font-size:110%;font-weight:bold\">Tracing `Modules`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red;font-size:180%;font-weight:bold;\">torch.jit.trace()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        \n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  original_name=MyCell\n",
      "  (linear): Linear(original_name=Linear)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8850, 0.2197, 0.3758, 0.6387],\n",
       "         [0.4030, 0.5595, 0.7519, 0.7046],\n",
       "         [0.8786, 0.5741, 0.8806, 0.3584]], grad_fn=<TanhBackward0>),\n",
       " tensor([[0.8850, 0.2197, 0.3758, 0.6387],\n",
       "         [0.4030, 0.5595, 0.7519, 0.7046],\n",
       "         [0.8786, 0.5741, 0.8806, 0.3584]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "\n",
    "print(traced_cell)\n",
    "\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve rewinded a bit and taken the second version of our `MyCell` class. As before, we’ve instantiated it, but this time, we’ve called **`torch.jit.trace`**, passed in the `Module`, and passed in example inputs the network might see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=maroon>What exactly has this done? It has invoked the `Module`, recorded the operations that occured when the `Module` was run, and created an instance of **`torch.jit.ScriptModule`** (of which `TracedModule` is an instance)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.graph` property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchScript records its definitions in an <font size=3 color=maroon><b>Intermediate Representation</b></font> (or <font color=maroon size=3>IR</font>), commonly referred to in Deep learning as a graph. We can examine the graph with the **`.graph`** property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.MyCell,\n",
       "      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),\n",
       "      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
       "  %linear : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"linear\"](%self.1)\n",
       "  %20 : Tensor = prim::CallMethod[name=\"forward\"](%linear, %x)\n",
       "  %11 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_13796/2435684823.py:7:0\n",
       "  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_13796/2435684823.py:7:0\n",
       "  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_13796/2435684823.py:7:0\n",
       "  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)\n",
       "  return (%14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_cell.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.code` property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is a very low-level representation and most of the information contained in the graph is not useful for end users. Instead, we can use the **`.code`** property to give a Python-syntax interpretation of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def forward(self,\\n    x: Tensor,\\n    h: Tensor) -> Tuple[Tensor, Tensor]:\\n  linear = self.linear\\n  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\\n  return (_0, _0)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_cell.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  linear = self.linear\n",
      "  _0 = torch.tanh(torch.add((linear).forward(x, ), h))\n",
      "  return (_0, _0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Tracing Modules?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why did we do all this? There are several reasons:\n",
    "\n",
    "* TorchScript code can be invoked in <font color=maroon>its own interpreter</font>, which is basically <font color=maroon>a restricted Python interpreter</font>. This interpreter does not acquire the `Global Interpreter Lock`, and so many requests can be processed on the same instance simultaneously.\n",
    "\n",
    "\n",
    "* <font color=maroon>This format allows us to save the whole model to disk and load it into another environment, such as in a server written in a language other than Python.</font>\n",
    "\n",
    "\n",
    "* <font color=maroon>TorchScript gives us a representation in which we can do compiler optimizations on the code to provide more efficient execution.</font>\n",
    "\n",
    "\n",
    "* <font color=maroon>TorchScript allows us to interface with many backend/device runtimes that require a broader view of the program than individual operators.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that invoking `traced_cell` produces the same results as the Python module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8850, 0.2197, 0.3758, 0.6387],\n",
       "         [0.4030, 0.5595, 0.7519, 0.7046],\n",
       "         [0.8786, 0.5741, 0.8806, 0.3584]], grad_fn=<TanhBackward0>),\n",
       " tensor([[0.8850, 0.2197, 0.3758, 0.6387],\n",
       "         [0.4030, 0.5595, 0.7519, 0.7046],\n",
       "         [0.8786, 0.5741, 0.8806, 0.3584]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8850, 0.2197, 0.3758, 0.6387],\n",
       "         [0.4030, 0.5595, 0.7519, 0.7046],\n",
       "         [0.8786, 0.5741, 0.8806, 0.3584]], grad_fn=<TanhBackward0>),\n",
       " tensor([[0.8850, 0.2197, 0.3758, 0.6387],\n",
       "         [0.4030, 0.5595, 0.7519, 0.7046],\n",
       "         [0.8786, 0.5741, 0.8806, 0.3584]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scripting to Convert Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s a reason we used version two of our module, and not the one with the control-flow-laden submodule. \n",
    "\n",
    "Let’s examine that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        \n",
    "        return new_h, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_13796/3193462135.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "my_cell = MyCell(MyDecisionGate())\n",
    "\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> NoneType:\n",
      "  return None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.dg.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = (linear).forward(x, )\n",
      "  _1 = (dg).forward(_0, )\n",
      "  _2 = torch.tanh(torch.add(_0, h))\n",
      "  return (_2, _2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `.code` output, we can see that the `if-else` branch is nowhere to be found! Why? <font color=maroon>Tracing does exactly what we said it would: run the code, record the operations that happen and construct a ScriptModule that does exactly that. Unfortunately, <b>things like control flow are erased</b>.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:red;font-size:110%;font-weight:bold\">script `compiler`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red;font-size:180%;font-weight:bold;\">torch.jit.script()</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we faithfully represent this module in TorchScript? We provide a <font size=3 color=maroon><b>script compiler</b></font>, which does direct analysis of your Python source code to transform it into TorchScript. \n",
    "\n",
    "Let’s convert `MyDecisionGate` using the script compiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "\n",
    "my_cell = MyCell(scripted_gate)\n",
    "scripted_cell = torch.jit.script(my_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scripted_gate.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scripted_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! We’ve now faithfully captured the behavior of our program in TorchScript. \n",
    "\n",
    "Let’s now try running the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0620,  0.4553,  0.8167,  0.2478],\n",
       "         [ 0.5178,  0.6599,  0.3854,  0.4780],\n",
       "         [ 0.4654,  0.6470,  0.7033,  0.0836]], grad_fn=<TanhBackward0>),\n",
       " tensor([[-0.0620,  0.4553,  0.8167,  0.2478],\n",
       "         [ 0.5178,  0.6599,  0.3854,  0.4780],\n",
       "         [ 0.4654,  0.6470,  0.7033,  0.0836]], grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, h = torch.rand(3, 4), torch.rand(3, 4)   # New inputs\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing Scripting and Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some situations call for using tracing rather than scripting (e.g. a module has many architectural decisions that are made based on constant Python values that we would like to not appear in TorchScript). In this case, scripting can be composed with tracing: **`torch.jit.script`** will inline the code for a traced module, and tracing will inline the code for a scripted module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the first case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h))\n",
    "        \n",
    "        \n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "            \n",
    "        return y, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  h = torch.zeros([3, 4])\n",
      "  y = torch.zeros([3, 4])\n",
      "  y0 = y\n",
      "  h0 = h\n",
      "  for i in range(torch.size(xs, 0)):\n",
      "    cell = self.cell\n",
      "    _0 = (cell).forward(torch.select(xs, 0, i), h0, )\n",
      "    y1, h1, = _0\n",
      "    y0, h0 = y1, h1\n",
      "  return (y0, h0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(rnn_loop.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example of the second case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrapRNN, self).__init__()\n",
    "        self.loop = torch.jit.script(MyRNNLoop())\n",
    "\n",
    "    def forward(self, xs):\n",
    "        y, h = self.loop(xs)\n",
    "        \n",
    "        return torch.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, scripting and tracing can be used when the situation calls for each of them and used together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=maroon size=3>We provide APIs to save and load TorchScript modules to/from disk in an archive format. This format includes code, parameters, attributes, and debug information, meaning that the archive is a freestanding representation of the model that can be loaded in an entirely separate process. </font>\n",
    "    \n",
    "    \n",
    "Let’s save and load our wrapped RNN module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=WrapRNN\n",
      "  (loop): RecursiveScriptModule(\n",
      "    original_name=MyRNNLoop\n",
      "    (cell): RecursiveScriptModule(\n",
      "      original_name=MyCell\n",
      "      (dg): RecursiveScriptModule(original_name=MyDecisionGate)\n",
      "      (linear): RecursiveScriptModule(original_name=Linear)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "def forward(self,\n",
      "    xs: Tensor) -> Tensor:\n",
      "  loop = self.loop\n",
      "  _0, y, = (loop).forward(xs, )\n",
      "  return torch.relu(y)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traced.save('./model_weights/wrapped_rnn.pt')\n",
    "\n",
    "loaded = torch.jit.load('./model_weights/wrapped_rnn.pt')\n",
    "\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, **serialization** preserves the module hierarchy and the code we’ve been examining throughout. The model can also be loaded, for example, <a href=\"https://pytorch.org/tutorials/advanced/cpp_export.html\" style=\"text-decoration:none;\">into C++</a> for python-free execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve completed our tutorial! For a more involved demonstration, check out the NeurIPS demo for converting machine translation models using TorchScript:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ\" style=\"text-decoration:none;\">https://colab.research.google.com/drive/1HiICg6jRkBnr5hvK2-VnMi88Vi9pUzEJ</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptg]",
   "language": "python",
   "name": "conda-env-ptg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.727px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
