{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><font color=maroon size=6><b>TorchScript</b></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>References:</b></font>\n",
    "* `Docs > `<a href=\"https://pytorch.org/docs/stable/jit.html\" style=\"text-decoration:none;\">TorchScript</a>\n",
    "* Docs > TorchScript > <a href=\"https://pytorch.org/docs/stable/jit_language_reference_v2.html\" style=\"text-decoration:none;\">TorchScript Language Reference</a>\n",
    "* Docs > TorchScript > <a href=\"https://pytorch.org/docs/stable/jit_builtin_functions.html\" style=\"text-decoration:none;\">TorchScript Builtins</a>\n",
    "* Docs > TorchScript > <a href=\"https://pytorch.org/docs/master/generated/torch.jit.trace.html\" style=\"text-decoration:none;\">torch.jit.trace</a>\n",
    "* Docs > TorchScript > <a href=\"\" style=\"text-decoration:none;\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>TorchScript is a way to create serializable and optimizable models from PyTorch code. Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency.\n",
    "\n",
    "We provide tools to incrementally transition a model from a pure Python program to a TorchScript program that can be run independently from Python, such as in a standalone C++ program. This makes it possible to train models in PyTorch using familiar tools in Python and then export the model via TorchScript to a production environment where Python programs may be disadvantageous for performance and multi-threading reasons.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For a gentle introduction to TorchScript, see the <a href=\"https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html\" style=\"text-decoration:none;color:maroon;font-size:120%;\">Introduction to TorchScript</a> tutorial. <br>\n",
    "`(详见笔记：D:\\KeepStudy\\0_Coding\\Pytorch\\Pytorch_Tutorials\\3-2 Introduction to TorchScript.ipynb)`\n",
    "\n",
    "\n",
    "* For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see the <a href=\"https://pytorch.org/tutorials/advanced/cpp_export.html\" style=\"text-decoration:none;color:maroon;font-size:120%;\">Loading a PyTorch Model in C++</a> tutorial. <br>\n",
    "`(详见笔记：D:\\KeepStudy\\0_Coding\\Pytorch\\Pytorch_Tutorials\\3-3 Loading a TorchScript Model in C++.ipynb)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchScript Language Reference <a href=\"https://pytorch.org/docs/stable/jit_language_reference_v2.html\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reference manual describes the syntax and core semantics of the TorchScript language. \n",
    "\n",
    "TorchScript is a statically typed subset of the Python language. \n",
    "\n",
    "This document explains the supported features of Python in TorchScript and also how the language diverges from regular Python. \n",
    "\n",
    "Any features of Python that are not mentioned in this reference manual are not part of TorchScript. TorchScript focuses specifically on the features of Python that are needed to represent neural network models in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(其它详细内容，详见原网址)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating TorchScript Code <a href=\"https://pytorch.org/docs/stable/jit.html#creating-torchscript-code\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(详见蓝色 link 链接)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Tracing and Scripting <a href=\"https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>In many cases either tracing or scripting is an easier approach for converting a model to TorchScript. Tracing and scripting can be composed to suit the particular requirements of a part of a model. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><font color=maroon><b>① Scripted functions can call traced functions</b>. This is particularly useful when you need to use **control-flow** around **a simple feed-forward model**.</font> For instance the beam search of a sequence to sequence model will typically be written in script but can call an encoder module generated using tracing.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example (calling a traced function in script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def foo(x, y):\n",
    "    return 2 * x + y\n",
    "\n",
    "traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def bar(x):\n",
    "    return traced_foo(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar(torch.tensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar(torch.tensor([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3><font color=maroon><b>② Traced functions can call script functions</b>. This is useful when a small part of a model requires some **control-flow** even though most of the model is just a feed-forward network.</font> Control-flow inside of a script function called by a traced function is preserved correctly.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example (calling a script function in a traced function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.jit.script\n",
    "def foo(x, y):\n",
    "    if x.max() > y.max():\n",
    "        r = x\n",
    "    else:\n",
    "        r = y\n",
    "    return r\n",
    "\n",
    "\n",
    "def bar(x, y, z):\n",
    "    return foo(x, y) + z\n",
    "\n",
    "traced_bar = torch.jit.trace(bar, (torch.rand(3), torch.rand(3), torch.rand(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar(torch.tensor([1,2]), torch.tensor([2,3]), torch.tensor([2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_bar(torch.tensor([1,2]), torch.tensor([2,3]), torch.tensor([2,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>This composition also works for `nn.Modules` as well, where it can be used to generate a submodule using tracing that can be called from the methods of a script module.</font>\n",
    "\n",
    "Example (using a traced module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "class MyScriptModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyScriptModule, self).__init__()\n",
    "        self.means = torch.nn.Parameter(torch.tensor([103.939, 116.779, 123.68])\n",
    "                                        .resize_(1, 3, 1, 1))\n",
    "        self.resnet = torch.jit.trace(torchvision.models.resnet18(),\n",
    "                                      torch.rand(1, 3, 224, 224))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.resnet(input - self.means)\n",
    "\n",
    "my_script_module = torch.jit.script(MyScriptModule())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchScript Language <a href=\"https://pytorch.org/docs/stable/jit.html#torchscript-language\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchScript is a statically typed subset of Python, so many Python features apply directly to TorchScript. See the full <a href=\"https://pytorch.org/docs/stable/jit_language_reference.html#language-reference\" style=\"text-decoration:none;color:maroon;font-size:120%;\">TorchScript Language Reference</a> for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Functions and Modules <a href=\"https://pytorch.org/docs/stable/jit.html#built-in-functions-and-modules\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchScript supports the use of most PyTorch functions and many Python built-ins. See <a href=\"https://pytorch.org/docs/stable/jit_builtin_functions.html#builtin-functions\" style=\"text-decoration:none;color:maroon;font-size:120%;\">TorchScript Builtins</a> for a full reference of supported functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Functions and Modules <a href=\"https://pytorch.org/docs/stable/jit.html#pytorch-functions-and-modules\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>TorchScript supports a subset of the tensor and neural network functions that PyTorch provides. Most methods on `Tensor` as well as `functions in the torch namespace`, `all functions in torch.nn.functional` and `most modules from torch.nn` are supported in TorchScript.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See <a href=\"https://pytorch.org/docs/stable/jit_unsupported.html#jit-unsupported\" style=\"text-decoration:none;color:maroon;font-size:120%;\">TorchScript Unsupported Pytorch Constructs</a> for a list of unsupported PyTorch functions and modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Functions and Modules <a href=\"https://pytorch.org/docs/stable/jit.html#python-functions-and-modules\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of Python’s <a href=\"https://docs.python.org/3/library/functions.html\" style=\"text-decoration:none;font-size:120%;\">built-in functions</a> are supported in TorchScript. The <a href=\"https://docs.python.org/3/library/math.html#module-math\" style=\"text-decoration:none;font-size:120%\">math</a> module is also supported (see <a href=\"https://pytorch.org/docs/stable/jit_builtin_functions.html#math-module\" style=\"text-decoration:none;color:maroon;font-size:120%;\">math Module</a> for details), but no other Python modules (built-in or third party) are supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Language Reference Comparison <a href=\"https://pytorch.org/docs/stable/jit.html#python-language-reference-comparison\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full listing of supported Python features, see <a href=\"https://pytorch.org/docs/stable/jit_python_reference.html#python-language-reference\" style=\"text-decoration:none;color:maroon;font-size:120%;\">Python Language Reference Coverage</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging <a href=\"https://pytorch.org/docs/stable/jit.html#debugging\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disable JIT for Debugging <a href=\"https://pytorch.org/docs/stable/jit.html#disable-jit-for-debugging\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"font-size:130%\">**`PYTORCH_JIT`**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Setting the environment variable <font size=4>`PYTORCH_JIT=0`</font> will disable all script and tracing annotations. If there is hard-to-debug error in one of your TorchScript models, you can use this flag to force everything to run using native Python. Since TorchScript (scripting and tracing) is disabled with this flag, you can use tools like pdb to debug the model code. For example:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\18617\\appdata\\local\\temp\\ipykernel_1500\\2546201766.py\u001b[0m(12)\u001b[0;36mfn\u001b[1;34m()\u001b[0m\n",
      "\n",
      "ipdb> 6\n",
      "6\n",
      "ipdb> torch.tensor([1,2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<stdin>:1: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "ipdb> exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1500/2546201766.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscripted_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtraced_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtraced_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_qualified_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m     traced = torch._C._create_function_from_trace(\n\u001b[0m\u001b[0;32m    787\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1500/2546201766.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mscripted_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtraced_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1500/2546201766.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mscripted_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtraced_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def scripted_fn(x : torch.Tensor):\n",
    "    for i in range(12):\n",
    "        x = x + x\n",
    "    return x\n",
    "\n",
    "def fn(x):\n",
    "    x = torch.neg(x)\n",
    "    \n",
    "    import pdb; pdb.set_trace()          ### !!!\n",
    "    \n",
    "    return scripted_fn(x)\n",
    "\n",
    "traced_fn = torch.jit.trace(fn, (torch.rand(4, 5),))\n",
    "traced_fn(torch.rand(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging this script with `pdb` works except for when we invoke the <a href=\"https://pytorch.org/docs/stable/generated/torch.jit.script.html#torch.jit.script\" style=\"text-decoration:none;font-size:120%\">@torch.jit.script</a> function. We can globally disable JIT, so that we can call the `@torch.jit.script` function as a normal Python function and not compile it. \n",
    "\n",
    "If the above script is called disable_jit_example.py, we can invoke it like so:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ PYTORCH_JIT=0 python disable_jit_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will be able to step into the @torch.jit.script function as a normal Python function. <font color=maroon>To disable the TorchScript compiler for a specific function, see <a href=\"https://pytorch.org/docs/stable/generated/torch.jit.ignore.html#torch.jit.ignore\" style=\"text-decoration:none;font-size:120%\">@torch.jit.ignore</a>.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Code <a href=\"https://pytorch.org/docs/stable/jit.html#inspecting-code\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>TorchScript provides a code pretty-printer for all <a href=\"https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule\" style=\"text-decoration:none;font-size:120%\">ScriptModule</a> instances. This pretty-printer gives an interpretation of the script method’s code as valid Python syntax. \n",
    "\n",
    "For example:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def foo(len: int) -> Tensor:\n",
      "  rv = torch.zeros([3, 4])\n",
      "  rv0 = rv\n",
      "  for i in range(len):\n",
      "    if torch.lt(i, 10):\n",
      "      rv1 = torch.sub(rv0, 1.)\n",
      "    else:\n",
      "      rv1 = torch.add(rv0, 1.)\n",
      "    rv0 = rv1\n",
      "  return rv0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def foo(len):\n",
    "    # type: (int) -> torch.Tensor\n",
    "    rv = torch.zeros(3, 4)\n",
    "    for i in range(len):\n",
    "        if i < 10:\n",
    "            rv = rv - 1.0\n",
    "        else:\n",
    "            rv = rv + 1.0\n",
    "    return rv\n",
    "\n",
    "print(foo.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>A `ScriptModule` with a single `forward` method will have an attribute `code`, which you can use to inspect the `ScriptModule’s code`. <font color=maroon>If the ScriptModule has more than one method, you will need to access `.code` on the method itself and not the module.</font> We can inspect the code of a method named `foo` on a ScriptModule by accessing `.foo.code`. The example above produces this output (shown as above):</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is TorchScript’s compilation of the code for the `forward` method. You can use this to ensure TorchScript (tracing or scripting) has captured your model code correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Graphs <a href=\"https://pytorch.org/docs/stable/jit.html#interpreting-graphs\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>TorchScript also has a representation at a lower level than the `code pretty- printer`, in the form of `IR graphs`.\n",
    "\n",
    "TorchScript uses a `static single assignment (SSA) `**`intermediate representation (IR)`** to represent computation. The instructions in this format consist of ATen (the C++ backend of PyTorch) operators and other primitive operators, including control flow operators for loops and conditionals. </font>\n",
    "\n",
    "As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%len.1 : int):\n",
      "  %21 : int = prim::Constant[value=1]()\n",
      "  %13 : bool = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:5:4\n",
      "  %5 : NoneType = prim::Constant()\n",
      "  %1 : int = prim::Constant[value=3]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:4:21\n",
      "  %2 : int = prim::Constant[value=4]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:4:24\n",
      "  %16 : int = prim::Constant[value=10]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:6:15\n",
      "  %20 : float = prim::Constant[value=1.]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:7:22\n",
      "  %4 : int[] = prim::ListConstruct(%1, %2)\n",
      "  %rv.1 : Tensor = aten::zeros(%4, %5, %5, %5, %5) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:4:9\n",
      "  %rv : Tensor = prim::Loop(%len.1, %13, %rv.1) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:5:4\n",
      "    block0(%i.1 : int, %rv.29 : Tensor):\n",
      "      %17 : bool = aten::lt(%i.1, %16) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:6:11\n",
      "      %rv.27 : Tensor = prim::If(%17) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:6:8\n",
      "        block0():\n",
      "          %rv.5 : Tensor = aten::sub(%rv.29, %20, %21) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:7:17\n",
      "          -> (%rv.5)\n",
      "        block1():\n",
      "          %rv.11 : Tensor = aten::add(%rv.29, %20, %21) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2108428211.py:9:17\n",
      "          -> (%rv.11)\n",
      "      -> (%13, %rv.27)\n",
      "  return (%rv)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def foo(len):\n",
    "    # type: (int) -> torch.Tensor\n",
    "    rv = torch.zeros(3, 4)\n",
    "    for i in range(len):\n",
    "        if i < 10:\n",
    "            rv = rv - 1.0\n",
    "        else:\n",
    "            rv = rv + 1.0\n",
    "    return rv\n",
    "\n",
    "print(foo.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`graph` follows the same rules described in the <a href=\"https://pytorch.org/docs/stable/jit.html#inspecting-code\" style=\"text-decoration:none;color:maroon;\">Inspecting Code</a> section with regard to `forward` method lookup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(From the original site)` The example script above produces the graph:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "graph(%len.1 : int):\n",
    "  %24 : int = prim::Constant[value=1]()\n",
    "  %17 : bool = prim::Constant[value=1]() # test.py:10:5\n",
    "  %12 : bool? = prim::Constant()\n",
    "  %10 : Device? = prim::Constant()\n",
    "  %6 : int? = prim::Constant()\n",
    "  %1 : int = prim::Constant[value=3]() # test.py:9:22\n",
    "  %2 : int = prim::Constant[value=4]() # test.py:9:25\n",
    "  %20 : int = prim::Constant[value=10]() # test.py:11:16\n",
    "  %23 : float = prim::Constant[value=1]() # test.py:12:23\n",
    "  %4 : int[] = prim::ListConstruct(%1, %2)\n",
    "  %rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10\n",
    "  %rv : Tensor = prim::Loop(%len.1, %17, %rv.1) # test.py:10:5\n",
    "    block0(%i.1 : int, %rv.14 : Tensor):\n",
    "      %21 : bool = aten::lt(%i.1, %20) # test.py:11:12\n",
    "      %rv.13 : Tensor = prim::If(%21) # test.py:11:9\n",
    "        block0():\n",
    "          %rv.3 : Tensor = aten::sub(%rv.14, %23, %24) # test.py:12:18\n",
    "          -> (%rv.3)\n",
    "        block1():\n",
    "          %rv.6 : Tensor = aten::add(%rv.14, %23, %24) # test.py:14:18\n",
    "          -> (%rv.6)\n",
    "      -> (%17, %rv.13)\n",
    "  return (%rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the instruction `%rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10` for example.\n",
    "\n",
    "* `%rv.1 : Tensor` means we assign the output to a (unique) value named `rv.1`, that value is of `Tensor` type and that we do not know its concrete shape.\n",
    "\n",
    "* `aten::zeros` is the operator (equivalent to `torch.zeros`) and the input list `(%4, %6, %6, %10, %12)` specifies which values in scope should be passed as inputs. The schema for built-in functions like `aten::zeros` can be found at <a href=\"https://pytorch.org/docs/stable/jit.html#builtin-functions\" style=\"text-decoration:none;color:maroon;font-size:110%;\">Builtin Functions</a>.\n",
    "\n",
    "* `# test.py:9:10` is the location in the original source file that generated this instruction. In this case, it is a file named ***test.py***, on line 9, and at character 10.\n",
    "\n",
    "\n",
    "Notice that operators can also have associated `blocks`, namely the `prim::Loop` and `prim::If` operators. In the graph print-out, these operators are formatted to reflect their equivalent source code forms to facilitate easy debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Graphs can be inspected as shown to confirm that the computation described by a <a href=\"https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule\" style=\"text-decoration:none;font-size:120%\">ScriptModule</a> is correct, in both automated and manual fashion, as described below.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracer <a href=\"https://pytorch.org/docs/stable/jit.html#tracer\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing Edge Cases <a href=\"https://pytorch.org/docs/stable/jit.html#tracing-edge-cases\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>There are some edge cases that exist where the trace of a given Python function/module will not be representative of the underlying code. These cases can include:\n",
    "\n",
    "* Tracing of control flow that is dependent on inputs (e.g. tensor shapes)\n",
    "\n",
    "* Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment)\n",
    "\n",
    "Note that these cases may in fact be traceable in the future.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Trace Checking <a href=\"https://pytorch.org/docs/stable/jit.html#automatic-trace-checking\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>One way to automatically catch many errors in traces is by using <font color=maroon>***check_inputs***</font> on the `torch.jit.trace()` API. `check_inputs` takes a list of tuples of inputs that will be used to re-trace the computation and verify the results.</font> \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py:799: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 29 / 30 (96.7%)\n",
      "Greatest absolute difference: 0.2849639654159546 at index (4, 1) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 12.509584529747938 at index (1, 2) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    },
    {
     "ename": "TracingCheckError",
     "evalue": "Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%x : Tensor):\n\t\t    %1 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:2:0\n\t\t    %2 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:2:0\n\t\t    %result.1 : Tensor = aten::select(%x, %1, %2) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:2:0\n\t\t    %4 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %5 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %6 : Tensor = aten::select(%x, %4, %5) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %result.3 : Tensor = aten::mul(%result.1, %6) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %8 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %9 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %10 : Tensor = aten::select(%x, %8, %9) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t-   %result : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %result.5 : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?          ++\n\t\t    %12 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %13 : int = prim::Constant[value=2]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %14 : Tensor = aten::select(%x, %12, %13) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %result : Tensor = aten::mul(%result.5, %14) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %16 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %17 : int = prim::Constant[value=3]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %18 : Tensor = aten::select(%x, %16, %17) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t-   %15 : Tensor = aten::mul(%result, %14) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?     ^                                 ^\n\t\t+   %19 : Tensor = aten::mul(%result, %18) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?     ^                                 ^\n\t\t-   return (%15)\n\t\t?             ^\n\t\t+   return (%19)\n\t\t?             ^\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %result : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+ %result.5 : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?        ++\n\tTrace source location:\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(4): loop_in_traced_fn\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(786): trace\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(10): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3457): run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3377): run_ast_nodes\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3185): run_cell_async\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\async_helpers.py(78): _pseudo_sync_runner\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2960): _run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2914): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\zmqshell.py(533): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\ipkernel.py(353): do_execute\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(648): execute_request\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(353): dispatch_shell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(446): process_one\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(457): dispatch_queue\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\events.py(80): _run\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(1890): _run_once\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(596): run_forever\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelapp.py(677): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\traitlets\\config\\application.py(846): launch_instance\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel_launcher.py(16): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(87): _run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(197): _run_module_as_main\n\tCheck source location:\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(4): loop_in_traced_fn\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(786): trace\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(344): _check_trace\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\autograd\\grad_mode.py(28): decorate_context\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(799): trace\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(10): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3457): run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3377): run_ast_nodes\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3185): run_cell_async\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\async_helpers.py(78): _pseudo_sync_runner\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2960): _run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2914): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\zmqshell.py(533): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\ipkernel.py(353): do_execute\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(648): execute_request\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(353): dispatch_shell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(446): process_one\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(457): dispatch_queue\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\events.py(80): _run\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(1890): _run_once\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(596): run_forever\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelapp.py(677): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\traitlets\\config\\application.py(846): launch_instance\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel_launcher.py(16): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(87): _run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(197): _run_module_as_main\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTracingCheckError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcheck_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtraced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_in_traced_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_trace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_inputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m             _check_trace(\n\u001b[0m\u001b[0;32m    800\u001b[0m                 \u001b[0mcheck_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36m_check_trace\u001b[1;34m(check_inputs, func, traced_func, check_tolerance, strict, force_outplace, is_trace_module, _module_class)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mdiag_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_diagnostic_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdiag_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTracingCheckError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdiag_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTracingCheckError\u001b[0m: Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%x : Tensor):\n\t\t    %1 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:2:0\n\t\t    %2 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:2:0\n\t\t    %result.1 : Tensor = aten::select(%x, %1, %2) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:2:0\n\t\t    %4 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %5 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %6 : Tensor = aten::select(%x, %4, %5) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %result.3 : Tensor = aten::mul(%result.1, %6) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %8 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %9 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %10 : Tensor = aten::select(%x, %8, %9) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t-   %result : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %result.5 : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?          ++\n\t\t    %12 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %13 : int = prim::Constant[value=2]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t    %14 : Tensor = aten::select(%x, %12, %13) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %result : Tensor = aten::mul(%result.5, %14) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %16 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %17 : int = prim::Constant[value=3]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+   %18 : Tensor = aten::select(%x, %16, %17) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t-   %15 : Tensor = aten::mul(%result, %14) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?     ^                                 ^\n\t\t+   %19 : Tensor = aten::mul(%result, %18) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?     ^                                 ^\n\t\t-   return (%15)\n\t\t?             ^\n\t\t+   return (%19)\n\t\t?             ^\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %result : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t+ %result.5 : Tensor = aten::mul(%result.3, %10) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py:4:0\n\t\t?        ++\n\tTrace source location:\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(4): loop_in_traced_fn\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(786): trace\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(10): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3457): run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3377): run_ast_nodes\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3185): run_cell_async\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\async_helpers.py(78): _pseudo_sync_runner\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2960): _run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2914): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\zmqshell.py(533): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\ipkernel.py(353): do_execute\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(648): execute_request\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(353): dispatch_shell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(446): process_one\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(457): dispatch_queue\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\events.py(80): _run\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(1890): _run_once\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(596): run_forever\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelapp.py(677): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\traitlets\\config\\application.py(846): launch_instance\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel_launcher.py(16): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(87): _run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(197): _run_module_as_main\n\tCheck source location:\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(4): loop_in_traced_fn\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(786): trace\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(344): _check_trace\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\autograd\\grad_mode.py(28): decorate_context\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py(799): trace\n\t\tC:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1571788462.py(10): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3457): run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3377): run_ast_nodes\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3185): run_cell_async\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\async_helpers.py(78): _pseudo_sync_runner\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2960): _run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2914): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\zmqshell.py(533): run_cell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\ipkernel.py(353): do_execute\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(648): execute_request\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(353): dispatch_shell\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(446): process_one\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelbase.py(457): dispatch_queue\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\events.py(80): _run\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(1890): _run_once\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\asyncio\\base_events.py(596): run_forever\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel\\kernelapp.py(677): start\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\traitlets\\config\\application.py(846): launch_instance\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\ipykernel_launcher.py(16): <module>\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(87): _run_code\n\t\tD:\\Programs\\Anaconda3\\envs\\ptg\\lib\\runpy.py(197): _run_module_as_main\n"
     ]
    }
   ],
   "source": [
    "def loop_in_traced_fn(x):\n",
    "    result = x[0]\n",
    "    for i in range(x.size(0)):\n",
    "        result = result * x[i]\n",
    "    return result\n",
    "\n",
    "inputs = (torch.rand(3, 4, 5),)\n",
    "check_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)]\n",
    "\n",
    "traced = torch.jit.trace(loop_in_traced_fn, inputs, check_inputs=check_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives us the following diagnostic information: `(Shown as above or see the original site)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This message indicates to us that the computation differed between when we first traced it and when we traced it with the `check_inputs`. Indeed, the loop within the body of `loop_in_traced_fn` depends on the shape of the input `x`, and thus when we try another `x` with a different shape, the trace differs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>In this case, data-dependent control flow like this can be captured using <a href=\"https://pytorch.org/docs/stable/generated/torch.jit.script.html#torch.jit.script\" style=\"text-decoration:none;font-size:120%\">torch.jit.script()</a> instead:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x.1 : Tensor):\n",
      "  %9 : bool = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1970361538.py:3:4\n",
      "  %2 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1970361538.py:2:15\n",
      "  %result.1 : Tensor = aten::select(%x.1, %2, %2) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1970361538.py:2:13\n",
      "  %6 : int = aten::size(%x.1, %2) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1970361538.py:3:19\n",
      "  %result : Tensor = prim::Loop(%6, %9, %result.1) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1970361538.py:3:4\n",
      "    block0(%i.1 : int, %result.11 : Tensor):\n",
      "      %17 : Tensor = aten::select(%x.1, %2, %i.1) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1970361538.py:4:26\n",
      "      %result.5 : Tensor = aten::mul(%result.11, %17) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/1970361538.py:4:17\n",
      "      -> (%9, %result.5)\n",
      "  return (%result)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fn(x):\n",
    "    result = x[0]\n",
    "    for i in range(x.size(0)):\n",
    "        result = result * x[i]\n",
    "    return result\n",
    "\n",
    "inputs = (torch.rand(3, 4, 5),)\n",
    "check_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)]\n",
    "\n",
    "scripted_fn = torch.jit.script(fn)\n",
    "print(scripted_fn.graph)\n",
    "#print(str(scripted_fn.graph).strip())\n",
    "\n",
    "for input_tuple in [inputs] + check_inputs:\n",
    "    torch.testing.assert_close(fn(*input_tuple), scripted_fn(*input_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which produces: `(See original site)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracer Warnings <a href=\"https://pytorch.org/docs/stable/jit.html#tracer-warnings\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>The tracer produces warnings for several problematic patterns in traced computation. As an example, take a trace of a function that contains an in-place assignment on a slice (a view) of a Tensor:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %4 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %5 : int = aten::size(%x, %4) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %6 : Long(device=cpu) = prim::NumToTensor(%5)\n",
      "  %7 : int = aten::Int(%6)\n",
      "  %8 : int[] = prim::ListConstruct(%7)\n",
      "  %9 : int = prim::Constant[value=6]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %10 : NoneType = prim::Constant()\n",
      "  %11 : Device = prim::Constant[value=\"cpu\"]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %12 : bool = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %13 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::rand(%8, %9, %10, %11, %12) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %14 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %15 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %16 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::select(%x, %14, %15) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  %17 : bool = prim::Constant[value=0]()\n",
      "  %18 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::copy_(%16, %13, %17) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "  return (%x)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py:810: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%13 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::rand(%8, %9, %10, %11, %12) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/485136185.py:2:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "D:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py:810: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 4 / 12 (33.3%)\n",
      "Greatest absolute difference: 0.3016308546066284 at index (0, 3) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 1.726054506273522 at index (0, 3) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    }
   ],
   "source": [
    "def fill_row_zero(x):\n",
    "    x[0] = torch.rand(*x.shape[1:2])\n",
    "    return x\n",
    "\n",
    "traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\n",
    "print(traced.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(From the original site)` Produces several warnings and a graph which simply returns the input:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fill_row_zero.py:4: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n",
    "    x[0] = torch.rand(*x.shape[1:2])\n",
    "fill_row_zero.py:6: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
    "Not within tolerance rtol=1e-05 atol=1e-05 at input[0, 1] (0.09115803241729736 vs. 0.6782537698745728) and 3 other locations (33.00%)\n",
    "    traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\n",
    "graph(%0 : Float(3, 4)) {\n",
    "    return (%0);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>We can fix this by modifying the code to not use the in-place update, but rather build up the result tensor out-of-place with `torch.cat`:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
      "  %4 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %5 : int = aten::size(%x, %4) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %6 : Long(device=cpu) = prim::NumToTensor(%5)\n",
      "  %7 : int = aten::Int(%6)\n",
      "  %8 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %9 : int[] = prim::ListConstruct(%8, %7)\n",
      "  %10 : int = prim::Constant[value=6]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %11 : NoneType = prim::Constant()\n",
      "  %12 : Device = prim::Constant[value=\"cpu\"]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %13 : bool = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %14 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::rand(%9, %10, %11, %12, %13) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %15 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %16 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %17 : int = prim::Constant[value=2]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %18 : int = prim::Constant[value=1]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %19 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%x, %15, %16, %17, %18) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %20 : Tensor[] = prim::ListConstruct(%14, %19)\n",
      "  %21 : int = prim::Constant[value=0]() # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  %22 : Float(2, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::cat(%20, %21) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "  return (%22)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py:810: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
      "\t%14 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::rand(%9, %10, %11, %12, %13) # C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_1500/2152967042.py:2:0\n",
      "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
      "  _check_trace(\n",
      "D:\\Programs\\Anaconda3\\envs\\ptg\\lib\\site-packages\\torch\\jit\\_trace.py:810: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 4 / 8 (50.0%)\n",
      "Greatest absolute difference: 0.7674643993377686 at index (0, 2) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 3.7931623060432633 at index (0, 2) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    }
   ],
   "source": [
    "def fill_row_zero(x):\n",
    "    x = torch.cat((torch.rand(1, *x.shape[1:2]), x[1:2]), dim=0)\n",
    "    return x\n",
    "\n",
    "traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\n",
    "print(traced.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequently Asked Questions <a href=\"https://pytorch.org/docs/stable/jit.html#frequently-asked-questions\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=4 color=red>**Q: I would like to train a model on GPU and do inference on CPU. What are the best practices?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>First convert your model from GPU to CPU and then save it, like so:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "```python\n",
    "cpu_model = gpu_model.cpu()\n",
    "sample_input_cpu = sample_input_gpu.cpu()\n",
    "traced_cpu = torch.jit.trace(cpu_model, sample_input_cpu)\n",
    "torch.jit.save(traced_cpu, \"cpu.pt\")\n",
    "\n",
    "traced_gpu = torch.jit.trace(gpu_model, sample_input_gpu)\n",
    "torch.jit.save(traced_gpu, \"gpu.pt\")\n",
    "\n",
    "# ... later, when using the model:\n",
    "\n",
    "if use_gpu:\n",
    "  model = torch.jit.load(\"gpu.pt\")\n",
    "else:\n",
    "  model = torch.jit.load(\"cpu.pt\")\n",
    "\n",
    "model(input)\n",
    "```\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>This is recommended because the tracer may witness tensor creation on a specific device, so casting an already-loaded model may have unexpected effects. Casting the model before saving it ensures that the tracer has the correct device information.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=4 color=red>**Q: How do I store attributes on a ScriptModule?**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>Say we have a model like:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "```python\n",
    "import torch\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.x = 2\n",
    "\n",
    "    def forward(self):\n",
    "        return self.x\n",
    "\n",
    "m = torch.jit.script(Model())\n",
    "```\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>If `Model` is instantiated it will result in a compilation error since the compiler doesn’t know about `x`. There are 4 ways to inform the compiler of attributes on `ScriptModule`:\n",
    "<br>\n",
    "<br>\n",
    "    1. <font color=maroon>**nn.Parameter**</font> - Values wrapped in `nn.Parameter` will work as they do on `nn.Modules`\n",
    "<br>\n",
    "<br>\n",
    "    2. <font color=maroon>**register_buffer**</font> - Values wrapped in `register_buffer` will work as they do on `nn.Modules`. This is equivalent to an attribute (see 4) of type `Tensor`.\n",
    "<br>\n",
    "<br>\n",
    "    3. <font color=maroon>**Constants**</font> - Annotating a class member as `Final` (or adding it to a list called `__constants__` at the class definition level) will mark the contained names as constants. Constants are saved directly in the code of the model. See ***builtin-constants*** for details.\n",
    "<br>\n",
    "<br>\n",
    "    4. <font color=maroon>**Attributes**</font> - Values that are a ***supported type*** can be added as mutable attributes. Most types can be inferred but some may need to be specified, see ***module attributes*** for details.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=4 color=red>**Q: I would like to trace module’s method but I keep getting this error:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`RuntimeError: Cannot insert a Tensor that requires grad as a constant. Consider making it a parameter or input, or detaching the gradient`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>This error usually means that the method you are tracing uses a module’s parameters and you are passing the module’s method instead of the module instance (e.g. `my_module_instance.forward` vs `my_module_instance`).\n",
    "\n",
    "* Invoking `trace` with a module’s method captures module parameters (which may require gradients) as **constants**.\n",
    "<br>\n",
    "<br>\n",
    "* On the other hand, invoking `trace` with module’s instance (e.g. `my_module`) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required.\n",
    "\n",
    "\n",
    "To trace a specific method on a module, see <a href=\"https://pytorch.org/docs/stable/generated/torch.jit.trace_module.html#torch.jit.trace_module\" style=\"text-decoration:none;font-size:120%\">torch.jit.trace_module</a>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Known Issues <a href=\"https://pytorch.org/docs/stable/jit.html#known-issues\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>If you’re using `Sequential` with TorchScript, the inputs of some of the `Sequential` submodules may be falsely inferred to be `Tensor`, even if they’re annotated otherwise. <font color=maroon>The canonical solution is to subclass `nn.Sequential` and redeclare `forward` with the input typed correctly.</font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix <a href=\"https://pytorch.org/docs/stable/jit.html#appendix\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrating to PyTorch 1.2 Recursive Scripting API <a href=\"https://pytorch.org/docs/stable/jit.html#migrating-to-pytorch-1-2-recursive-scripting-api\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(详见蓝色 link 链接的原网址内容)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References <a href=\"https://pytorch.org/docs/stable/jit.html#references\" style=\"text-decoration:none;font-size:70%\">[link]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(详见蓝色 link 链接的原网址内容)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<font size=3></font>\n",
    "\n",
    "<a href=\"\" style=\"text-decoration:none;font-size:70%\">[link]</a>\n",
    "<a href=\"\" style=\"text-decoration:none;font-size:120%\"></a>\n",
    "\n",
    "\n",
    "<a href=\"\" style=\"text-decoration:none;color:maroon;font-size:120%;\"></a>\n",
    "\n",
    "&emsp;&emsp;&emsp;&ensp;\n",
    "<a href=\"\" style=\"text-decoration:none;color:maroon;font-size:140%;font-weight:bold;\"></a>\n",
    "\n",
    "\n",
    "<font size=4>\n",
    "    \n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptg]",
   "language": "python",
   "name": "conda-env-ptg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
