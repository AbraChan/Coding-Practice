{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abrachan/parkinson-fog-prediction-torch-gru?scriptVersionId=135576565\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"66fe81a2","metadata":{"papermill":{"duration":0.079811,"end_time":"2023-07-03T08:36:51.794494","exception":false,"start_time":"2023-07-03T08:36:51.714683","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","# **Reference**:\n","* `Kaggle Competition`: <a href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview\" style=\"text-decoration:none\">Parkinson's Freezing of Gait Prediction</a>\n","* `Disscusion`: <a href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/416057\" style=\"text-decoration:none\">2nd place solution</a>\n","* `Notebook`: <a href=\"https://www.kaggle.com/code/takoihiraokazu/cv-ensemble-sub-0607-1\" style=\"text-decoration:none\">Inference notebook</a>\n","* `Github`: **TakoiHirokazu** <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction\" style=\"text-decoration:none\">Kaggle-Parkinsons-Freezing-of-Gait-Prediction</a> (Training)\n","\n","Thanks <a href=\"https://www.kaggle.com/takoihiraokazu\" style=\"text-decoration:none\">Takoi</a> and his/her teammates for their sharing solution and code!\n","\n","<br>\n","\n","* My own works: <a href=\"https://www.kaggle.com/code/abrachan/exploratory-data-analysis#Some-Conclusions\" style=\"text-decoration:none\">Exploratory Data Analysis</a>\n","\n","\n","<br>\n","<br>\n","\n","**Note**: <br>\n","The checkpoints using in this notebook which lying in the `/kaggle/input/parkinson-fog-prediction` were obtained from the training stage using **CUDA**. So if you want to run the `【Inference】` by skipping the training stage in this notebook in the kaggle environment, please select the GPU accelerator. Otherwise it will throw exceptions.\n","\n","`RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.`\n","\n","<br>\n","\n","------\n"]},{"cell_type":"markdown","id":"d25bedb9","metadata":{"papermill":{"duration":0.079097,"end_time":"2023-07-03T08:36:51.953484","exception":false,"start_time":"2023-07-03T08:36:51.874387","status":"completed"},"tags":[]},"source":["<br>\n","\n","# **Import Libraries**"]},{"cell_type":"code","execution_count":1,"id":"3ff1dc65","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:36:52.1145Z","iopub.status.busy":"2023-07-03T08:36:52.113713Z","iopub.status.idle":"2023-07-03T08:37:05.014446Z","shell.execute_reply":"2023-07-03T08:37:05.01352Z"},"papermill":{"duration":12.983614,"end_time":"2023-07-03T08:37:05.016921","exception":false,"start_time":"2023-07-03T08:36:52.033307","status":"completed"},"tags":[]},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import os\n","import gc\n","import sys\n","import glob\n","import json\n","import pickle\n","import logging\n","from tqdm import tqdm\n","from tqdm import tqdm_notebook as tqdm_nb\n","from contextlib import contextmanager\n","\n","import time\n","import datetime\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import PIL.Image as Image\n","\n","from IPython.display import Video\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, average_precision_score\n","from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import LayerNorm\n","from torch.nn import TransformerEncoder, TransformerDecoder\n","\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from transformers import AdamW, get_linear_schedule_with_warmup     # pip install transformers\n","\n","from torch.cuda import amp\n","from torch.utils.data import Dataset, DataLoader, TensorDataset"]},{"cell_type":"code","execution_count":2,"id":"73485cf4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:05.177492Z","iopub.status.busy":"2023-07-03T08:37:05.176179Z","iopub.status.idle":"2023-07-03T08:37:05.181663Z","shell.execute_reply":"2023-07-03T08:37:05.180791Z"},"papermill":{"duration":0.085819,"end_time":"2023-07-03T08:37:05.183728","exception":false,"start_time":"2023-07-03T08:37:05.097909","status":"completed"},"tags":[]},"outputs":[],"source":["# sys.path.append(\"../src/\")\n","# from logger import setup_logger, LOGGER    # Abrachan: see my revise below: `def init_logger()`\n","# from util_tool import reduce_mem_usage\n","\n","pd.set_option('display.max_columns', 300)"]},{"cell_type":"markdown","id":"9786614e","metadata":{"papermill":{"duration":0.078313,"end_time":"2023-07-03T08:37:05.340786","exception":false,"start_time":"2023-07-03T08:37:05.262473","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","# **Config**"]},{"cell_type":"code","execution_count":3,"id":"f7144986","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:05.495962Z","iopub.status.busy":"2023-07-03T08:37:05.495602Z","iopub.status.idle":"2023-07-03T08:37:05.500031Z","shell.execute_reply":"2023-07-03T08:37:05.499156Z"},"papermill":{"duration":0.083746,"end_time":"2023-07-03T08:37:05.501952","exception":false,"start_time":"2023-07-03T08:37:05.418206","status":"completed"},"tags":[]},"outputs":[],"source":["# When doing `inference`, set below as False so that we can run the whole notebook directly.\n","TRAIN_FLAG   = False # True\n","PREDICT_FLAG = False # True"]},{"cell_type":"markdown","id":"0dbf6929","metadata":{"papermill":{"duration":0.076849,"end_time":"2023-07-03T08:37:05.655369","exception":false,"start_time":"2023-07-03T08:37:05.57852","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","# **Load Data**"]},{"cell_type":"code","execution_count":4,"id":"9540aea1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:05.813976Z","iopub.status.busy":"2023-07-03T08:37:05.813612Z","iopub.status.idle":"2023-07-03T08:37:06.352172Z","shell.execute_reply":"2023-07-03T08:37:06.351185Z"},"papermill":{"duration":0.619164,"end_time":"2023-07-03T08:37:06.354592","exception":false,"start_time":"2023-07-03T08:37:05.735428","status":"completed"},"tags":[]},"outputs":[],"source":["root_data = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/'\n","\n","train_defog = glob.glob(root_data + 'train/defog/**')\n","train_tdcsfog = glob.glob(root_data + 'train/tdcsfog/**')\n","train_notype = glob.glob(root_data + 'train/notype/**')\n","\n","test_defog = glob.glob(root_data + 'test/defog/**')\n","test_tdcsfog = glob.glob(root_data + 'test/tdcsfog/**')\n","\n","subjects = pd.read_csv(root_data + 'subjects.csv')\n","tasks = pd.read_csv(root_data + 'tasks.csv')\n","events = pd.read_csv(root_data + 'events.csv')\n","\n","daily_metadata=pd.read_csv(root_data + 'daily_metadata.csv')\n","tdcsfog_metadata=pd.read_csv(root_data + 'tdcsfog_metadata.csv')\n","defog_metadata=pd.read_csv(root_data + 'defog_metadata.csv')\n","\n","sub = pd.read_csv(root_data + 'sample_submission.csv')"]},{"cell_type":"markdown","id":"0b7cf75c","metadata":{"papermill":{"duration":0.075975,"end_time":"2023-07-03T08:37:06.507817","exception":false,"start_time":"2023-07-03T08:37:06.431842","status":"completed"},"tags":[]},"source":["For some basic Exploratory Data Analysis (EDA), refers to <a href=\"https://www.kaggle.com/code/abrachan/exploratory-data-analysis\" style=\"text-decoration:none\">my own work</a> if you are interested."]},{"cell_type":"markdown","id":"edb80570","metadata":{"papermill":{"duration":0.077243,"end_time":"2023-07-03T08:37:06.66333","exception":false,"start_time":"2023-07-03T08:37:06.586087","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","# **tdcsfog** 【Training】\n","\n","<br>\n","\n","<br>\n","\n","## **Feature Engineering**\n","\n","<br>\n","\n","### fe001_tdcsfog_base_feature\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe001_tdcsfog_base_feature.ipynb\" style=\"text-decoration:none\">fe001_tdcsfog_base_feature.ipynb</a>"]},{"cell_type":"code","execution_count":5,"id":"e5a40d8f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:06.824587Z","iopub.status.busy":"2023-07-03T08:37:06.823717Z","iopub.status.idle":"2023-07-03T08:37:06.829346Z","shell.execute_reply":"2023-07-03T08:37:06.828383Z"},"papermill":{"duration":0.085801,"end_time":"2023-07-03T08:37:06.83135","exception":false,"start_time":"2023-07-03T08:37:06.745549","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"001\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\", exist_ok=True)\n","    os.makedirs(f\"./output/fe/fe{fe}/save\", exist_ok=True)"]},{"cell_type":"code","execution_count":6,"id":"f9c6768d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:06.988359Z","iopub.status.busy":"2023-07-03T08:37:06.987306Z","iopub.status.idle":"2023-07-03T08:37:06.991908Z","shell.execute_reply":"2023-07-03T08:37:06.99106Z"},"papermill":{"duration":0.084361,"end_time":"2023-07-03T08:37:06.994023","exception":false,"start_time":"2023-07-03T08:37:06.909662","status":"completed"},"tags":[]},"outputs":[],"source":["# TDCSFOG_META_PATH = \"../data/tdcsfog_metadata.csv\"\n","# TDCSFOG_FOLDER = \"../data/train/tdcsfog/*.csv\"\n","\n","# meta = pd.read_csv(TDCSFOG_META_PATH)"]},{"cell_type":"code","execution_count":7,"id":"67477c49","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:37:07.152584Z","iopub.status.busy":"2023-07-03T08:37:07.151601Z","iopub.status.idle":"2023-07-03T08:37:07.167743Z","shell.execute_reply":"2023-07-03T08:37:07.166907Z"},"papermill":{"duration":0.097376,"end_time":"2023-07-03T08:37:07.169835","exception":false,"start_time":"2023-07-03T08:37:07.072459","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"data":{"text/plain":["{'4dc2f8': 0,\n"," 'f62eec': 1,\n"," '231c3b': 2,\n"," 'fa8764': 3,\n"," 'c85fdf': 4,\n"," '31d269': 5,\n"," '07285e': 6,\n"," '02bc69': 7,\n"," '7eb666': 8,\n"," '220a17': 9,\n"," '54ee6e': 10,\n"," '242a3e': 11,\n"," 'e9fc55': 12,\n"," '66341b': 13,\n"," '7fcee9': 14,\n"," 'f686f0': 15,\n"," '312788': 16,\n"," '4ca9b3': 17,\n"," '2a39f8': 18,\n"," 'd9312a': 19,\n"," '3b2b7a': 20,\n"," '4b39ac': 21,\n"," '93f49f': 22,\n"," 'af82b2': 23,\n"," '251738': 24,\n"," '87174c': 25,\n"," '3b2403': 26,\n"," 'a03db7': 27,\n"," 'a80ae4': 28,\n"," '364459': 29,\n"," 'bc3908': 30,\n"," '4ba1d3': 31,\n"," '301ada': 32,\n"," '51574c': 33,\n"," '8db7dd': 34,\n"," '69cc45': 35,\n"," '2d57c2': 36,\n"," 'd8836b': 37,\n"," 'eeaff0': 38,\n"," '6a3e93': 39,\n"," 'f2c8aa': 40,\n"," '2c98f7': 41,\n"," 'c8e721': 42,\n"," 'e8919c': 43,\n"," '24a59d': 44,\n"," '743f4e': 45,\n"," '4bb5d0': 46,\n"," '516a67': 47,\n"," '48fd62': 48,\n"," '082f01': 49,\n"," 'c95ab0': 50,\n"," '59f492': 51,\n"," '79011a': 52,\n"," 'b19f77': 53,\n"," '5c0b8a': 54,\n"," '7688c1': 55,\n"," '4f13b4': 56,\n"," '19ea47': 57,\n"," '9f85da': 58,\n"," 'e39bc5': 59,\n"," 'c7fee4': 60,\n"," '194d1d': 61}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["sub_dict = {}\n","for n,i in enumerate(tdcsfog_metadata[\"Subject\"].unique()):\n","    sub_dict[i] = n\n","sub_dict"]},{"cell_type":"code","execution_count":8,"id":"3890764a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:07.340365Z","iopub.status.busy":"2023-07-03T08:37:07.339986Z","iopub.status.idle":"2023-07-03T08:37:07.777323Z","shell.execute_reply":"2023-07-03T08:37:07.776201Z"},"papermill":{"duration":0.520554,"end_time":"2023-07-03T08:37:07.780464","exception":false,"start_time":"2023-07-03T08:37:07.25991","status":"completed"},"tags":[]},"outputs":[],"source":["tdcsfog_metadata[\"Sub_id\"] = tdcsfog_metadata[\"Subject\"].map(sub_dict)\n","\n","\n","# pip install pyarrow\n","# pip install fastparquet\n","tdcsfog_metadata.to_parquet(\"./output/fe/fe001/fe001_tdcsfog_meta.parquet\")\n","\n","with open(f'./output/fe/fe{fe}/fe{fe}_sub_id.pkl', 'wb') as p:\n","    pickle.dump(sub_dict, p)"]},{"cell_type":"markdown","id":"b51d3369","metadata":{"papermill":{"duration":0.088814,"end_time":"2023-07-03T08:37:07.965052","exception":false,"start_time":"2023-07-03T08:37:07.876238","status":"completed"},"tags":[]},"source":["<br>\n","\n","\n","### fe022_tdcsfog_1000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe022_tdcsfog_1000.ipynb\" style=\"text-decoration:none\">fe022_tdcsfog_1000.ipynb</a>"]},{"cell_type":"code","execution_count":9,"id":"6a8b4f53","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:08.130943Z","iopub.status.busy":"2023-07-03T08:37:08.130552Z","iopub.status.idle":"2023-07-03T08:37:08.135347Z","shell.execute_reply":"2023-07-03T08:37:08.134272Z"},"papermill":{"duration":0.089936,"end_time":"2023-07-03T08:37:08.137954","exception":false,"start_time":"2023-07-03T08:37:08.048018","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler"]},{"cell_type":"code","execution_count":10,"id":"9447781a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:08.296751Z","iopub.status.busy":"2023-07-03T08:37:08.296417Z","iopub.status.idle":"2023-07-03T08:37:08.301789Z","shell.execute_reply":"2023-07-03T08:37:08.300849Z"},"papermill":{"duration":0.086686,"end_time":"2023-07-03T08:37:08.303741","exception":false,"start_time":"2023-07-03T08:37:08.217055","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"022\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":11,"id":"1b1fd200","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:08.459674Z","iopub.status.busy":"2023-07-03T08:37:08.459325Z","iopub.status.idle":"2023-07-03T08:37:08.463577Z","shell.execute_reply":"2023-07-03T08:37:08.462725Z"},"papermill":{"duration":0.085186,"end_time":"2023-07-03T08:37:08.465551","exception":false,"start_time":"2023-07-03T08:37:08.380365","status":"completed"},"tags":[]},"outputs":[],"source":["# TDCSFOG_META_PATH = \"../data/tdcsfog_metadata.csv\"\n","# TDCSFOG_FOLDER = \"../data/train/tdcsfog/*.csv\"      \n","\n","# data_list = glob.glob(TDCSFOG_FOLDER)\n","\n","# data_list\n","\n","# Abrachan: The variable `data_list` is the same as `train_tdcdfog` above."]},{"cell_type":"code","execution_count":12,"id":"9342bf68","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:08.667518Z","iopub.status.busy":"2023-07-03T08:37:08.666844Z","iopub.status.idle":"2023-07-03T08:37:08.739264Z","shell.execute_reply":"2023-07-03T08:37:08.738269Z"},"papermill":{"duration":0.199119,"end_time":"2023-07-03T08:37:08.74146","exception":false,"start_time":"2023-07-03T08:37:08.542341","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Subject</th>\n","      <th>Visit</th>\n","      <th>Test</th>\n","      <th>Medication</th>\n","      <th>Sub_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>003f117e14</td>\n","      <td>4dc2f8</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>009ee11563</td>\n","      <td>f62eec</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>011322847a</td>\n","      <td>231c3b</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01d0fe7266</td>\n","      <td>231c3b</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>024418ba39</td>\n","      <td>fa8764</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>on</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Id Subject  Visit  Test Medication  Sub_id\n","0  003f117e14  4dc2f8      3     2         on       0\n","1  009ee11563  f62eec      4     2         on       1\n","2  011322847a  231c3b      2     2         on       2\n","3  01d0fe7266  231c3b      2     1        off       2\n","4  024418ba39  fa8764     19     3         on       3"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["tdcsfog_metadata = pd.read_parquet(\"./output/fe/fe001/fe001_tdcsfog_meta.parquet\")\n","tdcsfog_metadata.head()"]},{"cell_type":"code","execution_count":13,"id":"1c7ca980","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:08.904522Z","iopub.status.busy":"2023-07-03T08:37:08.903868Z","iopub.status.idle":"2023-07-03T08:37:08.909404Z","shell.execute_reply":"2023-07-03T08:37:08.908561Z"},"papermill":{"duration":0.08607,"end_time":"2023-07-03T08:37:08.911482","exception":false,"start_time":"2023-07-03T08:37:08.825412","status":"completed"},"tags":[]},"outputs":[],"source":["cols       = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols   = ['AccV', 'AccML', 'AccAP',  \n","              'AccV_lag_diff',  'AccV_lead_diff',  'AccV_cumsum', \n","              'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","              'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","target_cols = [\"StartHesitation\",\"Turn\",\"Walking\"]\n","\n","seq_len = 1000\n","shift = 500\n","offset = 250\n","\n","# Abrachan:\n","# https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/416057\n","#     Each Id was split into sequences of a specified length. During training, \n","#     we used a shorter length (e.g., 1000 for tdcsfog, 5000 for defog)\n","#     For tdcsfog, sequences were created by shifting 500 steps from the starting position."]},{"cell_type":"code","execution_count":14,"id":"82f99bd2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:09.06947Z","iopub.status.busy":"2023-07-03T08:37:09.069145Z","iopub.status.idle":"2023-07-03T08:37:09.073854Z","shell.execute_reply":"2023-07-03T08:37:09.072949Z"},"papermill":{"duration":0.086748,"end_time":"2023-07-03T08:37:09.075951","exception":false,"start_time":"2023-07-03T08:37:08.989203","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","subject_list = []\n","id_list = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []"]},{"cell_type":"code","execution_count":15,"id":"435827ee","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:09.234967Z","iopub.status.busy":"2023-07-03T08:37:09.234189Z","iopub.status.idle":"2023-07-03T08:37:42.929318Z","shell.execute_reply":"2023-07-03T08:37:42.927804Z"},"papermill":{"duration":33.77725,"end_time":"2023-07-03T08:37:42.931638","exception":false,"start_time":"2023-07-03T08:37:09.154388","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["tdcsfog_metadata: : 833it [00:33, 24.74it/s]\n"]}],"source":["for i,s in tqdm(zip(tdcsfog_metadata[\"Id\"].values, tdcsfog_metadata[\"Sub_id\"].values), desc=\"tdcsfog_metadata: \"):\n","# for i,s in tqdm(zip(meta[\"Id\"].values, meta[\"sub_id\"].values)):\n","    # path = f\"../data/train/tdcsfog/{i}.csv\"\n","    path = root_data + f\"train/tdcsfog/{i}.csv\"\n","    df = pd.read_csv(path)\n","    \n","    batch = (len(df)-1) // shift    # Abrachan: Why minus 1 here?\n","    \n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    \n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    # for c in num_cols:\n","    #     df[c] = (df[c] - mean_std_dict[c][0]) / mean_std_dict[c][1]\n","    #     df[c] = df[c].fillna(0)\n","    \n","    num    = df[num_cols].values\n","    target = df[target_cols].values\n","    time_values   = df[\"Time\"].values\n","    \n","    num_array_      = np.zeros([batch, seq_len, 12])\n","    target_array_   = np.zeros([batch, seq_len,  3])\n","    time_array_     = np.zeros([batch, seq_len    ], dtype=int)\n","    \n","    mask_array_     = np.zeros([batch, seq_len    ], dtype=int)\n","    pred_use_array_ = np.zeros([batch, seq_len    ], dtype=int)\n","    \n","    \n","    for n,b in enumerate(range(batch)):\n","        if b == (batch - 1):\n","            num_ = num[b*shift : ]\n","            num_array_[b, :len(num_), :] = num_\n","            \n","            target_ = target[b*shift : ]\n","            target_array_[b, :len(target_), :] = target_\n","            \n","            mask_array_[b, :len(target_)] = 1\n","            \n","            pred_use_array_[b, offset:len(target_)] = 1\n","            \n","            time_ = time_values[b*shift : ]\n","            time_array_[b, :len(time_)] = time_\n","            \n","        elif b == 0:\n","            num_ = num[b*shift : b*shift+seq_len]          # [0:1000]\n","            num_array_[b, :, :] = num_\n","            \n","            target_ = target[b*shift : b*shift+seq_len]    # [0:1000]\n","            target_array_[b, :, :] = target_\n","            \n","            mask_array_[b, :] = 1                          # [b, :1000]\n","            \n","            pred_use_array_[b, :offset+shift] = 1          # [b, :750]    <===\n","            \n","            time_ = time_values[b*shift : b*shift+seq_len] # [0:1000]\n","            time_array_[b, :] = time_\n","        \n","        else:\n","            num_ = num[b*shift : b*shift+seq_len]          # for b=1: [500:1500]\n","            num_array_[b, :, :] = num_\n","            \n","            target_ = target[b*shift : b*shift+seq_len]    # for b=1: [500:1500]\n","            target_array_[b, :, :] = target_\n","            \n","            mask_array_[b, :] = 1                          # for b=1: [b, :1000]\n","            \n","            pred_use_array_[b, offset:offset+shift] = 1    # for b=1: [b, 250:750]   <===\n","            \n","            time_ = time_values[b*shift : b*shift+seq_len] # for b=1: [500:1500]\n","            time_array_[b,:] = time_\n","    \n","    \n","    num_array.append(num_array_)\n","    target_array.append(target_array_)\n","    mask_array.append(mask_array_)\n","    pred_use_array.append(pred_use_array_)\n","    time_array.append(time_array_)\n","    \n","    subject_list += [s for _ in range(batch)]     # s is `Sub_id`\n","    id_list      += [i for _ in range(batch)]     # i is `Id`"]},{"cell_type":"code","execution_count":16,"id":"1fa4fbd5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:43.129921Z","iopub.status.busy":"2023-07-03T08:37:43.129553Z","iopub.status.idle":"2023-07-03T08:37:43.742055Z","shell.execute_reply":"2023-07-03T08:37:43.741066Z"},"papermill":{"duration":0.714917,"end_time":"2023-07-03T08:37:43.744784","exception":false,"start_time":"2023-07-03T08:37:43.029867","status":"completed"},"tags":[]},"outputs":[],"source":["num_array      = np.concatenate(num_array, axis=0)\n","target_array   = np.concatenate(target_array, axis=0)\n","mask_array     = np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array     = np.concatenate(time_array, axis=0)"]},{"cell_type":"code","execution_count":17,"id":"1fae1e9a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:43.956325Z","iopub.status.busy":"2023-07-03T08:37:43.955943Z","iopub.status.idle":"2023-07-03T08:37:44.030432Z","shell.execute_reply":"2023-07-03T08:37:44.029445Z"},"papermill":{"duration":0.18923,"end_time":"2023-07-03T08:37:44.032798","exception":false,"start_time":"2023-07-03T08:37:43.843568","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>subject</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13711</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13712</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13713</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13714</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13715</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13716 rows × 2 columns</p>\n","</div>"],"text/plain":["               Id  subject\n","0      003f117e14        0\n","1      003f117e14        0\n","2      003f117e14        0\n","3      003f117e14        0\n","4      003f117e14        0\n","...           ...      ...\n","13711  ffda8fadfd       14\n","13712  ffda8fadfd       14\n","13713  ffda8fadfd       14\n","13714  ffda8fadfd       14\n","13715  ffda8fadfd       14\n","\n","[13716 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id"]},{"cell_type":"code","execution_count":18,"id":"550aac08","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:44.227839Z","iopub.status.busy":"2023-07-03T08:37:44.227507Z","iopub.status.idle":"2023-07-03T08:37:46.613847Z","shell.execute_reply":"2023-07-03T08:37:46.612612Z"},"papermill":{"duration":2.488215,"end_time":"2023-07-03T08:37:46.617838","exception":false,"start_time":"2023-07-03T08:37:44.129623","status":"completed"},"tags":[]},"outputs":[],"source":["np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\",time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)"]},{"cell_type":"code","execution_count":19,"id":"a8d20480","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:46.942852Z","iopub.status.busy":"2023-07-03T08:37:46.942491Z","iopub.status.idle":"2023-07-03T08:37:46.953205Z","shell.execute_reply":"2023-07-03T08:37:46.952268Z"},"papermill":{"duration":0.128032,"end_time":"2023-07-03T08:37:46.955538","exception":false,"start_time":"2023-07-03T08:37:46.827506","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"7fe0d6d8","metadata":{"papermill":{"duration":0.104567,"end_time":"2023-07-03T08:37:47.167546","exception":false,"start_time":"2023-07-03T08:37:47.062979","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>**Training**</font>"]},{"cell_type":"markdown","id":"508a51c2","metadata":{"papermill":{"duration":0.111542,"end_time":"2023-07-03T08:37:47.387751","exception":false,"start_time":"2023-07-03T08:37:47.276209","status":"completed"},"tags":[]},"source":["<br>\n","\n","Code below is common for the tdcsfog notebooks whose names start with \"ex\", for example: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex143_tdcsfog_gru.ipynb\" style=\"text-decoration:none\">ex143_tdcsfog_gru.ipynb</a>\n","\n","<br>"]},{"cell_type":"code","execution_count":20,"id":"9f7718f0","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:47.651145Z","iopub.status.busy":"2023-07-03T08:37:47.650478Z","iopub.status.idle":"2023-07-03T08:37:47.658541Z","shell.execute_reply":"2023-07-03T08:37:47.656766Z"},"papermill":{"duration":0.161952,"end_time":"2023-07-03T08:37:47.662545","exception":false,"start_time":"2023-07-03T08:37:47.500593","status":"completed"},"tags":[]},"outputs":[],"source":["TRAIN_FLAG_TDCSFOG = True"]},{"cell_type":"markdown","id":"8152fb10","metadata":{"papermill":{"duration":0.128132,"end_time":"2023-07-03T08:37:48.01884","exception":false,"start_time":"2023-07-03T08:37:47.890708","status":"completed"},"tags":[]},"source":["<br>\n","\n","### helpers\n","\n","<br>\n","\n","#### def `set_seed()`"]},{"cell_type":"code","execution_count":21,"id":"048da868","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:48.239307Z","iopub.status.busy":"2023-07-03T08:37:48.238943Z","iopub.status.idle":"2023-07-03T08:37:48.246184Z","shell.execute_reply":"2023-07-03T08:37:48.24519Z"},"papermill":{"duration":0.119176,"end_time":"2023-07-03T08:37:48.248378","exception":false,"start_time":"2023-07-03T08:37:48.129202","status":"completed"},"tags":[]},"outputs":[],"source":["def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","id":"18f06778","metadata":{"papermill":{"duration":0.1069,"end_time":"2023-07-03T08:37:48.464123","exception":false,"start_time":"2023-07-03T08:37:48.357223","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `init_logger()`"]},{"cell_type":"code","execution_count":22,"id":"b0250ad4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:48.697984Z","iopub.status.busy":"2023-07-03T08:37:48.69759Z","iopub.status.idle":"2023-07-03T08:37:48.704922Z","shell.execute_reply":"2023-07-03T08:37:48.703484Z"},"papermill":{"duration":0.12705,"end_time":"2023-07-03T08:37:48.70753","exception":false,"start_time":"2023-07-03T08:37:48.58048","status":"completed"},"tags":[]},"outputs":[],"source":["def init_logger(log_file):\n","    \n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    \n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    \n","    return logger\n","\n","\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"22f5fdf4","metadata":{"papermill":{"duration":0.12414,"end_time":"2023-07-03T08:37:48.945006","exception":false,"start_time":"2023-07-03T08:37:48.820866","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `timer()`"]},{"cell_type":"code","execution_count":23,"id":"59ba7d9e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:49.174625Z","iopub.status.busy":"2023-07-03T08:37:49.17412Z","iopub.status.idle":"2023-07-03T08:37:49.18477Z","shell.execute_reply":"2023-07-03T08:37:49.183657Z"},"papermill":{"duration":0.128358,"end_time":"2023-07-03T08:37:49.186922","exception":false,"start_time":"2023-07-03T08:37:49.058564","status":"completed"},"tags":[]},"outputs":[],"source":["@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    \n","    yield \n","    # LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(\"=\"*66)\n","    print(\"\\n\"*2)\n","    \n","# setup_logger(out_file=logger_path)"]},{"cell_type":"markdown","id":"19c34f42","metadata":{"papermill":{"duration":0.107607,"end_time":"2023-07-03T08:37:49.398103","exception":false,"start_time":"2023-07-03T08:37:49.290496","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `preprocess()`"]},{"cell_type":"code","execution_count":24,"id":"989e96a0","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:49.609059Z","iopub.status.busy":"2023-07-03T08:37:49.60803Z","iopub.status.idle":"2023-07-03T08:37:49.613917Z","shell.execute_reply":"2023-07-03T08:37:49.612955Z"},"papermill":{"duration":0.114432,"end_time":"2023-07-03T08:37:49.615956","exception":false,"start_time":"2023-07-03T08:37:49.501524","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array,):\n","    \n","    attention_mask = (mask_array == 0)\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"67460931","metadata":{"papermill":{"duration":0.118515,"end_time":"2023-07-03T08:37:49.848701","exception":false,"start_time":"2023-07-03T08:37:49.730186","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogDataset()`"]},{"cell_type":"code","execution_count":25,"id":"b41e7a2d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:50.094865Z","iopub.status.busy":"2023-07-03T08:37:50.094459Z","iopub.status.idle":"2023-07-03T08:37:50.107444Z","shell.execute_reply":"2023-07-03T08:37:50.106328Z"},"papermill":{"duration":0.13664,"end_time":"2023-07-03T08:37:50.110083","exception":false,"start_time":"2023-07-03T08:37:49.973443","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.train = train\n","        self.y = y\n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","\n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item],)\n","        \n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array'     : torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","              'attention_mask'            : torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\"                         : torch.tensor(self.y[item], dtype=torch.float32)\n","               }\n","        else:\n","            return {\n","                'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","                'input_data_mask_array'     : torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","                'attention_mask'            : torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"da0c0b5c","metadata":{"papermill":{"duration":0.114157,"end_time":"2023-07-03T08:37:50.344441","exception":false,"start_time":"2023-07-03T08:37:50.230284","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":26,"id":"258e087e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:50.61913Z","iopub.status.busy":"2023-07-03T08:37:50.618739Z","iopub.status.idle":"2023-07-03T08:37:50.632841Z","shell.execute_reply":"2023-07-03T08:37:50.631915Z"},"papermill":{"duration":0.130806,"end_time":"2023-07-03T08:37:50.635018","exception":false,"start_time":"2023-07-03T08:37:50.504212","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=12,        # len(num_cols) = 12\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        # input shape : [batch, seq_len, len(num_cols)]            ->  [24, 1000, 12]\n","        # output shape: [batch, seq_len, numeraical_linear_size]   ->  [24, 1000, 64]\n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size)\n","                                              )\n","        \n","        # input shape : [batch, seq_len, numeraical_linear_size]   ->  [24, 1000, 64]\n","        # h_0 shape   : [D∗num_layers, batch, hidden_size]         ->  [2*2, 24, 128]\n","        # output shape: [batch, seq_len, D*hidden_size]            ->  [24,1000, 128*2]\n","        self.rnn = nn.GRU(numeraical_linear_size,    # input_size – The number of expected features in the input x\n","                          model_size,                # hidden_size – The number of features in the hidden state h\n","                          num_layers = 2,            # num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two GRUs together to form a stacked GRU\n","                          batch_first=True,          # If True, the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature).\n","                          bidirectional=True)\n","        \n","        # input shape : [batch, seq_len, D*hidden_size]  ->  [24, 1000, 128*2]\n","        # output shape: [batch, seq_len, linear_out]     ->  [24, 1000, 3]\n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),    # [128*2, 3]\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size)\n","                                        )\n","        self._reinitialize()\n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","    \n","    \n","    def forward(self, numerical_array, mask_array, attention_mask):        \n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _           = self.rnn(numerical_embedding)\n","        output              = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"302eb6c4","metadata":{"papermill":{"duration":0.107929,"end_time":"2023-07-03T08:37:50.849702","exception":false,"start_time":"2023-07-03T08:37:50.741773","status":"completed"},"tags":[]},"source":["<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":27,"id":"631ce765","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:51.068613Z","iopub.status.busy":"2023-07-03T08:37:51.068229Z","iopub.status.idle":"2023-07-03T08:37:52.060053Z","shell.execute_reply":"2023-07-03T08:37:52.054884Z"},"papermill":{"duration":1.102214,"end_time":"2023-07-03T08:37:52.065407","exception":false,"start_time":"2023-07-03T08:37:50.963193","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe022/fe022_id.parquet\"\n","\n","numerical_path = f\"./output/fe/fe022/fe022_num_array.npy\"\n","target_path    = f\"./output/fe/fe022/fe022_target_array.npy\"\n","mask_path      = f\"./output/fe/fe022/fe022_mask_array.npy\"\n","pred_use_path  = f\"./output/fe/fe022/fe022_pred_use_array.npy\"\n","\n","\n","df_id           = pd.read_parquet(id_path)\n","\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","pred_use_array  = np.load(pred_use_path)"]},{"cell_type":"code","execution_count":28,"id":"fa286795","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:52.282159Z","iopub.status.busy":"2023-07-03T08:37:52.281139Z","iopub.status.idle":"2023-07-03T08:37:52.643517Z","shell.execute_reply":"2023-07-03T08:37:52.642303Z"},"papermill":{"duration":0.474331,"end_time":"2023-07-03T08:37:52.64619","exception":false,"start_time":"2023-07-03T08:37:52.171859","status":"completed"},"tags":[]},"outputs":[],"source":["target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i, :, 0]))\n","    target2.append(np.sum(target_array[i, :, 1]))\n","    target3.append(np.sum(target_array[i, :, 2]))"]},{"cell_type":"code","execution_count":29,"id":"f4c635cd","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:52.86392Z","iopub.status.busy":"2023-07-03T08:37:52.863547Z","iopub.status.idle":"2023-07-03T08:37:52.888228Z","shell.execute_reply":"2023-07-03T08:37:52.887301Z"},"papermill":{"duration":0.136868,"end_time":"2023-07-03T08:37:52.890336","exception":false,"start_time":"2023-07-03T08:37:52.753468","status":"completed"},"tags":[]},"outputs":[],"source":["df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)"]},{"cell_type":"code","execution_count":30,"id":"e2de2b86","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:53.108084Z","iopub.status.busy":"2023-07-03T08:37:53.106246Z","iopub.status.idle":"2023-07-03T08:37:53.116578Z","shell.execute_reply":"2023-07-03T08:37:53.115674Z"},"papermill":{"duration":0.1249,"end_time":"2023-07-03T08:37:53.118874","exception":false,"start_time":"2023-07-03T08:37:52.993974","status":"completed"},"tags":[]},"outputs":[],"source":["df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3"]},{"cell_type":"code","execution_count":31,"id":"dfb16706","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:53.327029Z","iopub.status.busy":"2023-07-03T08:37:53.326637Z","iopub.status.idle":"2023-07-03T08:37:53.337923Z","shell.execute_reply":"2023-07-03T08:37:53.337084Z"},"papermill":{"duration":0.115346,"end_time":"2023-07-03T08:37:53.33984","exception":false,"start_time":"2023-07-03T08:37:53.224494","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    7720\n","1    4604\n","2     782\n","3     610\n","Name: group, dtype: int64"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df_id[\"group\"].value_counts()"]},{"cell_type":"markdown","id":"8011840e","metadata":{"papermill":{"duration":0.098987,"end_time":"2023-07-03T08:37:53.537972","exception":false,"start_time":"2023-07-03T08:37:53.438985","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":32,"id":"674508bb","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:53.741322Z","iopub.status.busy":"2023-07-03T08:37:53.740092Z","iopub.status.idle":"2023-07-03T08:37:53.83637Z","shell.execute_reply":"2023-07-03T08:37:53.835384Z"},"papermill":{"duration":0.201436,"end_time":"2023-07-03T08:37:53.838974","exception":false,"start_time":"2023-07-03T08:37:53.637538","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 10\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"6f7d1f90","metadata":{"papermill":{"duration":0.102783,"end_time":"2023-07-03T08:37:54.044642","exception":false,"start_time":"2023-07-03T08:37:53.941859","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>**ex143_tdcsfog_gru.ipynb**</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex143_tdcsfog_gru.ipynb\" style=\"text-decoration:none\">ex143_tdcsfog_gru.ipynb</a>"]},{"cell_type":"code","execution_count":33,"id":"765c57be","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:54.247988Z","iopub.status.busy":"2023-07-03T08:37:54.246152Z","iopub.status.idle":"2023-07-03T08:37:54.254283Z","shell.execute_reply":"2023-07-03T08:37:54.253336Z"},"papermill":{"duration":0.110462,"end_time":"2023-07-03T08:37:54.256502","exception":false,"start_time":"2023-07-03T08:37:54.14604","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","\n","ex = \"143_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","    \n","logger_path = f\"./output/exp/ex{ex}/log_ex_{ex}.txt\"\n","LOGGER = init_logger(log_file=logger_path)\n","\n","# model_path  = f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}.pth\""]},{"cell_type":"markdown","id":"4a768b75","metadata":{"papermill":{"duration":0.099091,"end_time":"2023-07-03T08:37:54.454204","exception":false,"start_time":"2023-07-03T08:37:54.355113","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":34,"id":"17c5bda2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:54.65557Z","iopub.status.busy":"2023-07-03T08:37:54.655213Z","iopub.status.idle":"2023-07-03T08:37:54.679755Z","shell.execute_reply":"2023-07-03T08:37:54.678765Z"},"papermill":{"duration":0.130601,"end_time":"2023-07-03T08:37:54.682642","exception":false,"start_time":"2023-07-03T08:37:54.552041","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 10 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold: {fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"d9b37670","metadata":{"papermill":{"duration":0.100927,"end_time":"2023-07-03T08:37:54.885765","exception":false,"start_time":"2023-07-03T08:37:54.784838","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":35,"id":"7bfebdd2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:55.087949Z","iopub.status.busy":"2023-07-03T08:37:55.087003Z","iopub.status.idle":"2023-07-03T08:37:55.094391Z","shell.execute_reply":"2023-07-03T08:37:55.093534Z"},"papermill":{"duration":0.110776,"end_time":"2023-07-03T08:37:55.096372","exception":false,"start_time":"2023-07-03T08:37:54.985596","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","\n","\n","\n","    # kaggle_json = {\"title\": f\"fog-ex{ex}\",\n","    #                \"id\": f\"takoihiraokazu/fog-ex{ex}\",\n","    #                \"licenses\": [{\"name\": \"CC0-1.0\"}]}\n","\n","    # with open(f\"./output/exp/ex{ex}/ex{ex}_model/dataset-metadata.json\", 'w') as f:\n","    #     json.dump(kaggle_json, f)\n","\n","\n","    # del LOGGER\n","    # gc.collect()\n","    # logging.shutdown()"]},{"cell_type":"markdown","id":"8236669d","metadata":{"papermill":{"duration":0.1067,"end_time":"2023-07-03T08:37:55.304455","exception":false,"start_time":"2023-07-03T08:37:55.197755","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex145_tdcsfog_gru_StartHesitation.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex145_tdcsfog_gru_StartHesitation.ipynb\" style=\"text-decoration:none\">ex145_tdcsfog_gru_StartHesitation.ipynb</a>"]},{"cell_type":"code","execution_count":36,"id":"c3b15db5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:55.521385Z","iopub.status.busy":"2023-07-03T08:37:55.520375Z","iopub.status.idle":"2023-07-03T08:37:55.526832Z","shell.execute_reply":"2023-07-03T08:37:55.525807Z"},"papermill":{"duration":0.117339,"end_time":"2023-07-03T08:37:55.529052","exception":false,"start_time":"2023-07-03T08:37:55.411713","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","\n","ex = \"145_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","    \n","# logger_path = f\"./output/exp/ex{ex}/log_ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"c87b2827","metadata":{"papermill":{"duration":0.099594,"end_time":"2023-07-03T08:37:55.731699","exception":false,"start_time":"2023-07-03T08:37:55.632105","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":37,"id":"610bfb2d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:55.932285Z","iopub.status.busy":"2023-07-03T08:37:55.931942Z","iopub.status.idle":"2023-07-03T08:37:55.958468Z","shell.execute_reply":"2023-07-03T08:37:55.955124Z"},"papermill":{"duration":0.128793,"end_time":"2023-07-03T08:37:55.961645","exception":false,"start_time":"2023-07-03T08:37:55.832852","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n","Wall time: 8.11 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold:{fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, 0    ]\n","                    output2 = output[:, :, [1,2]]\n","                    y1 = y[:, :, 0    ]\n","                    y2 = y[:, :, [1,2]]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.6 + loss2*0.4\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"61a2ead5","metadata":{"papermill":{"duration":0.104816,"end_time":"2023-07-03T08:37:56.166452","exception":false,"start_time":"2023-07-03T08:37:56.061636","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":38,"id":"849a00a4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:56.457633Z","iopub.status.busy":"2023-07-03T08:37:56.457135Z","iopub.status.idle":"2023-07-03T08:37:56.465704Z","shell.execute_reply":"2023-07-03T08:37:56.46487Z"},"papermill":{"duration":0.171932,"end_time":"2023-07-03T08:37:56.473342","exception":false,"start_time":"2023-07-03T08:37:56.30141","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","\n","\n","\n","    # kaggle_json = {\"title\": f\"fog-ex{ex}\",\n","    #                \"id\": f\"takoihiraokazu/fog-ex{ex}\",\n","    #                \"licenses\": [{\"name\": \"CC0-1.0\"}]}\n","\n","    # with open(f\"./output/exp/ex{ex}/ex{ex}_model/dataset-metadata.json\", 'w') as f:\n","    #     json.dump(kaggle_json, f)\n","\n","\n","    # del LOGGER\n","    # gc.collect()"]},{"cell_type":"markdown","id":"3b20885c","metadata":{"papermill":{"duration":0.149269,"end_time":"2023-07-03T08:37:56.774413","exception":false,"start_time":"2023-07-03T08:37:56.625144","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex146_tdcsfog_gru_Turn.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex146_tdcsfog_gru_Turn.ipynb\" style=\"text-decoration:none\">ex146_tdcsfog_gru_Turn.ipynb</a>"]},{"cell_type":"code","execution_count":39,"id":"ccaa8230","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:57.07723Z","iopub.status.busy":"2023-07-03T08:37:57.076804Z","iopub.status.idle":"2023-07-03T08:37:57.083872Z","shell.execute_reply":"2023-07-03T08:37:57.083063Z"},"papermill":{"duration":0.166411,"end_time":"2023-07-03T08:37:57.08641","exception":false,"start_time":"2023-07-03T08:37:56.919999","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"146_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"1acca73f","metadata":{"papermill":{"duration":0.148374,"end_time":"2023-07-03T08:37:57.377497","exception":false,"start_time":"2023-07-03T08:37:57.229123","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":40,"id":"dc1bfb93","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:57.68121Z","iopub.status.busy":"2023-07-03T08:37:57.680766Z","iopub.status.idle":"2023-07-03T08:37:57.735068Z","shell.execute_reply":"2023-07-03T08:37:57.732952Z"},"papermill":{"duration":0.218535,"end_time":"2023-07-03T08:37:57.738795","exception":false,"start_time":"2023-07-03T08:37:57.52026","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 10.7 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, 1    ]\n","                    output2 = output[:, :, [0,2]]\n","                    y1 = y[:, :, 1    ]\n","                    y2 = y[:, :, [0,2]]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.6 + loss2*0.4\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"db9305a5","metadata":{"papermill":{"duration":0.099837,"end_time":"2023-07-03T08:37:57.998521","exception":false,"start_time":"2023-07-03T08:37:57.898684","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":41,"id":"aeef9545","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:58.197478Z","iopub.status.busy":"2023-07-03T08:37:58.197106Z","iopub.status.idle":"2023-07-03T08:37:58.203484Z","shell.execute_reply":"2023-07-03T08:37:58.202633Z"},"papermill":{"duration":0.108574,"end_time":"2023-07-03T08:37:58.205486","exception":false,"start_time":"2023-07-03T08:37:58.096912","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"24096850","metadata":{"papermill":{"duration":0.097082,"end_time":"2023-07-03T08:37:58.402034","exception":false,"start_time":"2023-07-03T08:37:58.304952","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex147_tdcsfog_gru_Walking.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex147_tdcsfog_gru_Walking.ipynb\" style=\"text-decoration:none\">ex147_tdcsfog_gru_Walking.ipynb</a>"]},{"cell_type":"code","execution_count":42,"id":"61f7ec26","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:58.646084Z","iopub.status.busy":"2023-07-03T08:37:58.645119Z","iopub.status.idle":"2023-07-03T08:37:58.650876Z","shell.execute_reply":"2023-07-03T08:37:58.650023Z"},"papermill":{"duration":0.152501,"end_time":"2023-07-03T08:37:58.65302","exception":false,"start_time":"2023-07-03T08:37:58.500519","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"147_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"3428a764","metadata":{"papermill":{"duration":0.099802,"end_time":"2023-07-03T08:37:58.85319","exception":false,"start_time":"2023-07-03T08:37:58.753388","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":43,"id":"dd94d037","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:59.060648Z","iopub.status.busy":"2023-07-03T08:37:59.0603Z","iopub.status.idle":"2023-07-03T08:37:59.084492Z","shell.execute_reply":"2023-07-03T08:37:59.083594Z"},"papermill":{"duration":0.134435,"end_time":"2023-07-03T08:37:59.086786","exception":false,"start_time":"2023-07-03T08:37:58.952351","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 8.58 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, 2    ]\n","                    output2 = output[:, :, [0,1]]\n","                    y1 = y[:, :, 2    ]\n","                    y2 = y[:, :, [0,1]]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.6 + loss2*0.4\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"212de2fe","metadata":{"papermill":{"duration":0.100657,"end_time":"2023-07-03T08:37:59.285","exception":false,"start_time":"2023-07-03T08:37:59.184343","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":44,"id":"78052e95","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:59.493516Z","iopub.status.busy":"2023-07-03T08:37:59.493147Z","iopub.status.idle":"2023-07-03T08:37:59.499861Z","shell.execute_reply":"2023-07-03T08:37:59.498954Z"},"papermill":{"duration":0.109177,"end_time":"2023-07-03T08:37:59.502073","exception":false,"start_time":"2023-07-03T08:37:59.392896","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n"]},{"cell_type":"markdown","id":"f27518e8","metadata":{"papermill":{"duration":0.097298,"end_time":"2023-07-03T08:37:59.699045","exception":false,"start_time":"2023-07-03T08:37:59.601747","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex182_tdcsfog_gru_StartHesitation_Turn.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex182_tdcsfog_gru_StartHesitation_Turn.ipynb\" style=\"text-decoration:none\">ex182_tdcsfog_gru_StartHesitation_Turn.ipynb</a>"]},{"cell_type":"code","execution_count":45,"id":"54de866b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:37:59.89753Z","iopub.status.busy":"2023-07-03T08:37:59.897179Z","iopub.status.idle":"2023-07-03T08:37:59.903053Z","shell.execute_reply":"2023-07-03T08:37:59.902043Z"},"papermill":{"duration":0.107242,"end_time":"2023-07-03T08:37:59.905069","exception":false,"start_time":"2023-07-03T08:37:59.797827","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"182_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"66c0e984","metadata":{"papermill":{"duration":0.099115,"end_time":"2023-07-03T08:38:00.104128","exception":false,"start_time":"2023-07-03T08:38:00.005013","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":46,"id":"86bfa3da","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:00.305421Z","iopub.status.busy":"2023-07-03T08:38:00.305051Z","iopub.status.idle":"2023-07-03T08:38:00.329779Z","shell.execute_reply":"2023-07-03T08:38:00.328854Z"},"papermill":{"duration":0.130192,"end_time":"2023-07-03T08:38:00.331842","exception":false,"start_time":"2023-07-03T08:38:00.20165","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 9.3 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, [0,1]]\n","                    output2 = output[:, :, 2]\n","                    y1 = y[:, :, [0,1]]\n","                    y2 = y[:, :, 2]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.8 + loss2*0.2\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"37790239","metadata":{"papermill":{"duration":0.099368,"end_time":"2023-07-03T08:38:00.531141","exception":false,"start_time":"2023-07-03T08:38:00.431773","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":47,"id":"cca6dc79","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:00.733483Z","iopub.status.busy":"2023-07-03T08:38:00.733121Z","iopub.status.idle":"2023-07-03T08:38:00.739758Z","shell.execute_reply":"2023-07-03T08:38:00.73878Z"},"papermill":{"duration":0.111465,"end_time":"2023-07-03T08:38:00.741972","exception":false,"start_time":"2023-07-03T08:38:00.630507","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"93f69bfe","metadata":{"papermill":{"duration":0.100145,"end_time":"2023-07-03T08:38:00.948144","exception":false,"start_time":"2023-07-03T08:38:00.847999","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex183_tdcsfog_gru_StartHesitation_Walking.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex183_tdcsfog_gru_StartHesitation_Walking.ipynb\" style=\"text-decoration:none\">ex183_tdcsfog_gru_StartHesitation_Walking.ipynb</a>"]},{"cell_type":"code","execution_count":48,"id":"b7942f7d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:01.152777Z","iopub.status.busy":"2023-07-03T08:38:01.152433Z","iopub.status.idle":"2023-07-03T08:38:01.158442Z","shell.execute_reply":"2023-07-03T08:38:01.157356Z"},"papermill":{"duration":0.110119,"end_time":"2023-07-03T08:38:01.160492","exception":false,"start_time":"2023-07-03T08:38:01.050373","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"183_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"345a2cbf","metadata":{"papermill":{"duration":0.106174,"end_time":"2023-07-03T08:38:01.36697","exception":false,"start_time":"2023-07-03T08:38:01.260796","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":49,"id":"7b629119","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:01.588666Z","iopub.status.busy":"2023-07-03T08:38:01.588292Z","iopub.status.idle":"2023-07-03T08:38:01.616956Z","shell.execute_reply":"2023-07-03T08:38:01.61593Z"},"papermill":{"duration":0.148469,"end_time":"2023-07-03T08:38:01.619352","exception":false,"start_time":"2023-07-03T08:38:01.470883","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n","Wall time: 9.78 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, [0,2]]\n","                    output2 = output[:, :, 1]\n","                    y1 = y[:, :, [0,2]]\n","                    y2 = y[:, :, 1]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.8 + loss2*0.2\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"9e3c6219","metadata":{"papermill":{"duration":0.099353,"end_time":"2023-07-03T08:38:01.83336","exception":false,"start_time":"2023-07-03T08:38:01.734007","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":50,"id":"d3a6cbb8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:02.033411Z","iopub.status.busy":"2023-07-03T08:38:02.033067Z","iopub.status.idle":"2023-07-03T08:38:02.039654Z","shell.execute_reply":"2023-07-03T08:38:02.038799Z"},"papermill":{"duration":0.110157,"end_time":"2023-07-03T08:38:02.041637","exception":false,"start_time":"2023-07-03T08:38:01.93148","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"64df46a0","metadata":{"papermill":{"duration":0.1006,"end_time":"2023-07-03T08:38:02.240444","exception":false,"start_time":"2023-07-03T08:38:02.139844","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex184_tdcsfog_gru_Turn_Walking.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex184_tdcsfog_gru_Turn_Walking.ipynb\" style=\"text-decoration:none\">ex184_tdcsfog_gru_Turn_Walking.ipynb</a>"]},{"cell_type":"code","execution_count":51,"id":"8437b2f1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:02.454643Z","iopub.status.busy":"2023-07-03T08:38:02.45365Z","iopub.status.idle":"2023-07-03T08:38:02.459979Z","shell.execute_reply":"2023-07-03T08:38:02.459077Z"},"papermill":{"duration":0.116751,"end_time":"2023-07-03T08:38:02.462167","exception":false,"start_time":"2023-07-03T08:38:02.345416","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"184_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"18055df4","metadata":{"papermill":{"duration":0.105858,"end_time":"2023-07-03T08:38:02.673365","exception":false,"start_time":"2023-07-03T08:38:02.567507","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":52,"id":"18b02fec","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:02.890609Z","iopub.status.busy":"2023-07-03T08:38:02.890259Z","iopub.status.idle":"2023-07-03T08:38:02.915391Z","shell.execute_reply":"2023-07-03T08:38:02.914142Z"},"papermill":{"duration":0.128326,"end_time":"2023-07-03T08:38:02.917447","exception":false,"start_time":"2023-07-03T08:38:02.789121","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n","Wall time: 8.58 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, [1,2]]\n","                    output2 = output[:, :, 0]\n","                    y1 = y[:, :, [1,2]]\n","                    y2 = y[:, :, 0]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.8 + loss2*0.2\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"16377dd2","metadata":{"papermill":{"duration":0.101297,"end_time":"2023-07-03T08:38:03.117473","exception":false,"start_time":"2023-07-03T08:38:03.016176","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":53,"id":"01e98773","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:03.32295Z","iopub.status.busy":"2023-07-03T08:38:03.321863Z","iopub.status.idle":"2023-07-03T08:38:03.328522Z","shell.execute_reply":"2023-07-03T08:38:03.327924Z"},"papermill":{"duration":0.110161,"end_time":"2023-07-03T08:38:03.330455","exception":false,"start_time":"2023-07-03T08:38:03.220294","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"fbe678e0","metadata":{"papermill":{"duration":0.100057,"end_time":"2023-07-03T08:38:03.528011","exception":false,"start_time":"2023-07-03T08:38:03.427954","status":"completed"},"tags":[]},"source":["<br>\n","\n","## **models choosed**\n","\n","<br>\n","\n","<font color=maroon size=5>All models above were used for final submission.</font>"]},{"cell_type":"markdown","id":"bf3ec20e","metadata":{"papermill":{"duration":0.09786,"end_time":"2023-07-03T08:38:03.733639","exception":false,"start_time":"2023-07-03T08:38:03.635779","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","# **defog** 【Training】\n","\n","<br>\n","\n","## **Feature Engineering**\n","\n","\n","### fe039_defog_base_feature\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe039_defog_base_feature.ipynb\" style=\"text-decoration:none\">fe039_defog_base_feature.ipynb</a>"]},{"cell_type":"code","execution_count":54,"id":"fe6c8c1e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:03.935385Z","iopub.status.busy":"2023-07-03T08:38:03.935038Z","iopub.status.idle":"2023-07-03T08:38:03.940213Z","shell.execute_reply":"2023-07-03T08:38:03.939197Z"},"papermill":{"duration":0.109337,"end_time":"2023-07-03T08:38:03.942159","exception":false,"start_time":"2023-07-03T08:38:03.832822","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"039\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":55,"id":"221b2a0e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:04.152658Z","iopub.status.busy":"2023-07-03T08:38:04.15232Z","iopub.status.idle":"2023-07-03T08:38:04.157684Z","shell.execute_reply":"2023-07-03T08:38:04.156667Z"},"papermill":{"duration":0.114003,"end_time":"2023-07-03T08:38:04.159772","exception":false,"start_time":"2023-07-03T08:38:04.045769","status":"completed"},"tags":[]},"outputs":[],"source":["sub_dict = {}\n","for n,i in enumerate(defog_metadata[\"Subject\"].unique()):\n","    sub_dict[i] = n"]},{"cell_type":"code","execution_count":56,"id":"b600c6ac","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:04.363567Z","iopub.status.busy":"2023-07-03T08:38:04.363223Z","iopub.status.idle":"2023-07-03T08:38:04.379867Z","shell.execute_reply":"2023-07-03T08:38:04.378794Z"},"papermill":{"duration":0.120528,"end_time":"2023-07-03T08:38:04.382085","exception":false,"start_time":"2023-07-03T08:38:04.261557","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Subject</th>\n","      <th>Visit</th>\n","      <th>Medication</th>\n","      <th>sub_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>02ab235146</td>\n","      <td>e1f62e</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>02ea782681</td>\n","      <td>ae2d35</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>06414383cf</td>\n","      <td>8c1f5e</td>\n","      <td>2</td>\n","      <td>off</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>092b4c1819</td>\n","      <td>2874c5</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0a900ed8a2</td>\n","      <td>0e3d49</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>f3a921edee</td>\n","      <td>1a778d</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>f40e8c6ebe</td>\n","      <td>575c60</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>f8ddbdd98d</td>\n","      <td>107712</td>\n","      <td>1</td>\n","      <td>on</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>f9efef91fb</td>\n","      <td>5d9cae</td>\n","      <td>2</td>\n","      <td>off</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>f9fc61ce85</td>\n","      <td>040587</td>\n","      <td>1</td>\n","      <td>on</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>137 rows × 5 columns</p>\n","</div>"],"text/plain":["             Id Subject  Visit Medication  sub_id\n","0    02ab235146  e1f62e      2         on       0\n","1    02ea782681  ae2d35      2         on       1\n","2    06414383cf  8c1f5e      2        off       2\n","3    092b4c1819  2874c5      1        off       3\n","4    0a900ed8a2  0e3d49      2         on       4\n","..          ...     ...    ...        ...     ...\n","132  f3a921edee  1a778d      1        off       8\n","133  f40e8c6ebe  575c60      1        off      38\n","134  f8ddbdd98d  107712      1         on      39\n","135  f9efef91fb  5d9cae      2        off      44\n","136  f9fc61ce85  040587      1         on      21\n","\n","[137 rows x 5 columns]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["defog_metadata[\"sub_id\"] = defog_metadata[\"Subject\"].map(sub_dict)\n","defog_metadata"]},{"cell_type":"code","execution_count":57,"id":"d6e624ce","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:04.602361Z","iopub.status.busy":"2023-07-03T08:38:04.601291Z","iopub.status.idle":"2023-07-03T08:38:04.60764Z","shell.execute_reply":"2023-07-03T08:38:04.606525Z"},"papermill":{"duration":0.11899,"end_time":"2023-07-03T08:38:04.609803","exception":false,"start_time":"2023-07-03T08:38:04.490813","status":"completed"},"tags":[]},"outputs":[],"source":["with open(f'./output/fe/fe{fe}/fe{fe}_sub_id.pkl', 'wb') as p:\n","    pickle.dump(sub_dict, p)"]},{"cell_type":"code","execution_count":58,"id":"b8b87fa5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:04.818751Z","iopub.status.busy":"2023-07-03T08:38:04.818408Z","iopub.status.idle":"2023-07-03T08:38:04.822693Z","shell.execute_reply":"2023-07-03T08:38:04.821724Z"},"papermill":{"duration":0.108006,"end_time":"2023-07-03T08:38:04.824848","exception":false,"start_time":"2023-07-03T08:38:04.716842","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/defog/*.csv\"\n","\n","# meta = pd.read_csv(DEFOG_META_PATH)\n","# data_list = glob.glob(DEFOG_FOLDER)"]},{"cell_type":"code","execution_count":59,"id":"7dd60525","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:05.027262Z","iopub.status.busy":"2023-07-03T08:38:05.026333Z","iopub.status.idle":"2023-07-03T08:38:30.659453Z","shell.execute_reply":"2023-07-03T08:38:30.658364Z"},"papermill":{"duration":25.737523,"end_time":"2023-07-03T08:38:30.662206","exception":false,"start_time":"2023-07-03T08:38:04.924683","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [00:21<00:00,  4.24it/s]\n"]}],"source":["df_all = []\n","for i in tqdm(train_defog):\n","    df = pd.read_csv(i)\n","    df_all.append(df)\n","df_all = pd.concat(df_all).reset_index(drop=True)\n","\n","# len(df_all)"]},{"cell_type":"code","execution_count":60,"id":"7f1e0de1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:30.89962Z","iopub.status.busy":"2023-07-03T08:38:30.899234Z","iopub.status.idle":"2023-07-03T08:38:30.919424Z","shell.execute_reply":"2023-07-03T08:38:30.9182Z"},"papermill":{"duration":0.13804,"end_time":"2023-07-03T08:38:30.922148","exception":false,"start_time":"2023-07-03T08:38:30.784108","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>AccV</th>\n","      <th>AccML</th>\n","      <th>AccAP</th>\n","      <th>StartHesitation</th>\n","      <th>Turn</th>\n","      <th>Walking</th>\n","      <th>Valid</th>\n","      <th>Task</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-1.002697</td>\n","      <td>0.022371</td>\n","      <td>0.068304</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>-1.002641</td>\n","      <td>0.019173</td>\n","      <td>0.066162</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-0.999820</td>\n","      <td>0.019142</td>\n","      <td>0.067536</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>-0.998023</td>\n","      <td>0.018378</td>\n","      <td>0.068409</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-0.998359</td>\n","      <td>0.016726</td>\n","      <td>0.066448</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13525697</th>\n","      <td>109120</td>\n","      <td>-0.939241</td>\n","      <td>0.031564</td>\n","      <td>-0.394737</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525698</th>\n","      <td>109121</td>\n","      <td>-0.941096</td>\n","      <td>0.031582</td>\n","      <td>-0.392626</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525699</th>\n","      <td>109122</td>\n","      <td>-0.940131</td>\n","      <td>0.029092</td>\n","      <td>-0.394385</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525700</th>\n","      <td>109123</td>\n","      <td>-0.939872</td>\n","      <td>0.028058</td>\n","      <td>-0.398664</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525701</th>\n","      <td>109124</td>\n","      <td>-0.939006</td>\n","      <td>0.026628</td>\n","      <td>-0.398454</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13525702 rows × 9 columns</p>\n","</div>"],"text/plain":["            Time      AccV     AccML     AccAP  StartHesitation  Turn  \\\n","0              0 -1.002697  0.022371  0.068304                0     0   \n","1              1 -1.002641  0.019173  0.066162                0     0   \n","2              2 -0.999820  0.019142  0.067536                0     0   \n","3              3 -0.998023  0.018378  0.068409                0     0   \n","4              4 -0.998359  0.016726  0.066448                0     0   \n","...          ...       ...       ...       ...              ...   ...   \n","13525697  109120 -0.939241  0.031564 -0.394737                0     0   \n","13525698  109121 -0.941096  0.031582 -0.392626                0     0   \n","13525699  109122 -0.940131  0.029092 -0.394385                0     0   \n","13525700  109123 -0.939872  0.028058 -0.398664                0     0   \n","13525701  109124 -0.939006  0.026628 -0.398454                0     0   \n","\n","          Walking  Valid   Task  \n","0               0  False  False  \n","1               0  False  False  \n","2               0  False  False  \n","3               0  False  False  \n","4               0  False  False  \n","...           ...    ...    ...  \n","13525697        0  False  False  \n","13525698        0  False  False  \n","13525699        0  False  False  \n","13525700        0  False  False  \n","13525701        0  False  False  \n","\n","[13525702 rows x 9 columns]"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["df_all"]},{"cell_type":"code","execution_count":61,"id":"c6081b1b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:31.166055Z","iopub.status.busy":"2023-07-03T08:38:31.165646Z","iopub.status.idle":"2023-07-03T08:38:31.684091Z","shell.execute_reply":"2023-07-03T08:38:31.682676Z"},"papermill":{"duration":0.639122,"end_time":"2023-07-03T08:38:31.686661","exception":false,"start_time":"2023-07-03T08:38:31.047539","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["AccV -0.9401728865187444 0.0860651354523073\n","AccML 0.0011727847170219124 0.12000798550797488\n","AccAP -0.13061518435798145 0.28238873112037965\n"]}],"source":["mean_std_dict = {}\n","for c in [\"AccV\", \"AccML\", \"AccAP\"]:\n","    mean = df_all[c].mean()\n","    std = df_all[c].std()\n","    mean_std_dict[c] = [mean,std]\n","    print(c, mean, std)"]},{"cell_type":"code","execution_count":62,"id":"484c5b3e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:31.923956Z","iopub.status.busy":"2023-07-03T08:38:31.923566Z","iopub.status.idle":"2023-07-03T08:38:31.929097Z","shell.execute_reply":"2023-07-03T08:38:31.927951Z"},"papermill":{"duration":0.125826,"end_time":"2023-07-03T08:38:31.931626","exception":false,"start_time":"2023-07-03T08:38:31.8058","status":"completed"},"tags":[]},"outputs":[],"source":["with open(f'./output/fe/fe{fe}/save/fe{fe}_sc.pkl', 'wb') as p:\n","    pickle.dump(mean_std_dict, p)"]},{"cell_type":"code","execution_count":63,"id":"98bebac2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:32.172567Z","iopub.status.busy":"2023-07-03T08:38:32.172177Z","iopub.status.idle":"2023-07-03T08:38:47.433134Z","shell.execute_reply":"2023-07-03T08:38:47.431874Z"},"papermill":{"duration":15.386908,"end_time":"2023-07-03T08:38:47.437101","exception":false,"start_time":"2023-07-03T08:38:32.050193","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_metadata: : 137it [00:15,  9.00it/s]\n"]}],"source":["d_list = []\n","num_array = []\n","target_array = []\n","valid_array = []\n","subject_list = []\n","id_list = []\n","mask_array = []\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 1000\n","\n","for i,s in tqdm(zip(defog_metadata[\"Id\"].values, defog_metadata[\"sub_id\"].values), desc=\"defog_metadata: \"):\n","    path = root_data + f\"train/defog/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_defog]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df) // seq_len) + 1\n","        \n","        for c in num_cols:\n","            df[c] = (df[c] - mean_std_dict[c][0]) / mean_std_dict[c][1]\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        \n","        num_array_    = np.zeros([batch, seq_len, 3])\n","        target_array_ = np.zeros([batch, seq_len, 3])\n","        mask_array_   = np.zeros([batch, seq_len])\n","        valid_array_  = np.zeros([batch, seq_len])\n","        \n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*seq_len : ]\n","                num_array_[b, :len(num_), :] = num_\n","                target_ = target[b*seq_len : ]\n","                target_array_[b,:len(target_), :] = target_\n","                valid_ = valid[b*seq_len : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","                mask_array_[b, :len(target_)] = 1\n","            else:\n","                num_ = num[b*seq_len : (b+1)*seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*seq_len : (b+1)*seq_len]\n","                target_array_[b, :, :] = target_\n","                valid_ = valid[b*seq_len : (b+1)*seq_len]\n","                valid_array_[b, :] = valid_\n","                mask_array_[b,:] = 1\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":64,"id":"8ec2e174","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:47.678729Z","iopub.status.busy":"2023-07-03T08:38:47.678374Z","iopub.status.idle":"2023-07-03T08:38:48.59372Z","shell.execute_reply":"2023-07-03T08:38:48.592749Z"},"papermill":{"duration":1.035231,"end_time":"2023-07-03T08:38:48.596315","exception":false,"start_time":"2023-07-03T08:38:47.561084","status":"completed"},"tags":[]},"outputs":[],"source":["num_array    = np.concatenate(num_array, axis=0)\n","target_array = np.concatenate(target_array, axis=0)\n","mask_array   =  np.concatenate(mask_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":65,"id":"8763bf5c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:48.883816Z","iopub.status.busy":"2023-07-03T08:38:48.883447Z","iopub.status.idle":"2023-07-03T08:38:48.892542Z","shell.execute_reply":"2023-07-03T08:38:48.891709Z"},"papermill":{"duration":0.129936,"end_time":"2023-07-03T08:38:48.894664","exception":false,"start_time":"2023-07-03T08:38:48.764728","status":"completed"},"tags":[]},"outputs":[],"source":["defog_metadata[\"data_is\"] = d_list\n","\n","defog_metadata.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":66,"id":"446db8f8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:49.122921Z","iopub.status.busy":"2023-07-03T08:38:49.122564Z","iopub.status.idle":"2023-07-03T08:38:49.196561Z","shell.execute_reply":"2023-07-03T08:38:49.195612Z"},"papermill":{"duration":0.190629,"end_time":"2023-07-03T08:38:49.198761","exception":false,"start_time":"2023-07-03T08:38:49.008132","status":"completed"},"tags":[]},"outputs":[],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"cbd77a67","metadata":{"papermill":{"duration":0.113629,"end_time":"2023-07-03T08:38:49.428569","exception":false,"start_time":"2023-07-03T08:38:49.31494","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe047_defog_5000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe047_defog_5000.ipynb\" style=\"text-decoration:none\">fe047_defog_5000.ipynb</a>"]},{"cell_type":"code","execution_count":67,"id":"ec7b2e5a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:49.658079Z","iopub.status.busy":"2023-07-03T08:38:49.657661Z","iopub.status.idle":"2023-07-03T08:38:49.663325Z","shell.execute_reply":"2023-07-03T08:38:49.662206Z"},"papermill":{"duration":0.123766,"end_time":"2023-07-03T08:38:49.66557","exception":false,"start_time":"2023-07-03T08:38:49.541804","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"047\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":68,"id":"b7d0c44f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:49.899175Z","iopub.status.busy":"2023-07-03T08:38:49.8988Z","iopub.status.idle":"2023-07-03T08:38:49.904506Z","shell.execute_reply":"2023-07-03T08:38:49.903477Z"},"papermill":{"duration":0.123822,"end_time":"2023-07-03T08:38:49.906981","exception":false,"start_time":"2023-07-03T08:38:49.783159","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff', \n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":69,"id":"4d696a3c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:50.136064Z","iopub.status.busy":"2023-07-03T08:38:50.135709Z","iopub.status.idle":"2023-07-03T08:38:50.144941Z","shell.execute_reply":"2023-07-03T08:38:50.144022Z"},"papermill":{"duration":0.125191,"end_time":"2023-07-03T08:38:50.146995","exception":false,"start_time":"2023-07-03T08:38:50.021804","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":70,"id":"ca439e49","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:38:50.380384Z","iopub.status.busy":"2023-07-03T08:38:50.379407Z","iopub.status.idle":"2023-07-03T08:39:13.860228Z","shell.execute_reply":"2023-07-03T08:39:13.858498Z"},"papermill":{"duration":23.599968,"end_time":"2023-07-03T08:39:13.862731","exception":false,"start_time":"2023-07-03T08:38:50.262763","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_metadata: : 137it [00:23,  5.84it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_metadata[\"Id\"].values, defog_metadata[\"sub_id\"].values), desc=\"defog_metadata: \"):\n","    path = root_data + f\"train/defog/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_defog]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 3])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":71,"id":"41b3ad63","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:14.112397Z","iopub.status.busy":"2023-07-03T08:39:14.112049Z","iopub.status.idle":"2023-07-03T08:39:28.48547Z","shell.execute_reply":"2023-07-03T08:39:28.483201Z"},"papermill":{"duration":14.499542,"end_time":"2023-07-03T08:39:28.488513","exception":false,"start_time":"2023-07-03T08:39:13.988971","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":72,"id":"26585c75","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:28.745329Z","iopub.status.busy":"2023-07-03T08:39:28.744971Z","iopub.status.idle":"2023-07-03T08:39:28.787001Z","shell.execute_reply":"2023-07-03T08:39:28.786134Z"},"papermill":{"duration":0.172177,"end_time":"2023-07-03T08:39:28.789089","exception":false,"start_time":"2023-07-03T08:39:28.616912","status":"completed"},"tags":[]},"outputs":[],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"b46da30e","metadata":{"papermill":{"duration":0.126098,"end_time":"2023-07-03T08:39:29.040842","exception":false,"start_time":"2023-07-03T08:39:28.914744","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>**Training**</font>\n","\n","\n","<br>\n","\n","### helpers"]},{"cell_type":"code","execution_count":73,"id":"cdad087d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:29.304552Z","iopub.status.busy":"2023-07-03T08:39:29.304135Z","iopub.status.idle":"2023-07-03T08:39:29.308599Z","shell.execute_reply":"2023-07-03T08:39:29.307658Z"},"papermill":{"duration":0.135584,"end_time":"2023-07-03T08:39:29.310941","exception":false,"start_time":"2023-07-03T08:39:29.175357","status":"completed"},"tags":[]},"outputs":[],"source":["TRAIN_FLAG_DEFOG = True"]},{"cell_type":"markdown","id":"09609111","metadata":{"papermill":{"duration":0.134321,"end_time":"2023-07-03T08:39:29.571592","exception":false,"start_time":"2023-07-03T08:39:29.437271","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `set_seed()`"]},{"cell_type":"code","execution_count":74,"id":"a1b98219","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:29.838381Z","iopub.status.busy":"2023-07-03T08:39:29.837558Z","iopub.status.idle":"2023-07-03T08:39:29.844598Z","shell.execute_reply":"2023-07-03T08:39:29.843322Z"},"papermill":{"duration":0.14582,"end_time":"2023-07-03T08:39:29.847396","exception":false,"start_time":"2023-07-03T08:39:29.701576","status":"completed"},"tags":[]},"outputs":[],"source":["def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","id":"576d3ea2","metadata":{"papermill":{"duration":0.12852,"end_time":"2023-07-03T08:39:30.102218","exception":false,"start_time":"2023-07-03T08:39:29.973698","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `timer()`"]},{"cell_type":"code","execution_count":75,"id":"e3d40450","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:30.354087Z","iopub.status.busy":"2023-07-03T08:39:30.353311Z","iopub.status.idle":"2023-07-03T08:39:30.363453Z","shell.execute_reply":"2023-07-03T08:39:30.35876Z"},"papermill":{"duration":0.14046,"end_time":"2023-07-03T08:39:30.367375","exception":false,"start_time":"2023-07-03T08:39:30.226915","status":"completed"},"tags":[]},"outputs":[],"source":["@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    \n","    yield \n","    # LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(\"=\"*66)\n","    print(\"\\n\"*2)\n","    \n","# setup_logger(out_file=logger_path)"]},{"cell_type":"markdown","id":"b7eba7e7","metadata":{"papermill":{"duration":0.128813,"end_time":"2023-07-03T08:39:30.679491","exception":false,"start_time":"2023-07-03T08:39:30.550678","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `preprocess()`"]},{"cell_type":"code","execution_count":76,"id":"e8688557","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:30.937459Z","iopub.status.busy":"2023-07-03T08:39:30.937098Z","iopub.status.idle":"2023-07-03T08:39:30.943323Z","shell.execute_reply":"2023-07-03T08:39:30.941851Z"},"papermill":{"duration":0.135637,"end_time":"2023-07-03T08:39:30.945385","exception":false,"start_time":"2023-07-03T08:39:30.809748","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array, valid_array,):\n","    \n","    attention_mask = mask_array == 0\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'input_data_valid_array': valid_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"20405d24","metadata":{"papermill":{"duration":0.128896,"end_time":"2023-07-03T08:39:31.199634","exception":false,"start_time":"2023-07-03T08:39:31.070738","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogDataset()`"]},{"cell_type":"code","execution_count":77,"id":"b535fe56","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:31.45299Z","iopub.status.busy":"2023-07-03T08:39:31.452517Z","iopub.status.idle":"2023-07-03T08:39:31.469339Z","shell.execute_reply":"2023-07-03T08:39:31.468438Z"},"papermill":{"duration":0.147914,"end_time":"2023-07-03T08:39:31.472254","exception":false,"start_time":"2023-07-03T08:39:31.32434","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, valid_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.valid_array = valid_array\n","        self.train = train\n","        self.y = y\n","    \n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","    \n","    \n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item], self.valid_array[item],)\n","\n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'],  dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),   \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\": torch.tensor(self.y[item], dtype=torch.float32)\n","            }\n","        else:\n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),  \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"479296cc","metadata":{"papermill":{"duration":0.127087,"end_time":"2023-07-03T08:39:31.726318","exception":false,"start_time":"2023-07-03T08:39:31.599231","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":78,"id":"4d30d8fe","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:32.015762Z","iopub.status.busy":"2023-07-03T08:39:32.015375Z","iopub.status.idle":"2023-07-03T08:39:32.040679Z","shell.execute_reply":"2023-07-03T08:39:32.038142Z"},"papermill":{"duration":0.192566,"end_time":"2023-07-03T08:39:32.045007","exception":false,"start_time":"2023-07-03T08:39:31.852441","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"0b35335a","metadata":{"papermill":{"duration":0.206459,"end_time":"2023-07-03T08:39:32.45037","exception":false,"start_time":"2023-07-03T08:39:32.243911","status":"completed"},"tags":[]},"source":["<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":79,"id":"bbadb234","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:32.834502Z","iopub.status.busy":"2023-07-03T08:39:32.834083Z","iopub.status.idle":"2023-07-03T08:39:32.83943Z","shell.execute_reply":"2023-07-03T08:39:32.83863Z"},"papermill":{"duration":0.193228,"end_time":"2023-07-03T08:39:32.84363","exception":false,"start_time":"2023-07-03T08:39:32.650402","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe047/fe047_id.parquet\"\n","numerical_path = f\"./output/fe/fe047/fe047_num_array.npy\"\n","target_path    = f\"./output/fe/fe047/fe047_target_array.npy\"\n","mask_path      = f\"./output/fe/fe047/fe047_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe047/fe047_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe047/fe047_pred_use_array.npy\""]},{"cell_type":"code","execution_count":80,"id":"c0a7e261","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:33.213698Z","iopub.status.busy":"2023-07-03T08:39:33.213266Z","iopub.status.idle":"2023-07-03T08:39:49.951739Z","shell.execute_reply":"2023-07-03T08:39:49.950795Z"},"papermill":{"duration":16.922082,"end_time":"2023-07-03T08:39:49.9539","exception":false,"start_time":"2023-07-03T08:39:33.031818","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    4107\n","2     897\n","3     354\n","1      11\n","Name: group, dtype: int64"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array = np.load(target_path)\n","mask_array = np.load(mask_path)\n","valid_array = np.load(valid_path)\n","pred_use_array = np.load(pred_use_path)\n","\n","target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i,:,0]))\n","    target2.append(np.sum(target_array[i,:,1]))\n","    target3.append(np.sum(target_array[i,:,2]))\n","\n","\n","df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)\n","\n","df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3\n","\n","\n","df_id[\"group\"].value_counts()"]},{"cell_type":"markdown","id":"fbf0a6d7","metadata":{"papermill":{"duration":0.124553,"end_time":"2023-07-03T08:39:50.210598","exception":false,"start_time":"2023-07-03T08:39:50.086045","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":81,"id":"a9b03e7c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:50.461241Z","iopub.status.busy":"2023-07-03T08:39:50.460866Z","iopub.status.idle":"2023-07-03T08:39:50.466439Z","shell.execute_reply":"2023-07-03T08:39:50.465458Z"},"papermill":{"duration":0.129466,"end_time":"2023-07-03T08:39:50.468661","exception":false,"start_time":"2023-07-03T08:39:50.339195","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 15\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"f30e8efc","metadata":{"papermill":{"duration":0.119133,"end_time":"2023-07-03T08:39:50.71241","exception":false,"start_time":"2023-07-03T08:39:50.593277","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex153_defog_gru.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex153_defog_gru.ipynb\" style=\"text-decoration:none\">ex153_defog_gru.ipynb</a>"]},{"cell_type":"code","execution_count":82,"id":"f4587b5a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:50.958765Z","iopub.status.busy":"2023-07-03T08:39:50.958428Z","iopub.status.idle":"2023-07-03T08:39:50.964704Z","shell.execute_reply":"2023-07-03T08:39:50.963889Z"},"papermill":{"duration":0.130932,"end_time":"2023-07-03T08:39:50.966797","exception":false,"start_time":"2023-07-03T08:39:50.835865","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"b82bdbd9","metadata":{"papermill":{"duration":0.126076,"end_time":"2023-07-03T08:39:51.215626","exception":false,"start_time":"2023-07-03T08:39:51.08955","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":83,"id":"861f9068","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:51.514366Z","iopub.status.busy":"2023-07-03T08:39:51.514023Z","iopub.status.idle":"2023-07-03T08:39:51.54103Z","shell.execute_reply":"2023-07-03T08:39:51.53937Z"},"papermill":{"duration":0.154099,"end_time":"2023-07-03T08:39:51.543263","exception":false,"start_time":"2023-07-03T08:39:51.389164","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n","Wall time: 9.06 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"30b99875","metadata":{"papermill":{"duration":0.128647,"end_time":"2023-07-03T08:39:51.79634","exception":false,"start_time":"2023-07-03T08:39:51.667693","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":84,"id":"612a0c6d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:52.044739Z","iopub.status.busy":"2023-07-03T08:39:52.043779Z","iopub.status.idle":"2023-07-03T08:39:52.051263Z","shell.execute_reply":"2023-07-03T08:39:52.050202Z"},"papermill":{"duration":0.130999,"end_time":"2023-07-03T08:39:52.053254","exception":false,"start_time":"2023-07-03T08:39:51.922255","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"0fc7bd8c","metadata":{"papermill":{"duration":0.121168,"end_time":"2023-07-03T08:39:52.296756","exception":false,"start_time":"2023-07-03T08:39:52.175588","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex154_defog_gru.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex154_defog_gru.ipynb\" style=\"text-decoration:none\">ex154_defog_gru.ipynb</a>"]},{"cell_type":"code","execution_count":85,"id":"7751710e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:52.537862Z","iopub.status.busy":"2023-07-03T08:39:52.536834Z","iopub.status.idle":"2023-07-03T08:39:52.542859Z","shell.execute_reply":"2023-07-03T08:39:52.541919Z"},"papermill":{"duration":0.129863,"end_time":"2023-07-03T08:39:52.545072","exception":false,"start_time":"2023-07-03T08:39:52.415209","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"154_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"859a3106","metadata":{"papermill":{"duration":0.124075,"end_time":"2023-07-03T08:39:52.791819","exception":false,"start_time":"2023-07-03T08:39:52.667744","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":86,"id":"f110e126","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:53.034956Z","iopub.status.busy":"2023-07-03T08:39:53.034556Z","iopub.status.idle":"2023-07-03T08:39:53.046517Z","shell.execute_reply":"2023-07-03T08:39:53.045661Z"},"papermill":{"duration":0.133277,"end_time":"2023-07-03T08:39:53.048602","exception":false,"start_time":"2023-07-03T08:39:52.915325","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 96,\n","                 model_size = 256,\n","                 linear_out = 256,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"8b126dda","metadata":{"papermill":{"duration":0.124752,"end_time":"2023-07-03T08:39:53.294496","exception":false,"start_time":"2023-07-03T08:39:53.169744","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":87,"id":"67a01b9b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:53.537988Z","iopub.status.busy":"2023-07-03T08:39:53.537602Z","iopub.status.idle":"2023-07-03T08:39:53.567571Z","shell.execute_reply":"2023-07-03T08:39:53.566555Z"},"papermill":{"duration":0.152861,"end_time":"2023-07-03T08:39:53.570074","exception":false,"start_time":"2023-07-03T08:39:53.417213","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n","Wall time: 11.2 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"b27ede01","metadata":{"papermill":{"duration":0.122024,"end_time":"2023-07-03T08:39:53.812193","exception":false,"start_time":"2023-07-03T08:39:53.690169","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":88,"id":"ec37d38a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:54.05926Z","iopub.status.busy":"2023-07-03T08:39:54.05885Z","iopub.status.idle":"2023-07-03T08:39:54.065655Z","shell.execute_reply":"2023-07-03T08:39:54.064725Z"},"papermill":{"duration":0.131445,"end_time":"2023-07-03T08:39:54.067738","exception":false,"start_time":"2023-07-03T08:39:53.936293","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"905e5d76","metadata":{"papermill":{"duration":0.123191,"end_time":"2023-07-03T08:39:54.314726","exception":false,"start_time":"2023-07-03T08:39:54.191535","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","\n","# **notype** 【Training】\n","\n","\n","<br>\n","\n","## **Feature Engineering**\n","\n","\n","<br>\n","\n","### fe061_notype_5000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe061_notype_5000.ipynb\" style=\"text-decoration:none\">fe061_notype_5000.ipynb</a>"]},{"cell_type":"code","execution_count":89,"id":"b9268939","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:54.566149Z","iopub.status.busy":"2023-07-03T08:39:54.565158Z","iopub.status.idle":"2023-07-03T08:39:54.574262Z","shell.execute_reply":"2023-07-03T08:39:54.573405Z"},"papermill":{"duration":0.136425,"end_time":"2023-07-03T08:39:54.576242","exception":false,"start_time":"2023-07-03T08:39:54.439817","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"061_notype\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":90,"id":"595f343d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:54.876792Z","iopub.status.busy":"2023-07-03T08:39:54.876446Z","iopub.status.idle":"2023-07-03T08:39:54.890773Z","shell.execute_reply":"2023-07-03T08:39:54.88978Z"},"papermill":{"duration":0.142575,"end_time":"2023-07-03T08:39:54.892808","exception":false,"start_time":"2023-07-03T08:39:54.750233","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":91,"id":"6053b4e8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:55.143396Z","iopub.status.busy":"2023-07-03T08:39:55.142356Z","iopub.status.idle":"2023-07-03T08:39:55.149503Z","shell.execute_reply":"2023-07-03T08:39:55.148412Z"},"papermill":{"duration":0.134519,"end_time":"2023-07-03T08:39:55.151612","exception":false,"start_time":"2023-07-03T08:39:55.017093","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\",  \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff',  \n","            'AccML_lag_diff', 'AccML_lead_diff', \n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"Event\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":92,"id":"7d10717b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:55.400372Z","iopub.status.busy":"2023-07-03T08:39:55.399272Z","iopub.status.idle":"2023-07-03T08:39:55.481904Z","shell.execute_reply":"2023-07-03T08:39:55.480947Z"},"papermill":{"duration":0.206733,"end_time":"2023-07-03T08:39:55.484274","exception":false,"start_time":"2023-07-03T08:39:55.277541","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":93,"id":"ac6b76df","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:39:55.725115Z","iopub.status.busy":"2023-07-03T08:39:55.724335Z","iopub.status.idle":"2023-07-03T08:40:20.830831Z","shell.execute_reply":"2023-07-03T08:40:20.82941Z"},"papermill":{"duration":25.22828,"end_time":"2023-07-03T08:40:20.832896","exception":false,"start_time":"2023-07-03T08:39:55.604616","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_meta: : 137it [00:25,  5.46it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values), desc=\"defog_meta: \"):\n","    path = root_data + f\"train/notype/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 1])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":94,"id":"43aae4c4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:21.084192Z","iopub.status.busy":"2023-07-03T08:40:21.083799Z","iopub.status.idle":"2023-07-03T08:40:28.062261Z","shell.execute_reply":"2023-07-03T08:40:28.061153Z"},"papermill":{"duration":7.107558,"end_time":"2023-07-03T08:40:28.064548","exception":false,"start_time":"2023-07-03T08:40:20.95699","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":95,"id":"97899a60","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:30.985959Z","iopub.status.busy":"2023-07-03T08:40:30.985454Z","iopub.status.idle":"2023-07-03T08:40:31.02043Z","shell.execute_reply":"2023-07-03T08:40:31.019551Z"},"papermill":{"duration":0.301157,"end_time":"2023-07-03T08:40:31.022434","exception":false,"start_time":"2023-07-03T08:40:30.721277","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["46"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id[\"Id\"].nunique()"]},{"cell_type":"code","execution_count":96,"id":"79e2d4b0","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:31.289141Z","iopub.status.busy":"2023-07-03T08:40:31.288765Z","iopub.status.idle":"2023-07-03T08:40:31.299793Z","shell.execute_reply":"2023-07-03T08:40:31.298616Z"},"papermill":{"duration":0.152409,"end_time":"2023-07-03T08:40:31.303217","exception":false,"start_time":"2023-07-03T08:40:31.150808","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"9374904a","metadata":{"papermill":{"duration":0.13171,"end_time":"2023-07-03T08:40:31.56755","exception":false,"start_time":"2023-07-03T08:40:31.43584","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe064_notype_10000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe064_notype_10000.ipynb\" style=\"text-decoration:none\">fe064_notype_10000.ipynb</a>"]},{"cell_type":"code","execution_count":97,"id":"f537829d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:31.83576Z","iopub.status.busy":"2023-07-03T08:40:31.835189Z","iopub.status.idle":"2023-07-03T08:40:31.841826Z","shell.execute_reply":"2023-07-03T08:40:31.840849Z"},"papermill":{"duration":0.141402,"end_time":"2023-07-03T08:40:31.844197","exception":false,"start_time":"2023-07-03T08:40:31.702795","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"064_notype\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":98,"id":"6361e729","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:32.095684Z","iopub.status.busy":"2023-07-03T08:40:32.095337Z","iopub.status.idle":"2023-07-03T08:40:32.106571Z","shell.execute_reply":"2023-07-03T08:40:32.105651Z"},"papermill":{"duration":0.141271,"end_time":"2023-07-03T08:40:32.10911","exception":false,"start_time":"2023-07-03T08:40:31.967839","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":99,"id":"98054598","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:32.37786Z","iopub.status.busy":"2023-07-03T08:40:32.376833Z","iopub.status.idle":"2023-07-03T08:40:32.383071Z","shell.execute_reply":"2023-07-03T08:40:32.382081Z"},"papermill":{"duration":0.136928,"end_time":"2023-07-03T08:40:32.385313","exception":false,"start_time":"2023-07-03T08:40:32.248385","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"Event\"]\n","seq_len = 10000\n","shift = 5000\n","offset = 2500"]},{"cell_type":"code","execution_count":100,"id":"e2615f3a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:32.646464Z","iopub.status.busy":"2023-07-03T08:40:32.645673Z","iopub.status.idle":"2023-07-03T08:40:32.657653Z","shell.execute_reply":"2023-07-03T08:40:32.656701Z"},"papermill":{"duration":0.14457,"end_time":"2023-07-03T08:40:32.659664","exception":false,"start_time":"2023-07-03T08:40:32.515094","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":101,"id":"618045f9","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:32.921695Z","iopub.status.busy":"2023-07-03T08:40:32.921361Z","iopub.status.idle":"2023-07-03T08:40:55.104699Z","shell.execute_reply":"2023-07-03T08:40:55.103399Z"},"papermill":{"duration":22.319452,"end_time":"2023-07-03T08:40:55.106794","exception":false,"start_time":"2023-07-03T08:40:32.787342","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_meta: : 137it [00:22,  6.18it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values), desc=\"defog_meta: \"):\n","    path = root_data + f\"train/notype/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 1])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":102,"id":"a3955b1a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:40:55.374794Z","iopub.status.busy":"2023-07-03T08:40:55.374427Z","iopub.status.idle":"2023-07-03T08:41:02.904415Z","shell.execute_reply":"2023-07-03T08:41:02.903402Z"},"papermill":{"duration":7.667896,"end_time":"2023-07-03T08:41:02.907936","exception":false,"start_time":"2023-07-03T08:40:55.24004","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":103,"id":"1e4e49f6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:03.192708Z","iopub.status.busy":"2023-07-03T08:41:03.192328Z","iopub.status.idle":"2023-07-03T08:41:03.216732Z","shell.execute_reply":"2023-07-03T08:41:03.215778Z"},"papermill":{"duration":0.169431,"end_time":"2023-07-03T08:41:03.219012","exception":false,"start_time":"2023-07-03T08:41:03.049581","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["46"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id[\"Id\"].nunique()"]},{"cell_type":"code","execution_count":104,"id":"19bbe0a4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:03.51582Z","iopub.status.busy":"2023-07-03T08:41:03.515252Z","iopub.status.idle":"2023-07-03T08:41:03.562707Z","shell.execute_reply":"2023-07-03T08:41:03.561458Z"},"papermill":{"duration":0.194439,"end_time":"2023-07-03T08:41:03.5648","exception":false,"start_time":"2023-07-03T08:41:03.370361","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"90fb08a6","metadata":{"papermill":{"duration":0.135314,"end_time":"2023-07-03T08:41:03.888339","exception":false,"start_time":"2023-07-03T08:41:03.753025","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe074_notype_15000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe074_notype_15000.ipynb\" style=\"text-decoration:none\">fe074_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":105,"id":"b5f0b108","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:04.166024Z","iopub.status.busy":"2023-07-03T08:41:04.165607Z","iopub.status.idle":"2023-07-03T08:41:04.1713Z","shell.execute_reply":"2023-07-03T08:41:04.170351Z"},"papermill":{"duration":0.144151,"end_time":"2023-07-03T08:41:04.173629","exception":false,"start_time":"2023-07-03T08:41:04.029478","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"074_notype\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":106,"id":"d245535b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:04.44999Z","iopub.status.busy":"2023-07-03T08:41:04.4496Z","iopub.status.idle":"2023-07-03T08:41:04.459537Z","shell.execute_reply":"2023-07-03T08:41:04.458529Z"},"papermill":{"duration":0.150809,"end_time":"2023-07-03T08:41:04.461679","exception":false,"start_time":"2023-07-03T08:41:04.31087","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":107,"id":"3d182171","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:04.738178Z","iopub.status.busy":"2023-07-03T08:41:04.737599Z","iopub.status.idle":"2023-07-03T08:41:04.743378Z","shell.execute_reply":"2023-07-03T08:41:04.742373Z"},"papermill":{"duration":0.14798,"end_time":"2023-07-03T08:41:04.74556","exception":false,"start_time":"2023-07-03T08:41:04.59758","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"Event\"]\n","seq_len = 15000\n","shift = 7500\n","offset = 3750"]},{"cell_type":"code","execution_count":108,"id":"aebdd295","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:05.026445Z","iopub.status.busy":"2023-07-03T08:41:05.025838Z","iopub.status.idle":"2023-07-03T08:41:05.046218Z","shell.execute_reply":"2023-07-03T08:41:05.045216Z"},"papermill":{"duration":0.166923,"end_time":"2023-07-03T08:41:05.048387","exception":false,"start_time":"2023-07-03T08:41:04.881464","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":109,"id":"6e23c459","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:05.32864Z","iopub.status.busy":"2023-07-03T08:41:05.328276Z","iopub.status.idle":"2023-07-03T08:41:21.220006Z","shell.execute_reply":"2023-07-03T08:41:21.218582Z"},"papermill":{"duration":16.035529,"end_time":"2023-07-03T08:41:21.222006","exception":false,"start_time":"2023-07-03T08:41:05.186477","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_meta: : 137it [00:15,  8.63it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values), desc=\"defog_meta: \"):\n","    path = root_data + f\"train/notype/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 1])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":110,"id":"fcaba9d6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:21.496903Z","iopub.status.busy":"2023-07-03T08:41:21.49625Z","iopub.status.idle":"2023-07-03T08:41:28.893414Z","shell.execute_reply":"2023-07-03T08:41:28.892438Z"},"papermill":{"duration":7.535296,"end_time":"2023-07-03T08:41:28.896438","exception":false,"start_time":"2023-07-03T08:41:21.361142","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":111,"id":"a172f735","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:31.071436Z","iopub.status.busy":"2023-07-03T08:41:31.070929Z","iopub.status.idle":"2023-07-03T08:41:31.111011Z","shell.execute_reply":"2023-07-03T08:41:31.109835Z"},"papermill":{"duration":0.315054,"end_time":"2023-07-03T08:41:31.114508","exception":false,"start_time":"2023-07-03T08:41:30.799454","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["46"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id[\"Id\"].nunique()"]},{"cell_type":"code","execution_count":112,"id":"e04ca7e6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:31.452948Z","iopub.status.busy":"2023-07-03T08:41:31.45247Z","iopub.status.idle":"2023-07-03T08:41:31.466564Z","shell.execute_reply":"2023-07-03T08:41:31.462105Z"},"papermill":{"duration":0.157783,"end_time":"2023-07-03T08:41:31.469491","exception":false,"start_time":"2023-07-03T08:41:31.311708","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"17bc06b2","metadata":{"papermill":{"duration":0.148474,"end_time":"2023-07-03T08:41:31.758492","exception":false,"start_time":"2023-07-03T08:41:31.610018","status":"completed"},"tags":[]},"source":["<br>\n","\n","## **Helpers**\n","\n","<br>\n","\n","### def `set_seed()`"]},{"cell_type":"code","execution_count":113,"id":"ac85a30b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:32.042527Z","iopub.status.busy":"2023-07-03T08:41:32.042048Z","iopub.status.idle":"2023-07-03T08:41:32.050708Z","shell.execute_reply":"2023-07-03T08:41:32.048634Z"},"papermill":{"duration":0.15522,"end_time":"2023-07-03T08:41:32.055475","exception":false,"start_time":"2023-07-03T08:41:31.900255","status":"completed"},"tags":[]},"outputs":[],"source":["def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","id":"2134bdc4","metadata":{"papermill":{"duration":0.147751,"end_time":"2023-07-03T08:41:32.34726","exception":false,"start_time":"2023-07-03T08:41:32.199509","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `timer()`"]},{"cell_type":"code","execution_count":114,"id":"7efc4b4d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:32.642338Z","iopub.status.busy":"2023-07-03T08:41:32.641972Z","iopub.status.idle":"2023-07-03T08:41:32.647308Z","shell.execute_reply":"2023-07-03T08:41:32.646432Z"},"papermill":{"duration":0.154248,"end_time":"2023-07-03T08:41:32.649481","exception":false,"start_time":"2023-07-03T08:41:32.495233","status":"completed"},"tags":[]},"outputs":[],"source":["@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    \n","    yield \n","    # LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(\"=\"*66)\n","    \n","# setup_logger(out_file=logger_path)"]},{"cell_type":"markdown","id":"6b7f21f7","metadata":{"papermill":{"duration":0.134935,"end_time":"2023-07-03T08:41:32.978707","exception":false,"start_time":"2023-07-03T08:41:32.843772","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `preprocess()`"]},{"cell_type":"code","execution_count":115,"id":"3826af1f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:33.255704Z","iopub.status.busy":"2023-07-03T08:41:33.255336Z","iopub.status.idle":"2023-07-03T08:41:33.260957Z","shell.execute_reply":"2023-07-03T08:41:33.260008Z"},"papermill":{"duration":0.147927,"end_time":"2023-07-03T08:41:33.263142","exception":false,"start_time":"2023-07-03T08:41:33.115215","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array, valid_array,):\n","    \n","    attention_mask = mask_array == 0\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'input_data_valid_array': valid_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"c822c37c","metadata":{"papermill":{"duration":0.132356,"end_time":"2023-07-03T08:41:33.532561","exception":false,"start_time":"2023-07-03T08:41:33.400205","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `FogDataset()`"]},{"cell_type":"code","execution_count":116,"id":"09a04cb3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:33.802631Z","iopub.status.busy":"2023-07-03T08:41:33.802277Z","iopub.status.idle":"2023-07-03T08:41:33.814216Z","shell.execute_reply":"2023-07-03T08:41:33.813307Z"},"papermill":{"duration":0.151166,"end_time":"2023-07-03T08:41:33.816372","exception":false,"start_time":"2023-07-03T08:41:33.665206","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, valid_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.valid_array = valid_array\n","        self.train = train\n","        self.y = y\n","    \n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","    \n","    \n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item], self.valid_array[item],)\n","\n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'],  dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),   \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\": torch.tensor(self.y[item], dtype=torch.float32)\n","            }\n","        else:\n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),  \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"6d8c6244","metadata":{"papermill":{"duration":0.136163,"end_time":"2023-07-03T08:41:34.088551","exception":false,"start_time":"2023-07-03T08:41:33.952388","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":117,"id":"1b8bf774","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:34.362507Z","iopub.status.busy":"2023-07-03T08:41:34.362163Z","iopub.status.idle":"2023-07-03T08:41:34.374847Z","shell.execute_reply":"2023-07-03T08:41:34.37396Z"},"papermill":{"duration":0.151263,"end_time":"2023-07-03T08:41:34.376889","exception":false,"start_time":"2023-07-03T08:41:34.225626","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"240fd52b","metadata":{"papermill":{"duration":0.136216,"end_time":"2023-07-03T08:41:34.645627","exception":false,"start_time":"2023-07-03T08:41:34.509411","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## <font color=blue>**ROUND 1**</font>\n","\n","<br>\n","<br>\n","\n","\n","## <font color=red>**Predicting**</font>: **Making** <font color=red>**pseudo**</font> **label** (round1: use models of ex153 & ex154)\n","\n","<br>\n","\n","### config"]},{"cell_type":"code","execution_count":118,"id":"1675633a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:34.920661Z","iopub.status.busy":"2023-07-03T08:41:34.919576Z","iopub.status.idle":"2023-07-03T08:41:34.926002Z","shell.execute_reply":"2023-07-03T08:41:34.925057Z"},"papermill":{"duration":0.146082,"end_time":"2023-07-03T08:41:34.928273","exception":false,"start_time":"2023-07-03T08:41:34.782191","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 15\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"c7087cd2","metadata":{"papermill":{"duration":0.139078,"end_time":"2023-07-03T08:41:35.20103","exception":false,"start_time":"2023-07-03T08:41:35.061952","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex153_defog_gru_inference_notype_10000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex153_defog_gru_inference_notype_10000.ipynb\" style=\"text-decoration:none\">ex153_defog_gru_inference_notype_10000.ipynb</a>"]},{"cell_type":"code","execution_count":119,"id":"71cba3b5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:35.47746Z","iopub.status.busy":"2023-07-03T08:41:35.477119Z","iopub.status.idle":"2023-07-03T08:41:35.48293Z","shell.execute_reply":"2023-07-03T08:41:35.481969Z"},"papermill":{"duration":0.145559,"end_time":"2023-07-03T08:41:35.485249","exception":false,"start_time":"2023-07-03T08:41:35.33969","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"36d36f54","metadata":{"papermill":{"duration":0.136615,"end_time":"2023-07-03T08:41:35.756441","exception":false,"start_time":"2023-07-03T08:41:35.619826","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data"]},{"cell_type":"code","execution_count":120,"id":"74cf1dfc","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:36.02668Z","iopub.status.busy":"2023-07-03T08:41:36.026245Z","iopub.status.idle":"2023-07-03T08:41:47.757676Z","shell.execute_reply":"2023-07-03T08:41:47.756916Z"},"papermill":{"duration":11.867764,"end_time":"2023-07-03T08:41:47.760633","exception":false,"start_time":"2023-07-03T08:41:35.892869","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 10000\n","\n","id_path        = f\"./output/fe/fe064_notype/fe064_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe064_notype/fe064_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe064_notype/fe064_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe064_notype/fe064_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe064_notype/fe064_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe064_notype/fe064_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe064_notype/fe064_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"a9a66d34","metadata":{"papermill":{"duration":0.131465,"end_time":"2023-07-03T08:41:48.063003","exception":false,"start_time":"2023-07-03T08:41:47.931538","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":121,"id":"7ed5dda9","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:48.380507Z","iopub.status.busy":"2023-07-03T08:41:48.380143Z","iopub.status.idle":"2023-07-03T08:41:48.386816Z","shell.execute_reply":"2023-07-03T08:41:48.385898Z"},"papermill":{"duration":0.139991,"end_time":"2023-07-03T08:41:48.388817","exception":false,"start_time":"2023-07-03T08:41:48.248826","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":121,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":122,"id":"e25f43b2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:48.655388Z","iopub.status.busy":"2023-07-03T08:41:48.654607Z","iopub.status.idle":"2023-07-03T08:41:48.665326Z","shell.execute_reply":"2023-07-03T08:41:48.664378Z"},"papermill":{"duration":0.146538,"end_time":"2023-07-03T08:41:48.667486","exception":false,"start_time":"2023-07-03T08:41:48.520948","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            model = FogRnnModel()\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, 10000, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)"]},{"cell_type":"code","execution_count":123,"id":"a5466a33","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:48.943066Z","iopub.status.busy":"2023-07-03T08:41:48.942157Z","iopub.status.idle":"2023-07-03T08:41:48.95053Z","shell.execute_reply":"2023-07-03T08:41:48.949584Z"},"papermill":{"duration":0.14967,"end_time":"2023-07-03T08:41:48.952724","exception":false,"start_time":"2023-07-03T08:41:48.803054","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")"]},{"cell_type":"markdown","id":"dd01771e","metadata":{"papermill":{"duration":0.135538,"end_time":"2023-07-03T08:41:49.219498","exception":false,"start_time":"2023-07-03T08:41:49.08396","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex153_defog_gru_inference_notype_15000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex153_defog_gru_inference_notype_15000.ipynb\" style=\"text-decoration:none\">ex153_defog_gru_inference_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":124,"id":"0718d36a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:49.485948Z","iopub.status.busy":"2023-07-03T08:41:49.485566Z","iopub.status.idle":"2023-07-03T08:41:49.491532Z","shell.execute_reply":"2023-07-03T08:41:49.490591Z"},"papermill":{"duration":0.140475,"end_time":"2023-07-03T08:41:49.493618","exception":false,"start_time":"2023-07-03T08:41:49.353143","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"1926e41c","metadata":{"papermill":{"duration":0.131918,"end_time":"2023-07-03T08:41:49.758138","exception":false,"start_time":"2023-07-03T08:41:49.62622","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data"]},{"cell_type":"code","execution_count":125,"id":"a6f072bf","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:41:50.020868Z","iopub.status.busy":"2023-07-03T08:41:50.020515Z","iopub.status.idle":"2023-07-03T08:42:01.268592Z","shell.execute_reply":"2023-07-03T08:42:01.267616Z"},"papermill":{"duration":11.381269,"end_time":"2023-07-03T08:42:01.270967","exception":false,"start_time":"2023-07-03T08:41:49.889698","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 15000\n","\n","id_path        = f\"./output/fe/fe074_notype/fe074_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe074_notype/fe074_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe074_notype/fe074_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe074_notype/fe074_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe074_notype/fe074_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe074_notype/fe074_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe074_notype/fe074_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"b6b2adbe","metadata":{"papermill":{"duration":0.133525,"end_time":"2023-07-03T08:42:01.541762","exception":false,"start_time":"2023-07-03T08:42:01.408237","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":126,"id":"1dd0538c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:01.809452Z","iopub.status.busy":"2023-07-03T08:42:01.808783Z","iopub.status.idle":"2023-07-03T08:42:01.815501Z","shell.execute_reply":"2023-07-03T08:42:01.814585Z"},"papermill":{"duration":0.139376,"end_time":"2023-07-03T08:42:01.8175","exception":false,"start_time":"2023-07-03T08:42:01.678124","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":127,"id":"9d08ed86","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:02.084499Z","iopub.status.busy":"2023-07-03T08:42:02.083795Z","iopub.status.idle":"2023-07-03T08:42:02.094491Z","shell.execute_reply":"2023-07-03T08:42:02.093528Z"},"papermill":{"duration":0.147618,"end_time":"2023-07-03T08:42:02.096521","exception":false,"start_time":"2023-07-03T08:42:01.948903","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            model = FogRnnModel()\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, seq_len, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)"]},{"cell_type":"code","execution_count":128,"id":"53b4f388","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:02.377483Z","iopub.status.busy":"2023-07-03T08:42:02.377109Z","iopub.status.idle":"2023-07-03T08:42:02.386585Z","shell.execute_reply":"2023-07-03T08:42:02.385596Z"},"papermill":{"duration":0.160282,"end_time":"2023-07-03T08:42:02.388774","exception":false,"start_time":"2023-07-03T08:42:02.228492","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")"]},{"cell_type":"markdown","id":"35ad3705","metadata":{"papermill":{"duration":0.141413,"end_time":"2023-07-03T08:42:02.666676","exception":false,"start_time":"2023-07-03T08:42:02.525263","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex154_defog_gru_inference_notype_15000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex154_defog_gru_inference_notype_15000.ipynb\" style=\"text-decoration:none\">ex154_defog_gru_inference_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":129,"id":"d8edf696","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:02.936499Z","iopub.status.busy":"2023-07-03T08:42:02.935692Z","iopub.status.idle":"2023-07-03T08:42:02.94222Z","shell.execute_reply":"2023-07-03T08:42:02.941038Z"},"papermill":{"duration":0.146171,"end_time":"2023-07-03T08:42:02.944911","exception":false,"start_time":"2023-07-03T08:42:02.79874","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"154_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"d4551992","metadata":{"papermill":{"duration":0.138282,"end_time":"2023-07-03T08:42:03.267503","exception":false,"start_time":"2023-07-03T08:42:03.129221","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data"]},{"cell_type":"code","execution_count":130,"id":"3e69136b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:03.537712Z","iopub.status.busy":"2023-07-03T08:42:03.537366Z","iopub.status.idle":"2023-07-03T08:42:14.284892Z","shell.execute_reply":"2023-07-03T08:42:14.281831Z"},"papermill":{"duration":10.884453,"end_time":"2023-07-03T08:42:14.289346","exception":false,"start_time":"2023-07-03T08:42:03.404893","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 15000\n","\n","id_path        = f\"./output/fe/fe074_notype/fe074_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe074_notype/fe074_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe074_notype/fe074_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe074_notype/fe074_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe074_notype/fe074_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe074_notype/fe074_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe074_notype/fe074_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"876ecccb","metadata":{"papermill":{"duration":0.133263,"end_time":"2023-07-03T08:42:14.558481","exception":false,"start_time":"2023-07-03T08:42:14.425218","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":131,"id":"41e8608c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:14.823877Z","iopub.status.busy":"2023-07-03T08:42:14.82352Z","iopub.status.idle":"2023-07-03T08:42:14.831771Z","shell.execute_reply":"2023-07-03T08:42:14.830895Z"},"papermill":{"duration":0.143194,"end_time":"2023-07-03T08:42:14.83396","exception":false,"start_time":"2023-07-03T08:42:14.690766","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":132,"id":"f2e1d677","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:15.09877Z","iopub.status.busy":"2023-07-03T08:42:15.098429Z","iopub.status.idle":"2023-07-03T08:42:15.110453Z","shell.execute_reply":"2023-07-03T08:42:15.109581Z"},"papermill":{"duration":0.146964,"end_time":"2023-07-03T08:42:15.112473","exception":false,"start_time":"2023-07-03T08:42:14.965509","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            # model = FogRnnModel()\n","            model = FogRnnModel(numeraical_linear_size = 96,\n","                                model_size = 256,\n","                                linear_out = 256,)\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, seq_len, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)"]},{"cell_type":"code","execution_count":133,"id":"06bef0eb","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:15.386757Z","iopub.status.busy":"2023-07-03T08:42:15.386411Z","iopub.status.idle":"2023-07-03T08:42:15.394189Z","shell.execute_reply":"2023-07-03T08:42:15.393297Z"},"papermill":{"duration":0.151552,"end_time":"2023-07-03T08:42:15.396354","exception":false,"start_time":"2023-07-03T08:42:15.244802","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")"]},{"cell_type":"markdown","id":"4b42d900","metadata":{"papermill":{"duration":0.129928,"end_time":"2023-07-03T08:42:15.660189","exception":false,"start_time":"2023-07-03T08:42:15.530261","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## **Feature Engineering with** <font color=red>**pseudo**</font>  **label**\n","\n","<br>\n","\n","### fe073_notype_pseudo_ex153_10000.ipynb\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe073_notype_pseudo_ex153_10000.ipynb\" style=\"text-decoration:none\">fe073_notype_pseudo_ex153_10000.ipynb</a>"]},{"cell_type":"code","execution_count":134,"id":"26701300","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:15.924669Z","iopub.status.busy":"2023-07-03T08:42:15.92431Z","iopub.status.idle":"2023-07-03T08:42:15.929845Z","shell.execute_reply":"2023-07-03T08:42:15.928915Z"},"papermill":{"duration":0.140232,"end_time":"2023-07-03T08:42:15.932096","exception":false,"start_time":"2023-07-03T08:42:15.791864","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"073_notype_pseudo\"\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":135,"id":"c8545206","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:16.200669Z","iopub.status.busy":"2023-07-03T08:42:16.200318Z","iopub.status.idle":"2023-07-03T08:42:16.215034Z","shell.execute_reply":"2023-07-03T08:42:16.214076Z"},"papermill":{"duration":0.152032,"end_time":"2023-07-03T08:42:16.217284","exception":false,"start_time":"2023-07-03T08:42:16.065252","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":136,"id":"4a4a3b0b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:16.490557Z","iopub.status.busy":"2023-07-03T08:42:16.490209Z","iopub.status.idle":"2023-07-03T08:42:16.495818Z","shell.execute_reply":"2023-07-03T08:42:16.4948Z"},"papermill":{"duration":0.141357,"end_time":"2023-07-03T08:42:16.498287","exception":false,"start_time":"2023-07-03T08:42:16.35693","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":137,"id":"ab4ac81a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:16.763636Z","iopub.status.busy":"2023-07-03T08:42:16.763288Z","iopub.status.idle":"2023-07-03T08:42:16.777453Z","shell.execute_reply":"2023-07-03T08:42:16.776363Z"},"papermill":{"duration":0.148481,"end_time":"2023-07-03T08:42:16.780097","exception":false,"start_time":"2023-07-03T08:42:16.631616","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_10000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"code","execution_count":138,"id":"732bc13d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:17.047079Z","iopub.status.busy":"2023-07-03T08:42:17.046684Z","iopub.status.idle":"2023-07-03T08:42:17.051058Z","shell.execute_reply":"2023-07-03T08:42:17.050149Z"},"papermill":{"duration":0.141362,"end_time":"2023-07-03T08:42:17.053147","exception":false,"start_time":"2023-07-03T08:42:16.911785","status":"completed"},"tags":[]},"outputs":[],"source":["# df"]},{"cell_type":"code","execution_count":139,"id":"d0cf0b57","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:17.330407Z","iopub.status.busy":"2023-07-03T08:42:17.330036Z","iopub.status.idle":"2023-07-03T08:42:17.334421Z","shell.execute_reply":"2023-07-03T08:42:17.333517Z"},"papermill":{"duration":0.146431,"end_time":"2023-07-03T08:42:17.337201","exception":false,"start_time":"2023-07-03T08:42:17.19077","status":"completed"},"tags":[]},"outputs":[],"source":["# pred"]},{"cell_type":"markdown","id":"64a43b57","metadata":{"papermill":{"duration":0.138146,"end_time":"2023-07-03T08:42:17.662861","exception":false,"start_time":"2023-07-03T08:42:17.524715","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe075_notype_pseudo_ex153_15000.ipynb\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe075_notype_pseudo_ex153_15000.ipynb\" style=\"text-decoration:none\">fe075_notype_pseudo_ex153_15000.ipynb</a>"]},{"cell_type":"code","execution_count":140,"id":"74b8c303","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:17.975531Z","iopub.status.busy":"2023-07-03T08:42:17.975178Z","iopub.status.idle":"2023-07-03T08:42:17.980979Z","shell.execute_reply":"2023-07-03T08:42:17.979566Z"},"papermill":{"duration":0.14174,"end_time":"2023-07-03T08:42:17.98296","exception":false,"start_time":"2023-07-03T08:42:17.84122","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"075_notype_pseudo\"\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":141,"id":"714d8f22","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:18.253147Z","iopub.status.busy":"2023-07-03T08:42:18.252148Z","iopub.status.idle":"2023-07-03T08:42:18.262448Z","shell.execute_reply":"2023-07-03T08:42:18.261488Z"},"papermill":{"duration":0.146588,"end_time":"2023-07-03T08:42:18.264788","exception":false,"start_time":"2023-07-03T08:42:18.1182","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":142,"id":"c7b2fadf","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:18.53742Z","iopub.status.busy":"2023-07-03T08:42:18.536668Z","iopub.status.idle":"2023-07-03T08:42:18.542958Z","shell.execute_reply":"2023-07-03T08:42:18.542108Z"},"papermill":{"duration":0.140101,"end_time":"2023-07-03T08:42:18.544956","exception":false,"start_time":"2023-07-03T08:42:18.404855","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":143,"id":"1db732bc","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:18.811376Z","iopub.status.busy":"2023-07-03T08:42:18.811008Z","iopub.status.idle":"2023-07-03T08:42:18.826154Z","shell.execute_reply":"2023-07-03T08:42:18.825254Z"},"papermill":{"duration":0.15276,"end_time":"2023-07-03T08:42:18.828172","exception":false,"start_time":"2023-07-03T08:42:18.675412","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_15000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"code","execution_count":144,"id":"2c0356f7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:19.092217Z","iopub.status.busy":"2023-07-03T08:42:19.091833Z","iopub.status.idle":"2023-07-03T08:42:19.096196Z","shell.execute_reply":"2023-07-03T08:42:19.095145Z"},"papermill":{"duration":0.139333,"end_time":"2023-07-03T08:42:19.09851","exception":false,"start_time":"2023-07-03T08:42:18.959177","status":"completed"},"tags":[]},"outputs":[],"source":["# df"]},{"cell_type":"code","execution_count":145,"id":"7d83beb9","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:19.371005Z","iopub.status.busy":"2023-07-03T08:42:19.370629Z","iopub.status.idle":"2023-07-03T08:42:19.374701Z","shell.execute_reply":"2023-07-03T08:42:19.3738Z"},"papermill":{"duration":0.142475,"end_time":"2023-07-03T08:42:19.376725","exception":false,"start_time":"2023-07-03T08:42:19.23425","status":"completed"},"tags":[]},"outputs":[],"source":["# pred"]},{"cell_type":"markdown","id":"57032251","metadata":{"papermill":{"duration":0.136085,"end_time":"2023-07-03T08:42:19.645031","exception":false,"start_time":"2023-07-03T08:42:19.508946","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe086_notype_pseudo_ex154_15000.ipynb\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe086_notype_pseudo_ex154_15000.ipynb\" style=\"text-decoration:none\">fe086_notype_pseudo_ex154_15000.ipynb</a>"]},{"cell_type":"code","execution_count":146,"id":"6ada4297","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:19.907201Z","iopub.status.busy":"2023-07-03T08:42:19.906807Z","iopub.status.idle":"2023-07-03T08:42:19.912293Z","shell.execute_reply":"2023-07-03T08:42:19.911324Z"},"papermill":{"duration":0.139373,"end_time":"2023-07-03T08:42:19.914321","exception":false,"start_time":"2023-07-03T08:42:19.774948","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"086_notype_pseudo\"\n","ex = \"154_defog\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":147,"id":"f5bbaf7a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:20.178466Z","iopub.status.busy":"2023-07-03T08:42:20.178129Z","iopub.status.idle":"2023-07-03T08:42:20.188075Z","shell.execute_reply":"2023-07-03T08:42:20.187121Z"},"papermill":{"duration":0.146289,"end_time":"2023-07-03T08:42:20.190345","exception":false,"start_time":"2023-07-03T08:42:20.044056","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":148,"id":"dcd876a4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:20.466858Z","iopub.status.busy":"2023-07-03T08:42:20.465894Z","iopub.status.idle":"2023-07-03T08:42:20.472013Z","shell.execute_reply":"2023-07-03T08:42:20.471104Z"},"papermill":{"duration":0.14339,"end_time":"2023-07-03T08:42:20.473902","exception":false,"start_time":"2023-07-03T08:42:20.330512","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":149,"id":"0de3ab1a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:20.73683Z","iopub.status.busy":"2023-07-03T08:42:20.736452Z","iopub.status.idle":"2023-07-03T08:42:20.751067Z","shell.execute_reply":"2023-07-03T08:42:20.750051Z"},"papermill":{"duration":0.150159,"end_time":"2023-07-03T08:42:20.753185","exception":false,"start_time":"2023-07-03T08:42:20.603026","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_15000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"code","execution_count":150,"id":"95a0b80f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:21.018105Z","iopub.status.busy":"2023-07-03T08:42:21.01775Z","iopub.status.idle":"2023-07-03T08:42:21.021762Z","shell.execute_reply":"2023-07-03T08:42:21.020893Z"},"papermill":{"duration":0.138076,"end_time":"2023-07-03T08:42:21.023786","exception":false,"start_time":"2023-07-03T08:42:20.88571","status":"completed"},"tags":[]},"outputs":[],"source":["# df"]},{"cell_type":"code","execution_count":151,"id":"3d194c6f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:21.346051Z","iopub.status.busy":"2023-07-03T08:42:21.345675Z","iopub.status.idle":"2023-07-03T08:42:21.349807Z","shell.execute_reply":"2023-07-03T08:42:21.34893Z"},"papermill":{"duration":0.143237,"end_time":"2023-07-03T08:42:21.351919","exception":false,"start_time":"2023-07-03T08:42:21.208682","status":"completed"},"tags":[]},"outputs":[],"source":["# pred"]},{"cell_type":"markdown","id":"a06376c8","metadata":{"papermill":{"duration":0.129378,"end_time":"2023-07-03T08:42:21.617917","exception":false,"start_time":"2023-07-03T08:42:21.488539","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","##  <font color=red>**Training**</font> **with** <font color=red>**pseudo**</font> **label** (round1)\n","\n","\n","\n","<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":152,"id":"5e7e949c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:21.88038Z","iopub.status.busy":"2023-07-03T08:42:21.880028Z","iopub.status.idle":"2023-07-03T08:42:37.655756Z","shell.execute_reply":"2023-07-03T08:42:37.654767Z"},"papermill":{"duration":15.910403,"end_time":"2023-07-03T08:42:37.658603","exception":false,"start_time":"2023-07-03T08:42:21.7482","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe047/fe047_id.parquet\"\n","numerical_path = f\"./output/fe/fe047/fe047_num_array.npy\"\n","target_path    = f\"./output/fe/fe047/fe047_target_array.npy\"\n","mask_path      = f\"./output/fe/fe047/fe047_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe047/fe047_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe047/fe047_pred_use_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)"]},{"cell_type":"code","execution_count":153,"id":"a404edec","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:37.972615Z","iopub.status.busy":"2023-07-03T08:42:37.972236Z","iopub.status.idle":"2023-07-03T08:42:38.189789Z","shell.execute_reply":"2023-07-03T08:42:38.188759Z"},"papermill":{"duration":0.35576,"end_time":"2023-07-03T08:42:38.192369","exception":false,"start_time":"2023-07-03T08:42:37.836609","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    4107\n","2     897\n","3     354\n","1      11\n","Name: group, dtype: int64"]},"execution_count":153,"metadata":{},"output_type":"execute_result"}],"source":["target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i,:,0]))\n","    target2.append(np.sum(target_array[i,:,1]))\n","    target3.append(np.sum(target_array[i,:,2]))\n","\n","df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)\n","\n","df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3\n","\n","df_id[\"group\"].value_counts()"]},{"cell_type":"code","execution_count":154,"id":"f1fde2bb","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:38.461513Z","iopub.status.busy":"2023-07-03T08:42:38.461172Z","iopub.status.idle":"2023-07-03T08:42:47.807075Z","shell.execute_reply":"2023-07-03T08:42:47.80588Z"},"papermill":{"duration":9.488219,"end_time":"2023-07-03T08:42:47.812286","exception":false,"start_time":"2023-07-03T08:42:38.324067","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_id_path        = f\"./output/fe/fe061_notype/fe061_notype_id.parquet\"\n","pseudo_numerical_path = f\"./output/fe/fe061_notype/fe061_notype_num_array.npy\"\n","pseudo_mask_path      = f\"./output/fe/fe061_notype/fe061_notype_mask_array.npy\"\n","pseudo_valid_path     = f\"./output/fe/fe061_notype/fe061_notype_valid_array.npy\"\n","pseudo_pred_use_path  = f\"./output/fe/fe061_notype/fe061_notype_pred_use_array.npy\"\n","\n","pseudo_numerical_array = np.load(pseudo_numerical_path)\n","pseudo_mask_array      = np.load(pseudo_mask_path)\n","pseudo_valid_array     = np.load(pseudo_valid_path)\n","pseudo_pred_use_array  = np.load(pseudo_pred_use_path)"]},{"cell_type":"markdown","id":"18c2fd29","metadata":{"papermill":{"duration":0.131959,"end_time":"2023-07-03T08:42:48.087601","exception":false,"start_time":"2023-07-03T08:42:47.955642","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":155,"id":"91afb737","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:48.358309Z","iopub.status.busy":"2023-07-03T08:42:48.357869Z","iopub.status.idle":"2023-07-03T08:42:48.368721Z","shell.execute_reply":"2023-07-03T08:42:48.367296Z"},"papermill":{"duration":0.150196,"end_time":"2023-07-03T08:42:48.371678","exception":false,"start_time":"2023-07-03T08:42:48.221482","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 10\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"b2802ce5","metadata":{"papermill":{"duration":0.134052,"end_time":"2023-07-03T08:42:48.639813","exception":false,"start_time":"2023-07-03T08:42:48.505761","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex175_defog_gru_pseudo.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex175_defog_gru_pseudo.ipynb\" style=\"text-decoration:none\">ex175_defog_gru_pseudo.ipynb</a>"]},{"cell_type":"code","execution_count":156,"id":"a16f645f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:48.913295Z","iopub.status.busy":"2023-07-03T08:42:48.912945Z","iopub.status.idle":"2023-07-03T08:42:48.919185Z","shell.execute_reply":"2023-07-03T08:42:48.918313Z"},"papermill":{"duration":0.144483,"end_time":"2023-07-03T08:42:48.921381","exception":false,"start_time":"2023-07-03T08:42:48.776898","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"175_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":157,"id":"c525b6b5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:49.188114Z","iopub.status.busy":"2023-07-03T08:42:49.187208Z","iopub.status.idle":"2023-07-03T08:42:49.192192Z","shell.execute_reply":"2023-07-03T08:42:49.191218Z"},"papermill":{"duration":0.141641,"end_time":"2023-07-03T08:42:49.194176","exception":false,"start_time":"2023-07-03T08:42:49.052535","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_target = \"073_notype_pseudo\""]},{"cell_type":"markdown","id":"092d215b","metadata":{"papermill":{"duration":0.132506,"end_time":"2023-07-03T08:42:49.463855","exception":false,"start_time":"2023-07-03T08:42:49.331349","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":158,"id":"bbb7dff4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:49.733569Z","iopub.status.busy":"2023-07-03T08:42:49.733232Z","iopub.status.idle":"2023-07-03T08:42:49.763488Z","shell.execute_reply":"2023-07-03T08:42:49.762131Z"},"papermill":{"duration":0.166963,"end_time":"2023-07-03T08:42:49.765538","exception":false,"start_time":"2023-07-03T08:42:49.598575","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 9.54 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"0e44d8ae","metadata":{"papermill":{"duration":0.130832,"end_time":"2023-07-03T08:42:50.029566","exception":false,"start_time":"2023-07-03T08:42:49.898734","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":159,"id":"d07ba76f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:50.34831Z","iopub.status.busy":"2023-07-03T08:42:50.347947Z","iopub.status.idle":"2023-07-03T08:42:50.354612Z","shell.execute_reply":"2023-07-03T08:42:50.353679Z"},"papermill":{"duration":0.143984,"end_time":"2023-07-03T08:42:50.356895","exception":false,"start_time":"2023-07-03T08:42:50.212911","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"76fafee8","metadata":{"papermill":{"duration":0.134919,"end_time":"2023-07-03T08:42:50.62233","exception":false,"start_time":"2023-07-03T08:42:50.487411","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex179_defog_gru_pseudo.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex179_defog_gru_pseudo.ipynb\" style=\"text-decoration:none\">ex179_defog_gru_pseudo.ipynb</a>"]},{"cell_type":"code","execution_count":160,"id":"903e692d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:50.897503Z","iopub.status.busy":"2023-07-03T08:42:50.896242Z","iopub.status.idle":"2023-07-03T08:42:50.903467Z","shell.execute_reply":"2023-07-03T08:42:50.902562Z"},"papermill":{"duration":0.146828,"end_time":"2023-07-03T08:42:50.906044","exception":false,"start_time":"2023-07-03T08:42:50.759216","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"179_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":161,"id":"631cf2ee","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:51.178801Z","iopub.status.busy":"2023-07-03T08:42:51.177793Z","iopub.status.idle":"2023-07-03T08:42:51.182762Z","shell.execute_reply":"2023-07-03T08:42:51.181684Z"},"papermill":{"duration":0.14546,"end_time":"2023-07-03T08:42:51.185255","exception":false,"start_time":"2023-07-03T08:42:51.039795","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 5000\n","\n","pseudo_target = \"075_notype_pseudo\""]},{"cell_type":"markdown","id":"21f83734","metadata":{"papermill":{"duration":0.137556,"end_time":"2023-07-03T08:42:51.455597","exception":false,"start_time":"2023-07-03T08:42:51.318041","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":162,"id":"95ac3882","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:51.751288Z","iopub.status.busy":"2023-07-03T08:42:51.750933Z","iopub.status.idle":"2023-07-03T08:42:51.776108Z","shell.execute_reply":"2023-07-03T08:42:51.775054Z"},"papermill":{"duration":0.170015,"end_time":"2023-07-03T08:42:51.779703","exception":false,"start_time":"2023-07-03T08:42:51.609688","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 10.5 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), seq_len, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, seq_len, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"f35894db","metadata":{"papermill":{"duration":0.131127,"end_time":"2023-07-03T08:42:52.041316","exception":false,"start_time":"2023-07-03T08:42:51.910189","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":163,"id":"cf055ea1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:52.311373Z","iopub.status.busy":"2023-07-03T08:42:52.310795Z","iopub.status.idle":"2023-07-03T08:42:52.318064Z","shell.execute_reply":"2023-07-03T08:42:52.317181Z"},"papermill":{"duration":0.145111,"end_time":"2023-07-03T08:42:52.320483","exception":false,"start_time":"2023-07-03T08:42:52.175372","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"a8bb1136","metadata":{"papermill":{"duration":0.136681,"end_time":"2023-07-03T08:42:52.589786","exception":false,"start_time":"2023-07-03T08:42:52.453105","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex204_defog_gru_pseudo.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex204_defog_gru_pseudo.ipynb\" style=\"text-decoration:none\">ex204_defog_gru_pseudo.ipynb</a>"]},{"cell_type":"code","execution_count":164,"id":"d979fad1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:52.860519Z","iopub.status.busy":"2023-07-03T08:42:52.860164Z","iopub.status.idle":"2023-07-03T08:42:52.865813Z","shell.execute_reply":"2023-07-03T08:42:52.864917Z"},"papermill":{"duration":0.143692,"end_time":"2023-07-03T08:42:52.867898","exception":false,"start_time":"2023-07-03T08:42:52.724206","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"204_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":165,"id":"0b9b6667","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:53.139755Z","iopub.status.busy":"2023-07-03T08:42:53.1394Z","iopub.status.idle":"2023-07-03T08:42:53.143906Z","shell.execute_reply":"2023-07-03T08:42:53.142864Z"},"papermill":{"duration":0.143902,"end_time":"2023-07-03T08:42:53.146441","exception":false,"start_time":"2023-07-03T08:42:53.002539","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_target = \"086_notype_pseudo\""]},{"cell_type":"markdown","id":"3df05987","metadata":{"papermill":{"duration":0.133292,"end_time":"2023-07-03T08:42:53.411735","exception":false,"start_time":"2023-07-03T08:42:53.278443","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":166,"id":"6e5d2bdb","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:53.6825Z","iopub.status.busy":"2023-07-03T08:42:53.682149Z","iopub.status.idle":"2023-07-03T08:42:53.7128Z","shell.execute_reply":"2023-07-03T08:42:53.711375Z"},"papermill":{"duration":0.168708,"end_time":"2023-07-03T08:42:53.715224","exception":false,"start_time":"2023-07-03T08:42:53.546516","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n","Wall time: 8.82 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            # model = FogRnnModel()\n","            model = FogRnnModel(numeraical_linear_size = 96,\n","                                model_size = 256,\n","                                linear_out = 256,)            \n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"02bcb724","metadata":{"papermill":{"duration":0.134929,"end_time":"2023-07-03T08:42:54.031961","exception":false,"start_time":"2023-07-03T08:42:53.897032","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":167,"id":"40169401","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:54.30402Z","iopub.status.busy":"2023-07-03T08:42:54.303013Z","iopub.status.idle":"2023-07-03T08:42:54.310485Z","shell.execute_reply":"2023-07-03T08:42:54.309582Z"},"papermill":{"duration":0.145909,"end_time":"2023-07-03T08:42:54.312516","exception":false,"start_time":"2023-07-03T08:42:54.166607","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"697d3859","metadata":{"papermill":{"duration":0.135208,"end_time":"2023-07-03T08:42:54.578259","exception":false,"start_time":"2023-07-03T08:42:54.443051","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## <font color=blue>**ROUND 2**</font>\n","\n","<br>\n","<br>\n","\n","## <font color=red>**Predicting**</font>: **Making** <font color=red>**pseudo**</font> **label** (round2: use models of ex175 in round 1)\n","\n","\n","<br>\n","\n","### <font color=maroon>ex175_defog_gru_inference_notype_15000.ipynbb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex175_defog_gru_inference_notype_15000.ipynb\" style=\"text-decoration:none\">ex175_defog_gru_inference_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":168,"id":"8f250fb3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:54.852289Z","iopub.status.busy":"2023-07-03T08:42:54.851404Z","iopub.status.idle":"2023-07-03T08:42:54.857755Z","shell.execute_reply":"2023-07-03T08:42:54.856729Z"},"papermill":{"duration":0.149345,"end_time":"2023-07-03T08:42:54.859785","exception":false,"start_time":"2023-07-03T08:42:54.71044","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"175_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"4ae75c5b","metadata":{"papermill":{"duration":0.132251,"end_time":"2023-07-03T08:42:55.124438","exception":false,"start_time":"2023-07-03T08:42:54.992187","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data & preprocessing"]},{"cell_type":"code","execution_count":169,"id":"e6673c5c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:42:55.398573Z","iopub.status.busy":"2023-07-03T08:42:55.398207Z","iopub.status.idle":"2023-07-03T08:43:05.299689Z","shell.execute_reply":"2023-07-03T08:43:05.29865Z"},"papermill":{"duration":10.046148,"end_time":"2023-07-03T08:43:05.303566","exception":false,"start_time":"2023-07-03T08:42:55.257418","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 15000\n","\n","id_path        = f\"./output/fe/fe074_notype/fe074_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe074_notype/fe074_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe074_notype/fe074_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe074_notype/fe074_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe074_notype/fe074_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe074_notype/fe074_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe074_notype/fe074_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"ab0c83d9","metadata":{"papermill":{"duration":0.130783,"end_time":"2023-07-03T08:43:05.564822","exception":false,"start_time":"2023-07-03T08:43:05.434039","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### config"]},{"cell_type":"code","execution_count":170,"id":"da399f95","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:05.831316Z","iopub.status.busy":"2023-07-03T08:43:05.830971Z","iopub.status.idle":"2023-07-03T08:43:05.840228Z","shell.execute_reply":"2023-07-03T08:43:05.839274Z"},"papermill":{"duration":0.143527,"end_time":"2023-07-03T08:43:05.842204","exception":false,"start_time":"2023-07-03T08:43:05.698677","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 15\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"eae8c34c","metadata":{"papermill":{"duration":0.132947,"end_time":"2023-07-03T08:43:06.10576","exception":false,"start_time":"2023-07-03T08:43:05.972813","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":171,"id":"6806d45e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:06.368861Z","iopub.status.busy":"2023-07-03T08:43:06.36848Z","iopub.status.idle":"2023-07-03T08:43:06.375855Z","shell.execute_reply":"2023-07-03T08:43:06.374946Z"},"papermill":{"duration":0.140664,"end_time":"2023-07-03T08:43:06.377931","exception":false,"start_time":"2023-07-03T08:43:06.237267","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":171,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":172,"id":"ed1efa01","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:06.64603Z","iopub.status.busy":"2023-07-03T08:43:06.645638Z","iopub.status.idle":"2023-07-03T08:43:06.655857Z","shell.execute_reply":"2023-07-03T08:43:06.654914Z"},"papermill":{"duration":0.150193,"end_time":"2023-07-03T08:43:06.657903","exception":false,"start_time":"2023-07-03T08:43:06.50771","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            model = FogRnnModel()\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, seq_len, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            # np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_R2_{fold}_oof_{seq_len}.npy\",val_preds)            "]},{"cell_type":"code","execution_count":173,"id":"dcd1e1e1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:06.926764Z","iopub.status.busy":"2023-07-03T08:43:06.926397Z","iopub.status.idle":"2023-07-03T08:43:06.934291Z","shell.execute_reply":"2023-07-03T08:43:06.933407Z"},"papermill":{"duration":0.144628,"end_time":"2023-07-03T08:43:06.936356","exception":false,"start_time":"2023-07-03T08:43:06.791728","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        # pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_R2_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        # pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_R2_{i}_pred_{seq_len}.parquet\")    "]},{"cell_type":"markdown","id":"862fb6c2","metadata":{"papermill":{"duration":0.131163,"end_time":"2023-07-03T08:43:07.202733","exception":false,"start_time":"2023-07-03T08:43:07.07157","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## **Feature Engineering with** <font color=red>**pseudo**</font>  **label** \n","\n","<br>\n","\n","\n","### <font color=maroon>fe078_notype_pseudo_ex175_15000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe078_notype_pseudo_ex175_15000.ipynb\" style=\"text-decoration:none\">fe078_notype_pseudo_ex175_15000.ipynb</a>"]},{"cell_type":"code","execution_count":174,"id":"a086eb21","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:07.522729Z","iopub.status.busy":"2023-07-03T08:43:07.522336Z","iopub.status.idle":"2023-07-03T08:43:07.528237Z","shell.execute_reply":"2023-07-03T08:43:07.527136Z"},"papermill":{"duration":0.146345,"end_time":"2023-07-03T08:43:07.532482","exception":false,"start_time":"2023-07-03T08:43:07.386137","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"078_notype_pseudo\"\n","ex = \"175_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":175,"id":"4894ce12","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:07.850596Z","iopub.status.busy":"2023-07-03T08:43:07.850233Z","iopub.status.idle":"2023-07-03T08:43:07.863187Z","shell.execute_reply":"2023-07-03T08:43:07.862304Z"},"papermill":{"duration":0.193593,"end_time":"2023-07-03T08:43:07.865419","exception":false,"start_time":"2023-07-03T08:43:07.671826","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":176,"id":"4285477e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:08.129542Z","iopub.status.busy":"2023-07-03T08:43:08.129194Z","iopub.status.idle":"2023-07-03T08:43:08.134552Z","shell.execute_reply":"2023-07-03T08:43:08.133606Z"},"papermill":{"duration":0.138703,"end_time":"2023-07-03T08:43:08.136617","exception":false,"start_time":"2023-07-03T08:43:07.997914","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":177,"id":"88fc527d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:08.400296Z","iopub.status.busy":"2023-07-03T08:43:08.39996Z","iopub.status.idle":"2023-07-03T08:43:08.413878Z","shell.execute_reply":"2023-07-03T08:43:08.412899Z"},"papermill":{"duration":0.147675,"end_time":"2023-07-03T08:43:08.415869","exception":false,"start_time":"2023-07-03T08:43:08.268194","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        # pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_15000.parquet\")\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_R2_{fold}_pred_15000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"markdown","id":"422403b2","metadata":{"papermill":{"duration":0.13533,"end_time":"2023-07-03T08:43:08.682602","exception":false,"start_time":"2023-07-03T08:43:08.547272","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","##  <font color=red>**Training**</font> **with** <font color=red>**pseudo**</font> **label** (round2)\n","\n","<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":178,"id":"291d88c2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:08.946671Z","iopub.status.busy":"2023-07-03T08:43:08.946325Z","iopub.status.idle":"2023-07-03T08:43:24.984877Z","shell.execute_reply":"2023-07-03T08:43:24.9836Z"},"papermill":{"duration":16.172142,"end_time":"2023-07-03T08:43:24.988069","exception":false,"start_time":"2023-07-03T08:43:08.815927","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe047/fe047_id.parquet\"\n","numerical_path = f\"./output/fe/fe047/fe047_num_array.npy\"\n","target_path    = f\"./output/fe/fe047/fe047_target_array.npy\"\n","mask_path      = f\"./output/fe/fe047/fe047_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe047/fe047_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe047/fe047_pred_use_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)"]},{"cell_type":"code","execution_count":179,"id":"12186752","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:25.260423Z","iopub.status.busy":"2023-07-03T08:43:25.260075Z","iopub.status.idle":"2023-07-03T08:43:25.481445Z","shell.execute_reply":"2023-07-03T08:43:25.480394Z"},"papermill":{"duration":0.361746,"end_time":"2023-07-03T08:43:25.484179","exception":false,"start_time":"2023-07-03T08:43:25.122433","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    4107\n","2     897\n","3     354\n","1      11\n","Name: group, dtype: int64"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i,:,0]))\n","    target2.append(np.sum(target_array[i,:,1]))\n","    target3.append(np.sum(target_array[i,:,2]))\n","\n","df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)\n","\n","df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3\n","\n","df_id[\"group\"].value_counts()"]},{"cell_type":"code","execution_count":180,"id":"ccf770e9","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:25.75664Z","iopub.status.busy":"2023-07-03T08:43:25.756164Z","iopub.status.idle":"2023-07-03T08:43:35.460135Z","shell.execute_reply":"2023-07-03T08:43:35.455813Z"},"papermill":{"duration":9.848385,"end_time":"2023-07-03T08:43:35.463527","exception":false,"start_time":"2023-07-03T08:43:25.615142","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_id_path        = f\"./output/fe/fe061_notype/fe061_notype_id.parquet\"\n","pseudo_numerical_path = f\"./output/fe/fe061_notype/fe061_notype_num_array.npy\"\n","pseudo_mask_path      = f\"./output/fe/fe061_notype/fe061_notype_mask_array.npy\"\n","pseudo_valid_path     = f\"./output/fe/fe061_notype/fe061_notype_valid_array.npy\"\n","pseudo_pred_use_path  = f\"./output/fe/fe061_notype/fe061_notype_pred_use_array.npy\"\n","\n","pseudo_numerical_array = np.load(pseudo_numerical_path)\n","pseudo_mask_array      = np.load(pseudo_mask_path)\n","pseudo_valid_array     = np.load(pseudo_valid_path)\n","pseudo_pred_use_array  = np.load(pseudo_pred_use_path)"]},{"cell_type":"markdown","id":"6f070db9","metadata":{"papermill":{"duration":0.133565,"end_time":"2023-07-03T08:43:35.730763","exception":false,"start_time":"2023-07-03T08:43:35.597198","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":181,"id":"b6d63113","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:36.001148Z","iopub.status.busy":"2023-07-03T08:43:36.000173Z","iopub.status.idle":"2023-07-03T08:43:36.010603Z","shell.execute_reply":"2023-07-03T08:43:36.009686Z"},"papermill":{"duration":0.14882,"end_time":"2023-07-03T08:43:36.012562","exception":false,"start_time":"2023-07-03T08:43:35.863742","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 5000\n","\n","# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 10\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"42942441","metadata":{"papermill":{"duration":0.13243,"end_time":"2023-07-03T08:43:36.27614","exception":false,"start_time":"2023-07-03T08:43:36.14371","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex185_defog_gru_pseudo2.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex185_defog_gru_pseudo2.ipynb\" style=\"text-decoration:none\">ex185_defog_gru_pseudo2.ipynb</a>"]},{"cell_type":"code","execution_count":182,"id":"78fe2a48","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:36.542608Z","iopub.status.busy":"2023-07-03T08:43:36.542256Z","iopub.status.idle":"2023-07-03T08:43:36.547545Z","shell.execute_reply":"2023-07-03T08:43:36.546613Z"},"papermill":{"duration":0.143554,"end_time":"2023-07-03T08:43:36.549605","exception":false,"start_time":"2023-07-03T08:43:36.406051","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"185_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":183,"id":"2c8a42bd","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:36.820857Z","iopub.status.busy":"2023-07-03T08:43:36.820463Z","iopub.status.idle":"2023-07-03T08:43:36.824988Z","shell.execute_reply":"2023-07-03T08:43:36.824067Z"},"papermill":{"duration":0.146392,"end_time":"2023-07-03T08:43:36.827085","exception":false,"start_time":"2023-07-03T08:43:36.680693","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_target = \"078_notype_pseudo\""]},{"cell_type":"markdown","id":"f4d1ebe7","metadata":{"papermill":{"duration":0.131123,"end_time":"2023-07-03T08:43:37.145094","exception":false,"start_time":"2023-07-03T08:43:37.013971","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":184,"id":"d9992c25","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:37.421865Z","iopub.status.busy":"2023-07-03T08:43:37.421471Z","iopub.status.idle":"2023-07-03T08:43:37.45632Z","shell.execute_reply":"2023-07-03T08:43:37.454952Z"},"papermill":{"duration":0.177601,"end_time":"2023-07-03T08:43:37.458572","exception":false,"start_time":"2023-07-03T08:43:37.280971","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 0 ns, sys: 5 µs, total: 5 µs\n","Wall time: 8.82 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), seq_len, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, seq_len, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"cb6ee721","metadata":{"papermill":{"duration":0.173641,"end_time":"2023-07-03T08:43:37.796723","exception":false,"start_time":"2023-07-03T08:43:37.623082","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":185,"id":"dc3de769","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:38.075579Z","iopub.status.busy":"2023-07-03T08:43:38.075201Z","iopub.status.idle":"2023-07-03T08:43:38.081915Z","shell.execute_reply":"2023-07-03T08:43:38.080957Z"},"papermill":{"duration":0.145565,"end_time":"2023-07-03T08:43:38.083948","exception":false,"start_time":"2023-07-03T08:43:37.938383","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"19ea4603","metadata":{"papermill":{"duration":0.131458,"end_time":"2023-07-03T08:43:38.347979","exception":false,"start_time":"2023-07-03T08:43:38.216521","status":"completed"},"tags":[]},"source":["<br>\n","\n","## **models choosed**\n","\n","<br>\n","\n","<font color=maroon size=4>The following numbered models were used for the final submission:</font>\n","* <font color=maroon size=4>ex153</font>\n","* <font color=maroon size=4>ex179</font>\n","* <font color=maroon size=4>ex185</font>\n","* <font color=maroon size=4>ex204</font>"]},{"cell_type":"markdown","id":"f68e0c62","metadata":{"papermill":{"duration":0.131675,"end_time":"2023-07-03T08:43:38.610526","exception":false,"start_time":"2023-07-03T08:43:38.478851","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","\n","# 【**Inference**】\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://www.kaggle.com/code/takoihiraokazu/cv-ensemble-sub-0607-1\" style=\"text-decoration:none\">[cv]ensemble_sub_0607_1</a>"]},{"cell_type":"markdown","id":"849619a1","metadata":{"papermill":{"duration":0.133596,"end_time":"2023-07-03T08:43:38.88074","exception":false,"start_time":"2023-07-03T08:43:38.747144","status":"completed"},"tags":[]},"source":["<br>\n","\n","## Config"]},{"cell_type":"code","execution_count":186,"id":"4a7ac9c3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:39.149903Z","iopub.status.busy":"2023-07-03T08:43:39.149189Z","iopub.status.idle":"2023-07-03T08:43:39.153296Z","shell.execute_reply":"2023-07-03T08:43:39.15244Z"},"papermill":{"duration":0.141603,"end_time":"2023-07-03T08:43:39.15523","exception":false,"start_time":"2023-07-03T08:43:39.013627","status":"completed"},"tags":[]},"outputs":[],"source":["# SUB_PATH          = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv\"\n","# DEFOG_DATA_PATH   = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/*.csv\"\n","# TDCSFOG_DATA_PATH = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/*.csv\""]},{"cell_type":"code","execution_count":187,"id":"6cf6f076","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:39.438371Z","iopub.status.busy":"2023-07-03T08:43:39.437986Z","iopub.status.idle":"2023-07-03T08:43:39.443339Z","shell.execute_reply":"2023-07-03T08:43:39.442241Z"},"papermill":{"duration":0.150721,"end_time":"2023-07-03T08:43:39.445633","exception":false,"start_time":"2023-07-03T08:43:39.294912","status":"completed"},"tags":[]},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","bs = 32"]},{"cell_type":"code","execution_count":188,"id":"6d4751ad","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:39.724869Z","iopub.status.busy":"2023-07-03T08:43:39.724014Z","iopub.status.idle":"2023-07-03T08:43:39.732826Z","shell.execute_reply":"2023-07-03T08:43:39.731938Z"},"papermill":{"duration":0.15043,"end_time":"2023-07-03T08:43:39.734819","exception":false,"start_time":"2023-07-03T08:43:39.584389","status":"completed"},"tags":[]},"outputs":[],"source":["# sub = pd.read_csv(SUB_PATH)\n","\n","# # sub = pd.read_csv(root_data + 'sample_submission.csv')"]},{"cell_type":"code","execution_count":189,"id":"5c4720bd","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:40.008398Z","iopub.status.busy":"2023-07-03T08:43:40.007084Z","iopub.status.idle":"2023-07-03T08:43:40.012287Z","shell.execute_reply":"2023-07-03T08:43:40.01135Z"},"papermill":{"duration":0.143624,"end_time":"2023-07-03T08:43:40.014396","exception":false,"start_time":"2023-07-03T08:43:39.870772","status":"completed"},"tags":[]},"outputs":[],"source":["df_all = []"]},{"cell_type":"markdown","id":"7180f595","metadata":{"papermill":{"duration":0.135106,"end_time":"2023-07-03T08:43:40.283725","exception":false,"start_time":"2023-07-03T08:43:40.148619","status":"completed"},"tags":[]},"source":["<br>\n","\n","## Helpers\n","\n","<br>\n","\n","### def `preprocess()`"]},{"cell_type":"code","execution_count":190,"id":"753888af","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:40.5537Z","iopub.status.busy":"2023-07-03T08:43:40.553334Z","iopub.status.idle":"2023-07-03T08:43:40.559251Z","shell.execute_reply":"2023-07-03T08:43:40.558348Z"},"papermill":{"duration":0.140629,"end_time":"2023-07-03T08:43:40.561182","exception":false,"start_time":"2023-07-03T08:43:40.420553","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array):\n","    \n","    attention_mask = mask_array == 0\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"684c90e5","metadata":{"papermill":{"duration":0.136986,"end_time":"2023-07-03T08:43:40.888325","exception":false,"start_time":"2023-07-03T08:43:40.751339","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `FogDataset()`"]},{"cell_type":"code","execution_count":191,"id":"bf47356b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:41.157107Z","iopub.status.busy":"2023-07-03T08:43:41.1567Z","iopub.status.idle":"2023-07-03T08:43:41.167945Z","shell.execute_reply":"2023-07-03T08:43:41.166949Z"},"papermill":{"duration":0.147776,"end_time":"2023-07-03T08:43:41.170073","exception":false,"start_time":"2023-07-03T08:43:41.022297","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.train = train\n","        self.y = y\n","    \n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","    \n","    \n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item])\n","\n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'],  dtype=torch.long),              \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\": torch.tensor(self.y[item], dtype=torch.float32)\n","            }\n","        else:\n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'], dtype=torch.long),\n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"d287fc9c","metadata":{"papermill":{"duration":0.131137,"end_time":"2023-07-03T08:43:41.436765","exception":false,"start_time":"2023-07-03T08:43:41.305628","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `TdcsfogRnnModel()`"]},{"cell_type":"code","execution_count":192,"id":"fcbe80fa","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:41.699474Z","iopub.status.busy":"2023-07-03T08:43:41.699104Z","iopub.status.idle":"2023-07-03T08:43:41.712758Z","shell.execute_reply":"2023-07-03T08:43:41.711815Z"},"papermill":{"duration":0.147075,"end_time":"2023-07-03T08:43:41.714851","exception":false,"start_time":"2023-07-03T08:43:41.567776","status":"completed"},"tags":[]},"outputs":[],"source":["class TdcsfogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=12,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(TdcsfogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"ab12ceea","metadata":{"papermill":{"duration":0.13477,"end_time":"2023-07-03T08:43:41.993067","exception":false,"start_time":"2023-07-03T08:43:41.858297","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `TdcsfogRnnModel2()`"]},{"cell_type":"code","execution_count":193,"id":"865c4956","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:42.259817Z","iopub.status.busy":"2023-07-03T08:43:42.259447Z","iopub.status.idle":"2023-07-03T08:43:42.27269Z","shell.execute_reply":"2023-07-03T08:43:42.271742Z"},"papermill":{"duration":0.149516,"end_time":"2023-07-03T08:43:42.274754","exception":false,"start_time":"2023-07-03T08:43:42.125238","status":"completed"},"tags":[]},"outputs":[],"source":["class TdcsfogRnnModel2(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=12,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(TdcsfogRnnModel2, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         # nn.Linear(linear_out, out_size)\n","                                         )\n","        self.out1 = nn.Linear(linear_out, out_size)\n","        self.out2 = nn.Linear(linear_out, out_size)\n","        \n","        \n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        # return output\n","        \n","        output1 = self.out1(output)\n","        output2 = self.out2(output)\n","        return output1, output2"]},{"cell_type":"markdown","id":"3f2e2220","metadata":{"papermill":{"duration":0.132629,"end_time":"2023-07-03T08:43:42.541054","exception":false,"start_time":"2023-07-03T08:43:42.408425","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `DefogRnnModel()`"]},{"cell_type":"code","execution_count":194,"id":"a6d160be","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:42.808924Z","iopub.status.busy":"2023-07-03T08:43:42.808534Z","iopub.status.idle":"2023-07-03T08:43:42.820675Z","shell.execute_reply":"2023-07-03T08:43:42.819839Z"},"papermill":{"duration":0.150259,"end_time":"2023-07-03T08:43:42.82266","exception":false,"start_time":"2023-07-03T08:43:42.672401","status":"completed"},"tags":[]},"outputs":[],"source":["class DefogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(DefogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"81114e31","metadata":{"papermill":{"duration":0.130441,"end_time":"2023-07-03T08:43:43.084961","exception":false,"start_time":"2023-07-03T08:43:42.95452","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `DefogRnnModel2()`"]},{"cell_type":"code","execution_count":195,"id":"789602c8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:43.353036Z","iopub.status.busy":"2023-07-03T08:43:43.352677Z","iopub.status.idle":"2023-07-03T08:43:43.36449Z","shell.execute_reply":"2023-07-03T08:43:43.36366Z"},"papermill":{"duration":0.149786,"end_time":"2023-07-03T08:43:43.366513","exception":false,"start_time":"2023-07-03T08:43:43.216727","status":"completed"},"tags":[]},"outputs":[],"source":["class DefogRnnModel2(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 96,\n","                 model_size = 256,\n","                 linear_out = 256,\n","                 out_size=3):\n","        \n","        super(DefogRnnModel2, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"46507256","metadata":{"papermill":{"duration":0.138099,"end_time":"2023-07-03T08:43:43.637227","exception":false,"start_time":"2023-07-03T08:43:43.499128","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `Defog3Model()`"]},{"cell_type":"code","execution_count":196,"id":"6b7f2f71","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:43.903955Z","iopub.status.busy":"2023-07-03T08:43:43.903579Z","iopub.status.idle":"2023-07-03T08:43:43.914906Z","shell.execute_reply":"2023-07-03T08:43:43.914014Z"},"papermill":{"duration":0.145027,"end_time":"2023-07-03T08:43:43.916949","exception":false,"start_time":"2023-07-03T08:43:43.771922","status":"completed"},"tags":[]},"outputs":[],"source":["class Defog3Model(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(Defog3Model, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.lstm = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'lstm' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"fa1524f5","metadata":{"papermill":{"duration":0.131512,"end_time":"2023-07-03T08:43:44.186228","exception":false,"start_time":"2023-07-03T08:43:44.054716","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `make_pred()`"]},{"cell_type":"code","execution_count":197,"id":"2aa1278c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:44.503788Z","iopub.status.busy":"2023-07-03T08:43:44.503131Z","iopub.status.idle":"2023-07-03T08:43:44.509628Z","shell.execute_reply":"2023-07-03T08:43:44.508771Z"},"papermill":{"duration":0.140377,"end_time":"2023-07-03T08:43:44.51154","exception":false,"start_time":"2023-07-03T08:43:44.371163","status":"completed"},"tags":[]},"outputs":[],"source":["def make_pred(test_loader, model):\n","    test_preds = []\n","    # tk0 = tqdm(test_loader, total=len(test_loader), desc=\"test_loader: \")\n","    with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","        # Predicting on validation set\n","        # for d in tk0:\n","        for d in test_loader:\n","            input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","            input_data_mask_array      = d['input_data_mask_array'].to(device)\n","            attention_mask             = d['attention_mask'].to(device)\n","            output = model(input_data_numerical_array, \n","                           input_data_mask_array,\n","                           attention_mask)\n","            test_preds.append(output.sigmoid().cpu().numpy())\n","    test_preds = np.concatenate(test_preds, axis=0)\n","    return test_preds"]},{"cell_type":"markdown","id":"2ed56cf4","metadata":{"papermill":{"duration":0.138428,"end_time":"2023-07-03T08:43:44.786711","exception":false,"start_time":"2023-07-03T08:43:44.648283","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `make_pred2()`"]},{"cell_type":"code","execution_count":198,"id":"5195ca57","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:45.056355Z","iopub.status.busy":"2023-07-03T08:43:45.055997Z","iopub.status.idle":"2023-07-03T08:43:45.062636Z","shell.execute_reply":"2023-07-03T08:43:45.061744Z"},"papermill":{"duration":0.146894,"end_time":"2023-07-03T08:43:45.064685","exception":false,"start_time":"2023-07-03T08:43:44.917791","status":"completed"},"tags":[]},"outputs":[],"source":["def make_pred2(test_loader, model):\n","    test_preds = []\n","    # tk0 = tqdm(test_loader, total=len(test_loader), desc=\"test_loader: \")\n","    with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","        # Predicting on validation set\n","        # for d in tk0:\n","        for d in test_loader:\n","            input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","            input_data_mask_array      = d['input_data_mask_array'].to(device)\n","            attention_mask             = d['attention_mask'].to(device)\n","            \n","            output, _ = model(input_data_numerical_array, \n","                             input_data_mask_array,\n","                             attention_mask)\n","            test_preds.append(output.sigmoid().cpu().numpy())\n","    test_preds = np.concatenate(test_preds, axis=0)\n","    return test_preds"]},{"cell_type":"markdown","id":"07c45253","metadata":{"papermill":{"duration":0.196983,"end_time":"2023-07-03T08:43:45.457473","exception":false,"start_time":"2023-07-03T08:43:45.26049","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>tdcsfog models</font>\n","\n","### checkpoint paths"]},{"cell_type":"code","execution_count":199,"id":"242c87b3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:45.842019Z","iopub.status.busy":"2023-07-03T08:43:45.841433Z","iopub.status.idle":"2023-07-03T08:43:45.847104Z","shell.execute_reply":"2023-07-03T08:43:45.84581Z"},"papermill":{"duration":0.206715,"end_time":"2023-07-03T08:43:45.852305","exception":false,"start_time":"2023-07-03T08:43:45.64559","status":"completed"},"tags":[]},"outputs":[],"source":["# tdcsfog_path1   = [f\"/kaggle/input/fog-ex143/ex143_{i}.pth\" for i in range(5)] # len 3000 cv TdcsfogRnnModel\n","# tdcsfog_path3_1 = [f\"/kaggle/input/fog-ex145/ex145_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel  \n","# tdcsfog_path3_2 = [f\"/kaggle/input/fog-ex146/ex146_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel \n","# tdcsfog_path3_3 = [f\"/kaggle/input/fog-ex147/ex147_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel\n","# tdcsfog_path4_1 = [f\"/kaggle/input/fog-ex182/ex182_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel  \n","# tdcsfog_path4_2 = [f\"/kaggle/input/fog-ex183/ex183_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel \n","# tdcsfog_path4_3 = [f\"/kaggle/input/fog-ex184/ex184_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel"]},{"cell_type":"code","execution_count":200,"id":"0ad42d19","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:46.24321Z","iopub.status.busy":"2023-07-03T08:43:46.242778Z","iopub.status.idle":"2023-07-03T08:43:46.275396Z","shell.execute_reply":"2023-07-03T08:43:46.274487Z"},"papermill":{"duration":0.233585,"end_time":"2023-07-03T08:43:46.278106","exception":false,"start_time":"2023-07-03T08:43:46.044521","status":"completed"},"tags":[]},"outputs":[],"source":["tdcsfog_path1     = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex143*\")\n","tdcsfog_path3_1   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex145*\")\n","tdcsfog_path3_2   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex146*\")\n","tdcsfog_path3_3   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex147*\")\n","tdcsfog_path4_1   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex182*\")\n","tdcsfog_path4_2   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex183*\")\n","tdcsfog_path4_3   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex184*\")"]},{"cell_type":"markdown","id":"f8d06637","metadata":{"papermill":{"duration":0.172015,"end_time":"2023-07-03T08:43:46.636661","exception":false,"start_time":"2023-07-03T08:43:46.464646","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex143** (tdcsfog1: 0.2)\n","\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":201,"id":"34af81c0","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:46.904065Z","iopub.status.busy":"2023-07-03T08:43:46.903705Z","iopub.status.idle":"2023-07-03T08:43:54.537537Z","shell.execute_reply":"2023-07-03T08:43:54.536587Z"},"papermill":{"duration":7.770487,"end_time":"2023-07-03T08:43:54.540043","exception":false,"start_time":"2023-07-03T08:43:46.769556","status":"completed"},"tags":[]},"outputs":[],"source":["# TdcsfogRnnModel()\n","\n","tdcsfog_model_list1 = []\n","for i in tdcsfog_path1:  # ex143\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list1.append(model)"]},{"cell_type":"markdown","id":"e3b1e732","metadata":{"papermill":{"duration":0.138612,"end_time":"2023-07-03T08:43:54.815447","exception":false,"start_time":"2023-07-03T08:43:54.676835","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":202,"id":"f702955c","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:43:55.081241Z","iopub.status.busy":"2023-07-03T08:43:55.080832Z","iopub.status.idle":"2023-07-03T08:43:55.58897Z","shell.execute_reply":"2023-07-03T08:43:55.587998Z"},"papermill":{"duration":0.643183,"end_time":"2023-07-03T08:43:55.591083","exception":false,"start_time":"2023-07-03T08:43:54.9479","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_tdcsfog: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 203 ms, sys: 22.2 ms, total: 225 ms\n","Wall time: 483 ms\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# tdcsfog1\n","# =========================\n","th_len = 5000\n","w = 0.20\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = ['AccV', 'AccML', 'AccAP', \n","            'AccV_lag_diff',  'AccV_lead_diff', 'AccV_cumsum', \n","            'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","            'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","\n","# tdcsfog_list = glob.glob(TDCSFOG_DATA_PATH)\n","# for p in tqdm(tdcsfog_list):\n","for p in tqdm(test_tdcsfog, desc=\"test_tdcsfog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    df = pd.read_csv(p)\n","    \n","    if len(df) > th_len:\n","        seq_len = 5000\n","        shift = 2500\n","        offset = 1250\n","    else:\n","        seq_len = 3000\n","        shift = 1500\n","        offset = 750\n","        \n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 12])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_ = num.copy()\n","        time_ = time.copy()\n","        num_len = len(num_)\n","\n","        num_array[b,:num_len,:] = num_\n","        time_array[b,:num_len] = time_\n","        mask_array[b,:num_len] = 1\n","        pred_use_array[b,:num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b, :num_len, :] = num_\n","                time_array[b,:num_len] = time_\n","                mask_array[b,:num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b, :shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,offset : shift+offset] = 1\n","            \n","            \n","\n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(tdcsfog_model_list1):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(tdcsfog_model_list1)\n","        else:\n","            pred += make_pred(test_loader,m) / len(tdcsfog_model_list1)\n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i, mask_ == 1, :]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:, 0] * w\n","        df_[\"Turn\"] = pred_[:, 1] * w\n","        df_[\"Walking\"] = pred_[:, 2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"5483fb2f","metadata":{"papermill":{"duration":0.141943,"end_time":"2023-07-03T08:43:55.868541","exception":false,"start_time":"2023-07-03T08:43:55.726598","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex145, ex146, ex147** (tdcsfog3: 0.4)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":203,"id":"38ec54ff","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:56.146069Z","iopub.status.busy":"2023-07-03T08:43:56.145645Z","iopub.status.idle":"2023-07-03T08:43:57.098833Z","shell.execute_reply":"2023-07-03T08:43:57.097875Z"},"papermill":{"duration":1.094273,"end_time":"2023-07-03T08:43:57.10121","exception":false,"start_time":"2023-07-03T08:43:56.006937","status":"completed"},"tags":[]},"outputs":[],"source":["# TdcsfogRnnModel()\n","\n","tdcsfog_model_list3_1 = []\n","for i in tdcsfog_path3_1:  # ex145\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list3_1.append(model)\n","\n","\n","tdcsfog_model_list3_2 = []\n","for i in tdcsfog_path3_2:  # ex146\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list3_2.append(model)\n","\n","\n","tdcsfog_model_list3_3 = []\n","for i in tdcsfog_path3_3:  # ex147\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list3_3.append(model)"]},{"cell_type":"markdown","id":"73804a6e","metadata":{"papermill":{"duration":0.133153,"end_time":"2023-07-03T08:43:57.367381","exception":false,"start_time":"2023-07-03T08:43:57.234228","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":204,"id":"45b3b19d","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:43:57.689919Z","iopub.status.busy":"2023-07-03T08:43:57.689562Z","iopub.status.idle":"2023-07-03T08:43:58.120665Z","shell.execute_reply":"2023-07-03T08:43:58.119486Z"},"papermill":{"duration":0.566694,"end_time":"2023-07-03T08:43:58.12295","exception":false,"start_time":"2023-07-03T08:43:57.556256","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_tdcsfog: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 382 ms, sys: 5.14 ms, total: 387 ms\n","Wall time: 407 ms\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# tdcsfog3\n","# =========================\n","th_len = 5000\n","w = 0.40\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = ['AccV', 'AccML', 'AccAP', \n","            'AccV_lag_diff',  'AccV_lead_diff', 'AccV_cumsum', \n","            'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","            'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","\n","# tdcsfog_list = glob.glob(TDCSFOG_DATA_PATH)\n","# for p in tqdm(tdcsfog_list):\n","for p in tqdm(test_tdcsfog, desc=\"test_tdcsfog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    df = pd.read_csv(p)\n","    \n","    if len(df) > th_len:\n","        seq_len = 5000\n","        shift = 2500\n","        offset = 1250\n","    else:\n","        seq_len = 3000\n","        shift = 1500\n","        offset = 750\n","        \n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 12])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_ = num.copy()\n","        time_ = time.copy()\n","        num_len = len(num_)\n","\n","        num_array[b,:num_len,:] = num_\n","        time_array[b,:num_len] = time_\n","        mask_array[b,:num_len] = 1\n","        pred_use_array[b,:num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b, :num_len, :] = num_\n","                time_array[b,:num_len] = time_\n","                mask_array[b,:num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b, :shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,offset : shift+offset] = 1\n","            \n","            \n","\n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(tdcsfog_model_list3_1):\n","        if n == 0:\n","            pred1 = make_pred(test_loader,m) / len(tdcsfog_model_list3_1)\n","        else:\n","            pred1 += make_pred(test_loader,m) / len(tdcsfog_model_list3_1)\n","    for n,m in enumerate(tdcsfog_model_list3_2):\n","        if n == 0:\n","            pred2 = make_pred(test_loader,m) / len(tdcsfog_model_list3_2)\n","        else:\n","            pred2 += make_pred(test_loader,m) / len(tdcsfog_model_list3_2)\n","    for n,m in enumerate(tdcsfog_model_list3_3):\n","        if n == 0:\n","            pred3 = make_pred(test_loader,m) / len(tdcsfog_model_list3_3)\n","        else:\n","            pred3 += make_pred(test_loader,m) / len(tdcsfog_model_list3_3)\n","    pred = pred1.copy()\n","    pred[:,:,1] = pred2[:,:,1]\n","    pred[:,:,2] = pred3[:,:,2]\n","    \n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i, mask_ == 1, :]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:, 0] * w\n","        df_[\"Turn\"] = pred_[:, 1] * w\n","        df_[\"Walking\"] = pred_[:, 2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"a2169ac3","metadata":{"papermill":{"duration":0.136164,"end_time":"2023-07-03T08:43:58.394509","exception":false,"start_time":"2023-07-03T08:43:58.258345","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex182, ex183, ex184** (tdcsfog4: 0.4)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":205,"id":"6c7bce9f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:43:58.668784Z","iopub.status.busy":"2023-07-03T08:43:58.667878Z","iopub.status.idle":"2023-07-03T08:43:59.601271Z","shell.execute_reply":"2023-07-03T08:43:59.600292Z"},"papermill":{"duration":1.075402,"end_time":"2023-07-03T08:43:59.604127","exception":false,"start_time":"2023-07-03T08:43:58.528725","status":"completed"},"tags":[]},"outputs":[],"source":["# TdcsfogRnnModel()\n","\n","tdcsfog_model_list4_1 = []\n","for i in tdcsfog_path4_1:  # ex182\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list4_1.append(model)\n","\n","\n","tdcsfog_model_list4_2 = []\n","for i in tdcsfog_path4_2:  # ex183\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list4_2.append(model)\n","\n","\n","tdcsfog_model_list4_3 = []\n","for i in tdcsfog_path4_3:  # ex184\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list4_3.append(model)"]},{"cell_type":"markdown","id":"d5f698aa","metadata":{"papermill":{"duration":0.136236,"end_time":"2023-07-03T08:43:59.875132","exception":false,"start_time":"2023-07-03T08:43:59.738896","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":206,"id":"6487efac","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:44:00.145846Z","iopub.status.busy":"2023-07-03T08:44:00.145463Z","iopub.status.idle":"2023-07-03T08:44:00.540748Z","shell.execute_reply":"2023-07-03T08:44:00.539648Z"},"papermill":{"duration":0.535473,"end_time":"2023-07-03T08:44:00.54356","exception":false,"start_time":"2023-07-03T08:44:00.008087","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_tdcsfog: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 370 ms, sys: 0 ns, total: 370 ms\n","Wall time: 370 ms\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# tdcsfog4\n","# =========================\n","th_len = 5000\n","w = 0.40\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = ['AccV', 'AccML', 'AccAP', \n","            'AccV_lag_diff',  'AccV_lead_diff', 'AccV_cumsum', \n","            'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","            'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","\n","# tdcsfog_list = glob.glob(TDCSFOG_DATA_PATH)\n","# for p in tqdm(tdcsfog_list):\n","for p in tqdm(test_tdcsfog, desc=\"test_tdcsfog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    df = pd.read_csv(p)\n","    \n","    if len(df) > th_len:\n","        seq_len = 5000\n","        shift = 2500\n","        offset = 1250\n","    else:\n","        seq_len = 3000\n","        shift = 1500\n","        offset = 750\n","        \n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 12])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_ = num.copy()\n","        time_ = time.copy()\n","        num_len = len(num_)\n","\n","        num_array[b,:num_len,:] = num_\n","        time_array[b,:num_len] = time_\n","        mask_array[b,:num_len] = 1\n","        pred_use_array[b,:num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b, :num_len, :] = num_\n","                time_array[b,:num_len] = time_\n","                mask_array[b,:num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b, :shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,offset : shift+offset] = 1\n","            \n","            \n","\n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(tdcsfog_model_list4_1):\n","        if n == 0:\n","            pred1 = make_pred(test_loader,m) / len(tdcsfog_model_list4_1)\n","        else:\n","            pred1 += make_pred(test_loader,m) / len(tdcsfog_model_list4_1)\n","    for n,m in enumerate(tdcsfog_model_list4_2):\n","        if n == 0:\n","            pred2 = make_pred(test_loader,m) / len(tdcsfog_model_list4_2)\n","        else:\n","            pred2 += make_pred(test_loader,m) / len(tdcsfog_model_list4_2)\n","    for n,m in enumerate(tdcsfog_model_list4_3):\n","        if n == 0:\n","            pred3 = make_pred(test_loader,m) / len(tdcsfog_model_list4_3)\n","        else:\n","            pred3 += make_pred(test_loader,m) / len(tdcsfog_model_list4_3)\n","    pred = pred1.copy()\n","    pred[:,:,0] = pred1[:,:,0]*0.5 + pred2[:,:,0]*0.5\n","    pred[:,:,1] = pred1[:,:,1]*0.5 + pred3[:,:,1]*0.5\n","    pred[:,:,2] = pred2[:,:,2]*0.5 + pred3[:,:,2]*0.5\n","    \n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i, mask_ == 1, :]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:, 0] * w\n","        df_[\"Turn\"] = pred_[:, 1] * w\n","        df_[\"Walking\"] = pred_[:, 2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"5180b6c1","metadata":{"papermill":{"duration":0.137584,"end_time":"2023-07-03T08:44:00.817247","exception":false,"start_time":"2023-07-03T08:44:00.679663","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>defog models</font>\n","\n","### checkpoint paths"]},{"cell_type":"code","execution_count":207,"id":"42c14df1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:01.091051Z","iopub.status.busy":"2023-07-03T08:44:01.090681Z","iopub.status.idle":"2023-07-03T08:44:01.095104Z","shell.execute_reply":"2023-07-03T08:44:01.09418Z"},"papermill":{"duration":0.143609,"end_time":"2023-07-03T08:44:01.097094","exception":false,"start_time":"2023-07-03T08:44:00.953485","status":"completed"},"tags":[]},"outputs":[],"source":["# defog_path2 = [f\"/kaggle/input/fog-ex153/ex153_{i}.pth\" for i in range(5)] # len 30000 defog1 \n","# defog_path4 = [f\"/kaggle/input/fog-ex179/ex179_{i}.pth\" for i in range(5)] # len 30000 defog1\n","# defog_path5 = [f\"/kaggle/input/fog-ex185/ex185_{i}.pth\" for i in range(5)] # len 30000 defog1\n","# defog_path6 = [f\"/kaggle/input/fog-ex204/ex204_{i}.pth\" for i in range(5)] # len 30000 defog2\n","\n","# defog_path7 = [f\"/kaggle/input/pd-exp238/fold{i}_best.pth\" for i in [0, 1, 2, 3, 4]]  # len 30000 Defog3Model"]},{"cell_type":"code","execution_count":208,"id":"1f6898e4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:01.37075Z","iopub.status.busy":"2023-07-03T08:44:01.370407Z","iopub.status.idle":"2023-07-03T08:44:01.379357Z","shell.execute_reply":"2023-07-03T08:44:01.378532Z"},"papermill":{"duration":0.147845,"end_time":"2023-07-03T08:44:01.381356","exception":false,"start_time":"2023-07-03T08:44:01.233511","status":"completed"},"tags":[]},"outputs":[],"source":["defog_path2 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex153*\")\n","defog_path4 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex179*\")\n","defog_path5 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex185*\")\n","defog_path6 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex204*\")\n","\n","# defog_path7 = glob.glob(\".\\\\output\\\\exp\\\\ex238_\\\\ex238_\\\\*\")"]},{"cell_type":"markdown","id":"a78601ee","metadata":{"papermill":{"duration":0.133059,"end_time":"2023-07-03T08:44:01.651409","exception":false,"start_time":"2023-07-03T08:44:01.51835","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex153** (defog2: 0.35)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":209,"id":"a9ec24b6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:01.921289Z","iopub.status.busy":"2023-07-03T08:44:01.920928Z","iopub.status.idle":"2023-07-03T08:44:02.214819Z","shell.execute_reply":"2023-07-03T08:44:02.213786Z"},"papermill":{"duration":0.430968,"end_time":"2023-07-03T08:44:02.217333","exception":false,"start_time":"2023-07-03T08:44:01.786365","status":"completed"},"tags":[]},"outputs":[],"source":["# DefogRnnModel()\n","\n","defog_model_list2 = []\n","for i in defog_path2:         # ex153\n","    model = DefogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list2.append(model)"]},{"cell_type":"markdown","id":"a9d380d6","metadata":{"papermill":{"duration":0.136651,"end_time":"2023-07-03T08:44:02.495168","exception":false,"start_time":"2023-07-03T08:44:02.358517","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":210,"id":"81c7041a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:02.764289Z","iopub.status.busy":"2023-07-03T08:44:02.763925Z","iopub.status.idle":"2023-07-03T08:44:02.768443Z","shell.execute_reply":"2023-07-03T08:44:02.767394Z"},"papermill":{"duration":0.142866,"end_time":"2023-07-03T08:44:02.770848","exception":false,"start_time":"2023-07-03T08:44:02.627982","status":"completed"},"tags":[]},"outputs":[],"source":["# for p in train_defog:\n","#     id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","#     print(id_values)"]},{"cell_type":"code","execution_count":211,"id":"e4dd4ac4","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:44:03.045216Z","iopub.status.busy":"2023-07-03T08:44:03.044801Z","iopub.status.idle":"2023-07-03T08:44:05.372634Z","shell.execute_reply":"2023-07-03T08:44:05.371637Z"},"papermill":{"duration":2.466285,"end_time":"2023-07-03T08:44:05.374976","exception":false,"start_time":"2023-07-03T08:44:02.908691","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 2.11 s, sys: 20.2 ms, total: 2.13 s\n","Wall time: 2.31 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# defog2\n","# =========================\n","th_len = 200000\n","w = 0.35\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list2):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list2)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list2)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"59ddddb0","metadata":{"papermill":{"duration":0.134519,"end_time":"2023-07-03T08:44:05.695545","exception":false,"start_time":"2023-07-03T08:44:05.561026","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex179** (defog4: 0.25)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":212,"id":"f2b71216","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:05.964483Z","iopub.status.busy":"2023-07-03T08:44:05.964068Z","iopub.status.idle":"2023-07-03T08:44:06.24269Z","shell.execute_reply":"2023-07-03T08:44:06.241765Z"},"papermill":{"duration":0.417446,"end_time":"2023-07-03T08:44:06.245455","exception":false,"start_time":"2023-07-03T08:44:05.828009","status":"completed"},"tags":[]},"outputs":[],"source":["defog_model_list4 = []\n","for i in defog_path4:       # ex179\n","    model = DefogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list4.append(model)"]},{"cell_type":"markdown","id":"04a43a8c","metadata":{"papermill":{"duration":0.134085,"end_time":"2023-07-03T08:44:06.512212","exception":false,"start_time":"2023-07-03T08:44:06.378127","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":213,"id":"d9828f81","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:44:06.785115Z","iopub.status.busy":"2023-07-03T08:44:06.784465Z","iopub.status.idle":"2023-07-03T08:44:08.943088Z","shell.execute_reply":"2023-07-03T08:44:08.941089Z"},"papermill":{"duration":2.296336,"end_time":"2023-07-03T08:44:08.945275","exception":false,"start_time":"2023-07-03T08:44:06.648939","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 2.11 s, sys: 9.9 ms, total: 2.12 s\n","Wall time: 2.13 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# defog4\n","# =========================\n","th_len = 200000\n","w = 0.25\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list4):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list4)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list4)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"ddb70f83","metadata":{"papermill":{"duration":0.135266,"end_time":"2023-07-03T08:44:09.215836","exception":false,"start_time":"2023-07-03T08:44:09.08057","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex185** (defog5: 0.25)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":214,"id":"5ba41dac","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:09.48817Z","iopub.status.busy":"2023-07-03T08:44:09.487752Z","iopub.status.idle":"2023-07-03T08:44:09.741747Z","shell.execute_reply":"2023-07-03T08:44:09.74075Z"},"papermill":{"duration":0.394068,"end_time":"2023-07-03T08:44:09.744281","exception":false,"start_time":"2023-07-03T08:44:09.350213","status":"completed"},"tags":[]},"outputs":[],"source":["defog_model_list5 = []\n","for i in defog_path5:        # ex185\n","    model = DefogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list5.append(model)"]},{"cell_type":"markdown","id":"1606f66a","metadata":{"papermill":{"duration":0.135952,"end_time":"2023-07-03T08:44:10.01809","exception":false,"start_time":"2023-07-03T08:44:09.882138","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":215,"id":"ac7edbbc","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:44:10.289966Z","iopub.status.busy":"2023-07-03T08:44:10.289582Z","iopub.status.idle":"2023-07-03T08:44:12.4248Z","shell.execute_reply":"2023-07-03T08:44:12.423487Z"},"papermill":{"duration":2.273917,"end_time":"2023-07-03T08:44:12.427186","exception":false,"start_time":"2023-07-03T08:44:10.153269","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 2.1 s, sys: 12.5 ms, total: 2.11 s\n","Wall time: 2.11 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# defog5\n","# =========================\n","th_len = 200000\n","w = 0.25\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list5):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list5)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list5)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"8e3e726e","metadata":{"papermill":{"duration":0.13494,"end_time":"2023-07-03T08:44:12.702962","exception":false,"start_time":"2023-07-03T08:44:12.568022","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex204** (defog6: 0.10)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":216,"id":"3bf1e6dc","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:12.980396Z","iopub.status.busy":"2023-07-03T08:44:12.979777Z","iopub.status.idle":"2023-07-03T08:44:14.023071Z","shell.execute_reply":"2023-07-03T08:44:14.022095Z"},"papermill":{"duration":1.185046,"end_time":"2023-07-03T08:44:14.025439","exception":false,"start_time":"2023-07-03T08:44:12.840393","status":"completed"},"tags":[]},"outputs":[],"source":["# DefogRnnModel2()\n","\n","defog_model_list6 = []\n","for i in defog_path6:           # ex204\n","    model = DefogRnnModel2()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list6.append(model)"]},{"cell_type":"markdown","id":"965cecff","metadata":{"papermill":{"duration":0.136944,"end_time":"2023-07-03T08:44:14.30229","exception":false,"start_time":"2023-07-03T08:44:14.165346","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":217,"id":"92e82569","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:44:14.573811Z","iopub.status.busy":"2023-07-03T08:44:14.573449Z","iopub.status.idle":"2023-07-03T08:44:25.655005Z","shell.execute_reply":"2023-07-03T08:44:25.653835Z"},"papermill":{"duration":11.219784,"end_time":"2023-07-03T08:44:25.657193","exception":false,"start_time":"2023-07-03T08:44:14.437409","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:11<00:00, 11.06s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 9.22 s, sys: 1.76 s, total: 11 s\n","Wall time: 11.1 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","\n","# =========================\n","# defog6\n","# =========================\n","th_len = 200000\n","# w = 0.10\n","w = 0.15\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list6):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list6)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list6)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"b9ce82eb","metadata":{"papermill":{"duration":0.136135,"end_time":"2023-07-03T08:44:25.93313","exception":false,"start_time":"2023-07-03T08:44:25.796995","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex238** (defog7: 0.05)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":218,"id":"57e725aa","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:26.257344Z","iopub.status.busy":"2023-07-03T08:44:26.25698Z","iopub.status.idle":"2023-07-03T08:44:26.261747Z","shell.execute_reply":"2023-07-03T08:44:26.260662Z"},"papermill":{"duration":0.144932,"end_time":"2023-07-03T08:44:26.264257","exception":false,"start_time":"2023-07-03T08:44:26.119325","status":"completed"},"tags":[]},"outputs":[],"source":["# # Defog3Model()\n","\n","# defog_model_list7 = []\n","# for path in defog_path7:    # ex238\n","#     model = Defog3Model()\n","#     state = torch.load(path, map_location=torch.device(\"cpu\"))\n","#     model.load_state_dict(state[\"model\"])\n","#     model = model.to(device)\n","#     model.eval()\n","#     defog_model_list7.append(model)\n","#     print(f\"load weights from {path}\")"]},{"cell_type":"markdown","id":"36a074fc","metadata":{"papermill":{"duration":0.137872,"end_time":"2023-07-03T08:44:26.539366","exception":false,"start_time":"2023-07-03T08:44:26.401494","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":219,"id":"bfdd20c1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:26.808589Z","iopub.status.busy":"2023-07-03T08:44:26.807789Z","iopub.status.idle":"2023-07-03T08:44:26.815594Z","shell.execute_reply":"2023-07-03T08:44:26.814685Z"},"papermill":{"duration":0.146156,"end_time":"2023-07-03T08:44:26.817696","exception":false,"start_time":"2023-07-03T08:44:26.67154","status":"completed"},"tags":[]},"outputs":[],"source":["# %%time\n","\n","# # =========================\n","# # defog7\n","# # =========================\n","# th_len = 200000\n","# w = 0.05\n","\n","# cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","# num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","#             'AccV_lag_diff',  'AccV_lead_diff', \n","#             'AccML_lag_diff', 'AccML_lead_diff',\n","#             'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# # defog_list = glob.glob(DEFOG_DATA_PATH)\n","# # for p in tqdm(defog_list):\n","# for p in tqdm(test_defog, desc=\"test_defog: \"):\n","#     # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","#     id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","#     df = pd.read_csv(p)\n","#     if len(df) > th_len:\n","#         seq_len = 30000\n","#         shift = 15000\n","#         offset = 7500\n","#     else:\n","#         seq_len = 15000\n","#         shift = 7500\n","#         offset = 3750\n","#     batch = (len(df)-1) // shift\n","#     if batch == 0:\n","#         batch = 1\n","#     for c in cols:\n","#         df[f\"{c}_lag_diff\"] = df[c].diff()\n","#         df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","#     sc = StandardScaler()\n","#     df[num_cols] = sc.fit_transform(df[num_cols].values)\n","#     df[num_cols] = df[num_cols].fillna(0)\n","#     num = df[num_cols].values\n","#     time = df[\"Time\"].values\n","    \n","#     num_array = np.zeros([batch,seq_len, 9])\n","#     mask_array = np.zeros([batch,seq_len], dtype=int)\n","#     time_array = np.zeros([batch,seq_len], dtype=int)\n","#     pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","#     if len(df) <= seq_len:\n","#         b = 0\n","#         num_len = len(num)\n","#         num_array[b,  :num_len, :] = num\n","#         time_array[b, :num_len] = time\n","#         mask_array[b, :num_len] = 1\n","#         pred_use_array[b, :num_len] = 1\n","#     else:\n","#         for n,b in enumerate(range(batch)):\n","#             if b == (batch - 1):\n","#                 num_ = num[b*shift : ]\n","#                 time_ = time[b*shift : ]\n","#                 num_len = len(num_)\n","\n","#                 num_array[b,  :num_len, :] = num_\n","#                 time_array[b, :num_len] = time_\n","#                 mask_array[b, :num_len] = 1\n","#                 pred_use_array[b, offset:num_len] = 1\n","#             elif b == 0:\n","#                 num_ = num[b*shift : b*shift+seq_len]\n","#                 time_ = time[b*shift : b*shift + seq_len]\n","\n","#                 num_array[b,  :, :] = num_\n","#                 time_array[b, :] = time_\n","#                 mask_array[b, :] = 1\n","#                 pred_use_array[b,:shift+offset] = 1\n","#             else:\n","#                 num_ = num[b*shift : b*shift+seq_len]\n","#                 time_ = time[b*shift : b*shift + seq_len]\n","\n","#                 num_array[b, :, :] = num_\n","#                 time_array[b,:] = time_\n","#                 mask_array[b,:] = 1\n","#                 pred_use_array[b,offset:shift+offset] = 1  \n","    \n","#     test_ = FogDataset(num_array, mask_array, train=False)\n","#     test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","#     for n,m in enumerate(defog_model_list7):\n","#         if n == 0:\n","#             pred = make_pred(test_loader,m) / len(defog_model_list7)\n","#         else:\n","#             pred += make_pred(test_loader,m) / len(defog_model_list7)\n","    \n","#     pred_list = []\n","#     for i in range(batch):\n","#         mask_ = pred_use_array[i]\n","#         pred_ = pred[i,mask_ == 1,:]\n","#         time_ = time_array[i, mask_ == 1]\n","        \n","#         df_ = pd.DataFrame()\n","#         df_[\"StartHesitation\"] = pred_[:,0] * w\n","#         df_[\"Turn\"] = pred_[:,1] * w\n","#         df_[\"Walking\"] = pred_[:,2] * w\n","#         df_[\"Time\"] = time_\n","#         df_[\"Id\"] = id_values\n","#         df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","#         pred_list.append(df_)\n","#     pred = pd.concat(pred_list).reset_index(drop=True)\n","#     df_all.append(pred)"]},{"cell_type":"markdown","id":"712628f0","metadata":{"papermill":{"duration":0.136719,"end_time":"2023-07-03T08:44:27.090455","exception":false,"start_time":"2023-07-03T08:44:26.953736","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","\n","# **Submission** "]},{"cell_type":"code","execution_count":220,"id":"57afbb1d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:27.363723Z","iopub.status.busy":"2023-07-03T08:44:27.362704Z","iopub.status.idle":"2023-07-03T08:44:29.976288Z","shell.execute_reply":"2023-07-03T08:44:29.974706Z"},"papermill":{"duration":2.755008,"end_time":"2023-07-03T08:44:29.978997","exception":false,"start_time":"2023-07-03T08:44:27.223989","status":"completed"},"tags":[]},"outputs":[],"source":["df_all = pd.concat(df_all).reset_index(drop=True)\n","df_all = df_all.groupby(by=\"Id\")[['StartHesitation', 'Turn', 'Walking']].sum().reset_index()\n","df_all[['Id', 'StartHesitation', 'Turn', 'Walking']].to_csv(\"submission.csv\",index=False)"]},{"cell_type":"code","execution_count":221,"id":"cd09a54b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:44:30.249101Z","iopub.status.busy":"2023-07-03T08:44:30.248746Z","iopub.status.idle":"2023-07-03T08:44:30.263457Z","shell.execute_reply":"2023-07-03T08:44:30.262465Z"},"papermill":{"duration":0.150987,"end_time":"2023-07-03T08:44:30.265498","exception":false,"start_time":"2023-07-03T08:44:30.114511","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>StartHesitation</th>\n","      <th>Turn</th>\n","      <th>Walking</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>003f117e14_0</td>\n","      <td>0.002476</td>\n","      <td>0.002984</td>\n","      <td>0.000762</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>003f117e14_1</td>\n","      <td>0.002400</td>\n","      <td>0.002903</td>\n","      <td>0.000708</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>003f117e14_10</td>\n","      <td>0.001943</td>\n","      <td>0.002561</td>\n","      <td>0.000587</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003f117e14_100</td>\n","      <td>0.001559</td>\n","      <td>0.002188</td>\n","      <td>0.000472</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>003f117e14_1000</td>\n","      <td>0.002783</td>\n","      <td>0.042777</td>\n","      <td>0.000950</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>286365</th>\n","      <td>02ab235146_99995</td>\n","      <td>0.000067</td>\n","      <td>0.033726</td>\n","      <td>0.004219</td>\n","    </tr>\n","    <tr>\n","      <th>286366</th>\n","      <td>02ab235146_99996</td>\n","      <td>0.000066</td>\n","      <td>0.032923</td>\n","      <td>0.004129</td>\n","    </tr>\n","    <tr>\n","      <th>286367</th>\n","      <td>02ab235146_99997</td>\n","      <td>0.000065</td>\n","      <td>0.032285</td>\n","      <td>0.004020</td>\n","    </tr>\n","    <tr>\n","      <th>286368</th>\n","      <td>02ab235146_99998</td>\n","      <td>0.000064</td>\n","      <td>0.031890</td>\n","      <td>0.003912</td>\n","    </tr>\n","    <tr>\n","      <th>286369</th>\n","      <td>02ab235146_99999</td>\n","      <td>0.000062</td>\n","      <td>0.031264</td>\n","      <td>0.003791</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>286370 rows × 4 columns</p>\n","</div>"],"text/plain":["                      Id  StartHesitation      Turn   Walking\n","0           003f117e14_0         0.002476  0.002984  0.000762\n","1           003f117e14_1         0.002400  0.002903  0.000708\n","2          003f117e14_10         0.001943  0.002561  0.000587\n","3         003f117e14_100         0.001559  0.002188  0.000472\n","4        003f117e14_1000         0.002783  0.042777  0.000950\n","...                  ...              ...       ...       ...\n","286365  02ab235146_99995         0.000067  0.033726  0.004219\n","286366  02ab235146_99996         0.000066  0.032923  0.004129\n","286367  02ab235146_99997         0.000065  0.032285  0.004020\n","286368  02ab235146_99998         0.000064  0.031890  0.003912\n","286369  02ab235146_99999         0.000062  0.031264  0.003791\n","\n","[286370 rows x 4 columns]"]},"execution_count":221,"metadata":{},"output_type":"execute_result"}],"source":["df_all"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":473.245527,"end_time":"2023-07-03T08:44:34.05986","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-03T08:36:40.814333","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}