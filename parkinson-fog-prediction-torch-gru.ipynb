{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abrachan/parkinson-fog-prediction-torch-gru?scriptVersionId=135572973\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"099dad95","metadata":{"papermill":{"duration":0.082399,"end_time":"2023-07-03T07:58:17.697321","exception":false,"start_time":"2023-07-03T07:58:17.614922","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","# **Reference**:\n","* `Kaggle Competition`: <a href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/overview\" style=\"text-decoration:none\">Parkinson's Freezing of Gait Prediction</a>\n","* `Disscusion`: <a href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/416057\" style=\"text-decoration:none\">2nd place solution</a>\n","* `Notebook`: <a href=\"https://www.kaggle.com/code/takoihiraokazu/cv-ensemble-sub-0607-1\" style=\"text-decoration:none\">Inference notebook</a>\n","* `Github`: **TakoiHirokazu** <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction\" style=\"text-decoration:none\">Kaggle-Parkinsons-Freezing-of-Gait-Prediction</a> (Training)\n","\n","Thanks <a href=\"https://www.kaggle.com/takoihiraokazu\" style=\"text-decoration:none\">Takoi</a> and his/her teammates for their sharing solution and code!\n","\n","<br>\n","\n","* My own works: <a href=\"https://www.kaggle.com/code/abrachan/exploratory-data-analysis#Some-Conclusions\" style=\"text-decoration:none\">Exploratory Data Analysis</a>\n","\n","\n","<br>\n","<br>\n","\n","**Note**: <br>\n","The checkpoints using in this notebook which lying in the `/kaggle/input/parkinson-fog-prediction` were obtained from the training stage using **CUDA**. So if you want to run the `【Inference】` by skipping the training stage in this notebook in the kaggle environment, please select the GPU accelerator. Otherwise it will throw exceptions.\n","\n","`RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.`\n","\n","<br>\n","\n","------\n"]},{"cell_type":"markdown","id":"fbf16357","metadata":{"papermill":{"duration":0.076386,"end_time":"2023-07-03T07:58:17.850961","exception":false,"start_time":"2023-07-03T07:58:17.774575","status":"completed"},"tags":[]},"source":["<br>\n","\n","# **Import Libraries**"]},{"cell_type":"code","execution_count":1,"id":"631d74f9","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:18.007502Z","iopub.status.busy":"2023-07-03T07:58:18.006782Z","iopub.status.idle":"2023-07-03T07:58:29.522883Z","shell.execute_reply":"2023-07-03T07:58:29.521706Z"},"papermill":{"duration":11.597652,"end_time":"2023-07-03T07:58:29.525667","exception":false,"start_time":"2023-07-03T07:58:17.928015","status":"completed"},"tags":[]},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import os\n","import gc\n","import sys\n","import glob\n","import json\n","import pickle\n","import logging\n","from tqdm import tqdm\n","from tqdm import tqdm_notebook as tqdm_nb\n","from contextlib import contextmanager\n","\n","import time\n","import datetime\n","\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import PIL.Image as Image\n","\n","from IPython.display import Video\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, average_precision_score\n","from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import LayerNorm\n","from torch.nn import TransformerEncoder, TransformerDecoder\n","\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from transformers import AdamW, get_linear_schedule_with_warmup     # pip install transformers\n","\n","from torch.cuda import amp\n","from torch.utils.data import Dataset, DataLoader, TensorDataset"]},{"cell_type":"code","execution_count":2,"id":"b0f91570","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:29.683847Z","iopub.status.busy":"2023-07-03T07:58:29.682543Z","iopub.status.idle":"2023-07-03T07:58:29.687948Z","shell.execute_reply":"2023-07-03T07:58:29.686889Z"},"papermill":{"duration":0.085784,"end_time":"2023-07-03T07:58:29.689904","exception":false,"start_time":"2023-07-03T07:58:29.60412","status":"completed"},"tags":[]},"outputs":[],"source":["# sys.path.append(\"../src/\")\n","# from logger import setup_logger, LOGGER    # Abrachan: see my revise below: `def init_logger()`\n","# from util_tool import reduce_mem_usage\n","\n","pd.set_option('display.max_columns', 300)"]},{"cell_type":"markdown","id":"2c1a388a","metadata":{"papermill":{"duration":0.076689,"end_time":"2023-07-03T07:58:29.84362","exception":false,"start_time":"2023-07-03T07:58:29.766931","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","# **Config**"]},{"cell_type":"code","execution_count":3,"id":"2b72cfac","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:29.998829Z","iopub.status.busy":"2023-07-03T07:58:29.998452Z","iopub.status.idle":"2023-07-03T07:58:30.003515Z","shell.execute_reply":"2023-07-03T07:58:30.002471Z"},"papermill":{"duration":0.085356,"end_time":"2023-07-03T07:58:30.005509","exception":false,"start_time":"2023-07-03T07:58:29.920153","status":"completed"},"tags":[]},"outputs":[],"source":["# When doing `inference`, set below as False so that we can run the whole notebook directly.\n","TRAIN_FLAG   = False # True\n","PREDICT_FLAG = False # True"]},{"cell_type":"markdown","id":"e80bfecd","metadata":{"papermill":{"duration":0.078001,"end_time":"2023-07-03T07:58:30.161491","exception":false,"start_time":"2023-07-03T07:58:30.08349","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","# **Load Data**"]},{"cell_type":"code","execution_count":4,"id":"574fe64e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:30.321093Z","iopub.status.busy":"2023-07-03T07:58:30.320745Z","iopub.status.idle":"2023-07-03T07:58:30.703249Z","shell.execute_reply":"2023-07-03T07:58:30.702262Z"},"papermill":{"duration":0.46679,"end_time":"2023-07-03T07:58:30.705676","exception":false,"start_time":"2023-07-03T07:58:30.238886","status":"completed"},"tags":[]},"outputs":[],"source":["root_data = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/'\n","\n","train_defog = glob.glob(root_data + 'train/defog/**')\n","train_tdcsfog = glob.glob(root_data + 'train/tdcsfog/**')\n","train_notype = glob.glob(root_data + 'train/notype/**')\n","\n","test_defog = glob.glob(root_data + 'test/defog/**')\n","test_tdcsfog = glob.glob(root_data + 'test/tdcsfog/**')\n","\n","subjects = pd.read_csv(root_data + 'subjects.csv')\n","tasks = pd.read_csv(root_data + 'tasks.csv')\n","events = pd.read_csv(root_data + 'events.csv')\n","\n","daily_metadata=pd.read_csv(root_data + 'daily_metadata.csv')\n","tdcsfog_metadata=pd.read_csv(root_data + 'tdcsfog_metadata.csv')\n","defog_metadata=pd.read_csv(root_data + 'defog_metadata.csv')\n","\n","sub = pd.read_csv(root_data + 'sample_submission.csv')"]},{"cell_type":"markdown","id":"e44b974a","metadata":{"papermill":{"duration":0.080317,"end_time":"2023-07-03T07:58:30.867493","exception":false,"start_time":"2023-07-03T07:58:30.787176","status":"completed"},"tags":[]},"source":["For some basic Exploratory Data Analysis (EDA), refers to <a href=\"https://www.kaggle.com/code/abrachan/exploratory-data-analysis\" style=\"text-decoration:none\">my own work</a> if you are interested."]},{"cell_type":"markdown","id":"2a7fd52e","metadata":{"papermill":{"duration":0.078132,"end_time":"2023-07-03T07:58:31.024971","exception":false,"start_time":"2023-07-03T07:58:30.946839","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","# **tdcsfog** 【Training】\n","\n","<br>\n","\n","<br>\n","\n","## **Feature Engineering**\n","\n","<br>\n","\n","### fe001_tdcsfog_base_feature\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe001_tdcsfog_base_feature.ipynb\" style=\"text-decoration:none\">fe001_tdcsfog_base_feature.ipynb</a>"]},{"cell_type":"code","execution_count":5,"id":"17541b90","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:31.190208Z","iopub.status.busy":"2023-07-03T07:58:31.189475Z","iopub.status.idle":"2023-07-03T07:58:31.195939Z","shell.execute_reply":"2023-07-03T07:58:31.19483Z"},"papermill":{"duration":0.093719,"end_time":"2023-07-03T07:58:31.198179","exception":false,"start_time":"2023-07-03T07:58:31.10446","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"001\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\", exist_ok=True)\n","    os.makedirs(f\"./output/fe/fe{fe}/save\", exist_ok=True)"]},{"cell_type":"code","execution_count":6,"id":"67a29ce3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:31.375783Z","iopub.status.busy":"2023-07-03T07:58:31.375119Z","iopub.status.idle":"2023-07-03T07:58:31.379944Z","shell.execute_reply":"2023-07-03T07:58:31.379109Z"},"papermill":{"duration":0.092369,"end_time":"2023-07-03T07:58:31.381977","exception":false,"start_time":"2023-07-03T07:58:31.289608","status":"completed"},"tags":[]},"outputs":[],"source":["# TDCSFOG_META_PATH = \"../data/tdcsfog_metadata.csv\"\n","# TDCSFOG_FOLDER = \"../data/train/tdcsfog/*.csv\"\n","\n","# meta = pd.read_csv(TDCSFOG_META_PATH)"]},{"cell_type":"code","execution_count":7,"id":"c03f905c","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T07:58:31.541237Z","iopub.status.busy":"2023-07-03T07:58:31.540923Z","iopub.status.idle":"2023-07-03T07:58:31.556074Z","shell.execute_reply":"2023-07-03T07:58:31.555246Z"},"papermill":{"duration":0.096664,"end_time":"2023-07-03T07:58:31.558074","exception":false,"start_time":"2023-07-03T07:58:31.46141","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"data":{"text/plain":["{'4dc2f8': 0,\n"," 'f62eec': 1,\n"," '231c3b': 2,\n"," 'fa8764': 3,\n"," 'c85fdf': 4,\n"," '31d269': 5,\n"," '07285e': 6,\n"," '02bc69': 7,\n"," '7eb666': 8,\n"," '220a17': 9,\n"," '54ee6e': 10,\n"," '242a3e': 11,\n"," 'e9fc55': 12,\n"," '66341b': 13,\n"," '7fcee9': 14,\n"," 'f686f0': 15,\n"," '312788': 16,\n"," '4ca9b3': 17,\n"," '2a39f8': 18,\n"," 'd9312a': 19,\n"," '3b2b7a': 20,\n"," '4b39ac': 21,\n"," '93f49f': 22,\n"," 'af82b2': 23,\n"," '251738': 24,\n"," '87174c': 25,\n"," '3b2403': 26,\n"," 'a03db7': 27,\n"," 'a80ae4': 28,\n"," '364459': 29,\n"," 'bc3908': 30,\n"," '4ba1d3': 31,\n"," '301ada': 32,\n"," '51574c': 33,\n"," '8db7dd': 34,\n"," '69cc45': 35,\n"," '2d57c2': 36,\n"," 'd8836b': 37,\n"," 'eeaff0': 38,\n"," '6a3e93': 39,\n"," 'f2c8aa': 40,\n"," '2c98f7': 41,\n"," 'c8e721': 42,\n"," 'e8919c': 43,\n"," '24a59d': 44,\n"," '743f4e': 45,\n"," '4bb5d0': 46,\n"," '516a67': 47,\n"," '48fd62': 48,\n"," '082f01': 49,\n"," 'c95ab0': 50,\n"," '59f492': 51,\n"," '79011a': 52,\n"," 'b19f77': 53,\n"," '5c0b8a': 54,\n"," '7688c1': 55,\n"," '4f13b4': 56,\n"," '19ea47': 57,\n"," '9f85da': 58,\n"," 'e39bc5': 59,\n"," 'c7fee4': 60,\n"," '194d1d': 61}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["sub_dict = {}\n","for n,i in enumerate(tdcsfog_metadata[\"Subject\"].unique()):\n","    sub_dict[i] = n\n","sub_dict"]},{"cell_type":"code","execution_count":8,"id":"134a18a1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:31.719739Z","iopub.status.busy":"2023-07-03T07:58:31.718776Z","iopub.status.idle":"2023-07-03T07:58:32.101848Z","shell.execute_reply":"2023-07-03T07:58:32.100888Z"},"papermill":{"duration":0.466675,"end_time":"2023-07-03T07:58:32.104445","exception":false,"start_time":"2023-07-03T07:58:31.63777","status":"completed"},"tags":[]},"outputs":[],"source":["tdcsfog_metadata[\"Sub_id\"] = tdcsfog_metadata[\"Subject\"].map(sub_dict)\n","\n","\n","# pip install pyarrow\n","# pip install fastparquet\n","tdcsfog_metadata.to_parquet(\"./output/fe/fe001/fe001_tdcsfog_meta.parquet\")\n","\n","with open(f'./output/fe/fe{fe}/fe{fe}_sub_id.pkl', 'wb') as p:\n","    pickle.dump(sub_dict, p)"]},{"cell_type":"markdown","id":"063e94b3","metadata":{"papermill":{"duration":0.076994,"end_time":"2023-07-03T07:58:32.260144","exception":false,"start_time":"2023-07-03T07:58:32.18315","status":"completed"},"tags":[]},"source":["<br>\n","\n","\n","### fe022_tdcsfog_1000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe022_tdcsfog_1000.ipynb\" style=\"text-decoration:none\">fe022_tdcsfog_1000.ipynb</a>"]},{"cell_type":"code","execution_count":9,"id":"feb1455c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:32.424228Z","iopub.status.busy":"2023-07-03T07:58:32.423889Z","iopub.status.idle":"2023-07-03T07:58:32.428382Z","shell.execute_reply":"2023-07-03T07:58:32.427393Z"},"papermill":{"duration":0.084688,"end_time":"2023-07-03T07:58:32.430299","exception":false,"start_time":"2023-07-03T07:58:32.345611","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler"]},{"cell_type":"code","execution_count":10,"id":"4a018312","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:32.586567Z","iopub.status.busy":"2023-07-03T07:58:32.586243Z","iopub.status.idle":"2023-07-03T07:58:32.591242Z","shell.execute_reply":"2023-07-03T07:58:32.590395Z"},"papermill":{"duration":0.084661,"end_time":"2023-07-03T07:58:32.593101","exception":false,"start_time":"2023-07-03T07:58:32.50844","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"022\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":11,"id":"cb1371e5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:32.749948Z","iopub.status.busy":"2023-07-03T07:58:32.749195Z","iopub.status.idle":"2023-07-03T07:58:32.753891Z","shell.execute_reply":"2023-07-03T07:58:32.753047Z"},"papermill":{"duration":0.084923,"end_time":"2023-07-03T07:58:32.755856","exception":false,"start_time":"2023-07-03T07:58:32.670933","status":"completed"},"tags":[]},"outputs":[],"source":["# TDCSFOG_META_PATH = \"../data/tdcsfog_metadata.csv\"\n","# TDCSFOG_FOLDER = \"../data/train/tdcsfog/*.csv\"      \n","\n","# data_list = glob.glob(TDCSFOG_FOLDER)\n","\n","# data_list\n","\n","# Abrachan: The variable `data_list` is the same as `train_tdcdfog` above."]},{"cell_type":"code","execution_count":12,"id":"873016aa","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:32.954744Z","iopub.status.busy":"2023-07-03T07:58:32.954394Z","iopub.status.idle":"2023-07-03T07:58:33.019502Z","shell.execute_reply":"2023-07-03T07:58:33.018504Z"},"papermill":{"duration":0.187793,"end_time":"2023-07-03T07:58:33.021564","exception":false,"start_time":"2023-07-03T07:58:32.833771","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Subject</th>\n","      <th>Visit</th>\n","      <th>Test</th>\n","      <th>Medication</th>\n","      <th>Sub_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>003f117e14</td>\n","      <td>4dc2f8</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>009ee11563</td>\n","      <td>f62eec</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>011322847a</td>\n","      <td>231c3b</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01d0fe7266</td>\n","      <td>231c3b</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>024418ba39</td>\n","      <td>fa8764</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>on</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Id Subject  Visit  Test Medication  Sub_id\n","0  003f117e14  4dc2f8      3     2         on       0\n","1  009ee11563  f62eec      4     2         on       1\n","2  011322847a  231c3b      2     2         on       2\n","3  01d0fe7266  231c3b      2     1        off       2\n","4  024418ba39  fa8764     19     3         on       3"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["tdcsfog_metadata = pd.read_parquet(\"./output/fe/fe001/fe001_tdcsfog_meta.parquet\")\n","tdcsfog_metadata.head()"]},{"cell_type":"code","execution_count":13,"id":"367bf969","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:33.184118Z","iopub.status.busy":"2023-07-03T07:58:33.183518Z","iopub.status.idle":"2023-07-03T07:58:33.189567Z","shell.execute_reply":"2023-07-03T07:58:33.188723Z"},"papermill":{"duration":0.087948,"end_time":"2023-07-03T07:58:33.191522","exception":false,"start_time":"2023-07-03T07:58:33.103574","status":"completed"},"tags":[]},"outputs":[],"source":["cols       = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols   = ['AccV', 'AccML', 'AccAP',  \n","              'AccV_lag_diff',  'AccV_lead_diff',  'AccV_cumsum', \n","              'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","              'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","target_cols = [\"StartHesitation\",\"Turn\",\"Walking\"]\n","\n","seq_len = 1000\n","shift = 500\n","offset = 250\n","\n","# Abrachan:\n","# https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/416057\n","#     Each Id was split into sequences of a specified length. During training, \n","#     we used a shorter length (e.g., 1000 for tdcsfog, 5000 for defog)\n","#     For tdcsfog, sequences were created by shifting 500 steps from the starting position."]},{"cell_type":"code","execution_count":14,"id":"116cf9d0","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:33.363098Z","iopub.status.busy":"2023-07-03T07:58:33.362692Z","iopub.status.idle":"2023-07-03T07:58:33.368375Z","shell.execute_reply":"2023-07-03T07:58:33.36737Z"},"papermill":{"duration":0.101718,"end_time":"2023-07-03T07:58:33.37064","exception":false,"start_time":"2023-07-03T07:58:33.268922","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","subject_list = []\n","id_list = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []"]},{"cell_type":"code","execution_count":15,"id":"41859dc4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:58:33.546113Z","iopub.status.busy":"2023-07-03T07:58:33.545763Z","iopub.status.idle":"2023-07-03T07:59:07.353989Z","shell.execute_reply":"2023-07-03T07:59:07.352775Z"},"papermill":{"duration":33.894423,"end_time":"2023-07-03T07:59:07.356205","exception":false,"start_time":"2023-07-03T07:58:33.461782","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["tdcsfog_metadata: : 833it [00:33, 24.66it/s]\n"]}],"source":["for i,s in tqdm(zip(tdcsfog_metadata[\"Id\"].values, tdcsfog_metadata[\"Sub_id\"].values), desc=\"tdcsfog_metadata: \"):\n","# for i,s in tqdm(zip(meta[\"Id\"].values, meta[\"sub_id\"].values)):\n","    # path = f\"../data/train/tdcsfog/{i}.csv\"\n","    path = root_data + f\"train/tdcsfog/{i}.csv\"\n","    df = pd.read_csv(path)\n","    \n","    batch = (len(df)-1) // shift    # Abrachan: Why minus 1 here?\n","    \n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    \n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    # for c in num_cols:\n","    #     df[c] = (df[c] - mean_std_dict[c][0]) / mean_std_dict[c][1]\n","    #     df[c] = df[c].fillna(0)\n","    \n","    num    = df[num_cols].values\n","    target = df[target_cols].values\n","    time_values   = df[\"Time\"].values\n","    \n","    num_array_      = np.zeros([batch, seq_len, 12])\n","    target_array_   = np.zeros([batch, seq_len,  3])\n","    time_array_     = np.zeros([batch, seq_len    ], dtype=int)\n","    \n","    mask_array_     = np.zeros([batch, seq_len    ], dtype=int)\n","    pred_use_array_ = np.zeros([batch, seq_len    ], dtype=int)\n","    \n","    \n","    for n,b in enumerate(range(batch)):\n","        if b == (batch - 1):\n","            num_ = num[b*shift : ]\n","            num_array_[b, :len(num_), :] = num_\n","            \n","            target_ = target[b*shift : ]\n","            target_array_[b, :len(target_), :] = target_\n","            \n","            mask_array_[b, :len(target_)] = 1\n","            \n","            pred_use_array_[b, offset:len(target_)] = 1\n","            \n","            time_ = time_values[b*shift : ]\n","            time_array_[b, :len(time_)] = time_\n","            \n","        elif b == 0:\n","            num_ = num[b*shift : b*shift+seq_len]          # [0:1000]\n","            num_array_[b, :, :] = num_\n","            \n","            target_ = target[b*shift : b*shift+seq_len]    # [0:1000]\n","            target_array_[b, :, :] = target_\n","            \n","            mask_array_[b, :] = 1                          # [b, :1000]\n","            \n","            pred_use_array_[b, :offset+shift] = 1          # [b, :750]    <===\n","            \n","            time_ = time_values[b*shift : b*shift+seq_len] # [0:1000]\n","            time_array_[b, :] = time_\n","        \n","        else:\n","            num_ = num[b*shift : b*shift+seq_len]          # for b=1: [500:1500]\n","            num_array_[b, :, :] = num_\n","            \n","            target_ = target[b*shift : b*shift+seq_len]    # for b=1: [500:1500]\n","            target_array_[b, :, :] = target_\n","            \n","            mask_array_[b, :] = 1                          # for b=1: [b, :1000]\n","            \n","            pred_use_array_[b, offset:offset+shift] = 1    # for b=1: [b, 250:750]   <===\n","            \n","            time_ = time_values[b*shift : b*shift+seq_len] # for b=1: [500:1500]\n","            time_array_[b,:] = time_\n","    \n","    \n","    num_array.append(num_array_)\n","    target_array.append(target_array_)\n","    mask_array.append(mask_array_)\n","    pred_use_array.append(pred_use_array_)\n","    time_array.append(time_array_)\n","    \n","    subject_list += [s for _ in range(batch)]     # s is `Sub_id`\n","    id_list      += [i for _ in range(batch)]     # i is `Id`"]},{"cell_type":"code","execution_count":16,"id":"c24b8cc3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:07.555757Z","iopub.status.busy":"2023-07-03T07:59:07.554845Z","iopub.status.idle":"2023-07-03T07:59:08.162429Z","shell.execute_reply":"2023-07-03T07:59:08.161443Z"},"papermill":{"duration":0.707872,"end_time":"2023-07-03T07:59:08.165052","exception":false,"start_time":"2023-07-03T07:59:07.45718","status":"completed"},"tags":[]},"outputs":[],"source":["num_array      = np.concatenate(num_array, axis=0)\n","target_array   = np.concatenate(target_array, axis=0)\n","mask_array     = np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array     = np.concatenate(time_array, axis=0)"]},{"cell_type":"code","execution_count":17,"id":"48ce1274","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:08.358869Z","iopub.status.busy":"2023-07-03T07:59:08.358533Z","iopub.status.idle":"2023-07-03T07:59:08.430097Z","shell.execute_reply":"2023-07-03T07:59:08.429084Z"},"papermill":{"duration":0.170002,"end_time":"2023-07-03T07:59:08.432285","exception":false,"start_time":"2023-07-03T07:59:08.262283","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>subject</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>003f117e14</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13711</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13712</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13713</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13714</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>13715</th>\n","      <td>ffda8fadfd</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13716 rows × 2 columns</p>\n","</div>"],"text/plain":["               Id  subject\n","0      003f117e14        0\n","1      003f117e14        0\n","2      003f117e14        0\n","3      003f117e14        0\n","4      003f117e14        0\n","...           ...      ...\n","13711  ffda8fadfd       14\n","13712  ffda8fadfd       14\n","13713  ffda8fadfd       14\n","13714  ffda8fadfd       14\n","13715  ffda8fadfd       14\n","\n","[13716 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id"]},{"cell_type":"code","execution_count":18,"id":"5d7c9038","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:08.630105Z","iopub.status.busy":"2023-07-03T07:59:08.629768Z","iopub.status.idle":"2023-07-03T07:59:14.330522Z","shell.execute_reply":"2023-07-03T07:59:14.329292Z"},"papermill":{"duration":5.800573,"end_time":"2023-07-03T07:59:14.333396","exception":false,"start_time":"2023-07-03T07:59:08.532823","status":"completed"},"tags":[]},"outputs":[],"source":["np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\",time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)"]},{"cell_type":"code","execution_count":19,"id":"7d9f5e1c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:21.214475Z","iopub.status.busy":"2023-07-03T07:59:21.214097Z","iopub.status.idle":"2023-07-03T07:59:21.224063Z","shell.execute_reply":"2023-07-03T07:59:21.223207Z"},"papermill":{"duration":0.112743,"end_time":"2023-07-03T07:59:21.226187","exception":false,"start_time":"2023-07-03T07:59:21.113444","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"7cb56d2d","metadata":{"papermill":{"duration":0.099235,"end_time":"2023-07-03T07:59:21.426816","exception":false,"start_time":"2023-07-03T07:59:21.327581","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>**Training**</font>"]},{"cell_type":"markdown","id":"4ba7a4ec","metadata":{"papermill":{"duration":0.099969,"end_time":"2023-07-03T07:59:21.62454","exception":false,"start_time":"2023-07-03T07:59:21.524571","status":"completed"},"tags":[]},"source":["<br>\n","\n","Code below is common for the tdcsfog notebooks whose names start with \"ex\", for example: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex143_tdcsfog_gru.ipynb\" style=\"text-decoration:none\">ex143_tdcsfog_gru.ipynb</a>\n","\n","<br>"]},{"cell_type":"code","execution_count":20,"id":"3d796b0d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:21.822792Z","iopub.status.busy":"2023-07-03T07:59:21.82243Z","iopub.status.idle":"2023-07-03T07:59:21.82686Z","shell.execute_reply":"2023-07-03T07:59:21.825894Z"},"papermill":{"duration":0.10683,"end_time":"2023-07-03T07:59:21.828896","exception":false,"start_time":"2023-07-03T07:59:21.722066","status":"completed"},"tags":[]},"outputs":[],"source":["TRAIN_FLAG_TDCSFOG = True"]},{"cell_type":"markdown","id":"f8bfb56d","metadata":{"papermill":{"duration":0.097023,"end_time":"2023-07-03T07:59:22.024868","exception":false,"start_time":"2023-07-03T07:59:21.927845","status":"completed"},"tags":[]},"source":["<br>\n","\n","### helpers\n","\n","<br>\n","\n","#### def `set_seed()`"]},{"cell_type":"code","execution_count":21,"id":"88337a09","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:22.221791Z","iopub.status.busy":"2023-07-03T07:59:22.221241Z","iopub.status.idle":"2023-07-03T07:59:22.227378Z","shell.execute_reply":"2023-07-03T07:59:22.226372Z"},"papermill":{"duration":0.107131,"end_time":"2023-07-03T07:59:22.22969","exception":false,"start_time":"2023-07-03T07:59:22.122559","status":"completed"},"tags":[]},"outputs":[],"source":["def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","id":"3d48b76e","metadata":{"papermill":{"duration":0.097797,"end_time":"2023-07-03T07:59:22.425244","exception":false,"start_time":"2023-07-03T07:59:22.327447","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `init_logger()`"]},{"cell_type":"code","execution_count":22,"id":"aaa3a389","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:22.622775Z","iopub.status.busy":"2023-07-03T07:59:22.622424Z","iopub.status.idle":"2023-07-03T07:59:22.628225Z","shell.execute_reply":"2023-07-03T07:59:22.627396Z"},"papermill":{"duration":0.108672,"end_time":"2023-07-03T07:59:22.630141","exception":false,"start_time":"2023-07-03T07:59:22.521469","status":"completed"},"tags":[]},"outputs":[],"source":["def init_logger(log_file):\n","    \n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    \n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    \n","    return logger\n","\n","\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"6dc14f12","metadata":{"papermill":{"duration":0.099151,"end_time":"2023-07-03T07:59:22.826929","exception":false,"start_time":"2023-07-03T07:59:22.727778","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `timer()`"]},{"cell_type":"code","execution_count":23,"id":"b58a101d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:23.023874Z","iopub.status.busy":"2023-07-03T07:59:23.023527Z","iopub.status.idle":"2023-07-03T07:59:23.028847Z","shell.execute_reply":"2023-07-03T07:59:23.027858Z"},"papermill":{"duration":0.105784,"end_time":"2023-07-03T07:59:23.031193","exception":false,"start_time":"2023-07-03T07:59:22.925409","status":"completed"},"tags":[]},"outputs":[],"source":["@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    \n","    yield \n","    # LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(\"=\"*66)\n","    print(\"\\n\"*2)\n","    \n","# setup_logger(out_file=logger_path)"]},{"cell_type":"markdown","id":"0af75df5","metadata":{"papermill":{"duration":0.099114,"end_time":"2023-07-03T07:59:23.229636","exception":false,"start_time":"2023-07-03T07:59:23.130522","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `preprocess()`"]},{"cell_type":"code","execution_count":24,"id":"ef61bbe7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:23.426972Z","iopub.status.busy":"2023-07-03T07:59:23.426627Z","iopub.status.idle":"2023-07-03T07:59:23.431355Z","shell.execute_reply":"2023-07-03T07:59:23.43049Z"},"papermill":{"duration":0.105525,"end_time":"2023-07-03T07:59:23.433223","exception":false,"start_time":"2023-07-03T07:59:23.327698","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array,):\n","    \n","    attention_mask = (mask_array == 0)\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"f910f5b1","metadata":{"papermill":{"duration":0.099844,"end_time":"2023-07-03T07:59:23.629875","exception":false,"start_time":"2023-07-03T07:59:23.530031","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogDataset()`"]},{"cell_type":"code","execution_count":25,"id":"6afa6218","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:23.829642Z","iopub.status.busy":"2023-07-03T07:59:23.828692Z","iopub.status.idle":"2023-07-03T07:59:23.83916Z","shell.execute_reply":"2023-07-03T07:59:23.838288Z"},"papermill":{"duration":0.11304,"end_time":"2023-07-03T07:59:23.841485","exception":false,"start_time":"2023-07-03T07:59:23.728445","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.train = train\n","        self.y = y\n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","\n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item],)\n","        \n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array'     : torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","              'attention_mask'            : torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\"                         : torch.tensor(self.y[item], dtype=torch.float32)\n","               }\n","        else:\n","            return {\n","                'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","                'input_data_mask_array'     : torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","                'attention_mask'            : torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"3ac65776","metadata":{"papermill":{"duration":0.097082,"end_time":"2023-07-03T07:59:24.035881","exception":false,"start_time":"2023-07-03T07:59:23.938799","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":26,"id":"dc8e3cc8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:24.301505Z","iopub.status.busy":"2023-07-03T07:59:24.301143Z","iopub.status.idle":"2023-07-03T07:59:24.317456Z","shell.execute_reply":"2023-07-03T07:59:24.315692Z"},"papermill":{"duration":0.123772,"end_time":"2023-07-03T07:59:24.323163","exception":false,"start_time":"2023-07-03T07:59:24.199391","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=12,        # len(num_cols) = 12\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        # input shape : [batch, seq_len, len(num_cols)]            ->  [24, 1000, 12]\n","        # output shape: [batch, seq_len, numeraical_linear_size]   ->  [24, 1000, 64]\n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size)\n","                                              )\n","        \n","        # input shape : [batch, seq_len, numeraical_linear_size]   ->  [24, 1000, 64]\n","        # h_0 shape   : [D∗num_layers, batch, hidden_size]         ->  [2*2, 24, 128]\n","        # output shape: [batch, seq_len, D*hidden_size]            ->  [24,1000, 128*2]\n","        self.rnn = nn.GRU(numeraical_linear_size,    # input_size – The number of expected features in the input x\n","                          model_size,                # hidden_size – The number of features in the hidden state h\n","                          num_layers = 2,            # num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two GRUs together to form a stacked GRU\n","                          batch_first=True,          # If True, the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature).\n","                          bidirectional=True)\n","        \n","        # input shape : [batch, seq_len, D*hidden_size]  ->  [24, 1000, 128*2]\n","        # output shape: [batch, seq_len, linear_out]     ->  [24, 1000, 3]\n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),    # [128*2, 3]\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size)\n","                                        )\n","        self._reinitialize()\n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","    \n","    \n","    def forward(self, numerical_array, mask_array, attention_mask):        \n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _           = self.rnn(numerical_embedding)\n","        output              = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"6d830a97","metadata":{"papermill":{"duration":0.101473,"end_time":"2023-07-03T07:59:24.56527","exception":false,"start_time":"2023-07-03T07:59:24.463797","status":"completed"},"tags":[]},"source":["<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":27,"id":"9d20d221","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:24.764384Z","iopub.status.busy":"2023-07-03T07:59:24.764002Z","iopub.status.idle":"2023-07-03T07:59:25.773422Z","shell.execute_reply":"2023-07-03T07:59:25.772449Z"},"papermill":{"duration":1.110053,"end_time":"2023-07-03T07:59:25.775889","exception":false,"start_time":"2023-07-03T07:59:24.665836","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe022/fe022_id.parquet\"\n","\n","numerical_path = f\"./output/fe/fe022/fe022_num_array.npy\"\n","target_path    = f\"./output/fe/fe022/fe022_target_array.npy\"\n","mask_path      = f\"./output/fe/fe022/fe022_mask_array.npy\"\n","pred_use_path  = f\"./output/fe/fe022/fe022_pred_use_array.npy\"\n","\n","\n","df_id           = pd.read_parquet(id_path)\n","\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","pred_use_array  = np.load(pred_use_path)"]},{"cell_type":"code","execution_count":28,"id":"334e79ad","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:25.972231Z","iopub.status.busy":"2023-07-03T07:59:25.97129Z","iopub.status.idle":"2023-07-03T07:59:26.301116Z","shell.execute_reply":"2023-07-03T07:59:26.300044Z"},"papermill":{"duration":0.430213,"end_time":"2023-07-03T07:59:26.303497","exception":false,"start_time":"2023-07-03T07:59:25.873284","status":"completed"},"tags":[]},"outputs":[],"source":["target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i, :, 0]))\n","    target2.append(np.sum(target_array[i, :, 1]))\n","    target3.append(np.sum(target_array[i, :, 2]))"]},{"cell_type":"code","execution_count":29,"id":"61edc816","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:26.514164Z","iopub.status.busy":"2023-07-03T07:59:26.513825Z","iopub.status.idle":"2023-07-03T07:59:26.537442Z","shell.execute_reply":"2023-07-03T07:59:26.536624Z"},"papermill":{"duration":0.126368,"end_time":"2023-07-03T07:59:26.539394","exception":false,"start_time":"2023-07-03T07:59:26.413026","status":"completed"},"tags":[]},"outputs":[],"source":["df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)"]},{"cell_type":"code","execution_count":30,"id":"45a44340","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:26.736878Z","iopub.status.busy":"2023-07-03T07:59:26.736242Z","iopub.status.idle":"2023-07-03T07:59:26.744161Z","shell.execute_reply":"2023-07-03T07:59:26.743263Z"},"papermill":{"duration":0.106464,"end_time":"2023-07-03T07:59:26.74619","exception":false,"start_time":"2023-07-03T07:59:26.639726","status":"completed"},"tags":[]},"outputs":[],"source":["df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3"]},{"cell_type":"code","execution_count":31,"id":"e90249b1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:26.94862Z","iopub.status.busy":"2023-07-03T07:59:26.947178Z","iopub.status.idle":"2023-07-03T07:59:26.958241Z","shell.execute_reply":"2023-07-03T07:59:26.957164Z"},"papermill":{"duration":0.112708,"end_time":"2023-07-03T07:59:26.960416","exception":false,"start_time":"2023-07-03T07:59:26.847708","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    7720\n","1    4604\n","2     782\n","3     610\n","Name: group, dtype: int64"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df_id[\"group\"].value_counts()"]},{"cell_type":"markdown","id":"3b7e9843","metadata":{"papermill":{"duration":0.101628,"end_time":"2023-07-03T07:59:27.161925","exception":false,"start_time":"2023-07-03T07:59:27.060297","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":32,"id":"c0988460","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:27.359075Z","iopub.status.busy":"2023-07-03T07:59:27.358723Z","iopub.status.idle":"2023-07-03T07:59:27.438033Z","shell.execute_reply":"2023-07-03T07:59:27.437088Z"},"papermill":{"duration":0.180222,"end_time":"2023-07-03T07:59:27.440162","exception":false,"start_time":"2023-07-03T07:59:27.25994","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 10\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"0b5d9feb","metadata":{"papermill":{"duration":0.09981,"end_time":"2023-07-03T07:59:27.635734","exception":false,"start_time":"2023-07-03T07:59:27.535924","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>**ex143_tdcsfog_gru.ipynb**</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex143_tdcsfog_gru.ipynb\" style=\"text-decoration:none\">ex143_tdcsfog_gru.ipynb</a>"]},{"cell_type":"code","execution_count":33,"id":"cdb9efc0","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:27.830766Z","iopub.status.busy":"2023-07-03T07:59:27.830374Z","iopub.status.idle":"2023-07-03T07:59:27.837062Z","shell.execute_reply":"2023-07-03T07:59:27.836137Z"},"papermill":{"duration":0.105718,"end_time":"2023-07-03T07:59:27.839104","exception":false,"start_time":"2023-07-03T07:59:27.733386","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","\n","ex = \"143_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","    \n","logger_path = f\"./output/exp/ex{ex}/log_ex_{ex}.txt\"\n","LOGGER = init_logger(log_file=logger_path)\n","\n","# model_path  = f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}.pth\""]},{"cell_type":"markdown","id":"36a55ef8","metadata":{"papermill":{"duration":0.096931,"end_time":"2023-07-03T07:59:28.031775","exception":false,"start_time":"2023-07-03T07:59:27.934844","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":34,"id":"eca3e834","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:28.22684Z","iopub.status.busy":"2023-07-03T07:59:28.226359Z","iopub.status.idle":"2023-07-03T07:59:28.252054Z","shell.execute_reply":"2023-07-03T07:59:28.251014Z"},"papermill":{"duration":0.125915,"end_time":"2023-07-03T07:59:28.254174","exception":false,"start_time":"2023-07-03T07:59:28.128259","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n","Wall time: 8.58 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold: {fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"925d2b74","metadata":{"papermill":{"duration":0.100056,"end_time":"2023-07-03T07:59:28.455823","exception":false,"start_time":"2023-07-03T07:59:28.355767","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":35,"id":"3f1e4f7b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:28.653306Z","iopub.status.busy":"2023-07-03T07:59:28.652956Z","iopub.status.idle":"2023-07-03T07:59:28.66006Z","shell.execute_reply":"2023-07-03T07:59:28.659096Z"},"papermill":{"duration":0.110033,"end_time":"2023-07-03T07:59:28.662112","exception":false,"start_time":"2023-07-03T07:59:28.552079","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","\n","\n","\n","    # kaggle_json = {\"title\": f\"fog-ex{ex}\",\n","    #                \"id\": f\"takoihiraokazu/fog-ex{ex}\",\n","    #                \"licenses\": [{\"name\": \"CC0-1.0\"}]}\n","\n","    # with open(f\"./output/exp/ex{ex}/ex{ex}_model/dataset-metadata.json\", 'w') as f:\n","    #     json.dump(kaggle_json, f)\n","\n","\n","    # del LOGGER\n","    # gc.collect()\n","    # logging.shutdown()"]},{"cell_type":"markdown","id":"53d0c119","metadata":{"papermill":{"duration":0.096133,"end_time":"2023-07-03T07:59:28.853446","exception":false,"start_time":"2023-07-03T07:59:28.757313","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex145_tdcsfog_gru_StartHesitation.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex145_tdcsfog_gru_StartHesitation.ipynb\" style=\"text-decoration:none\">ex145_tdcsfog_gru_StartHesitation.ipynb</a>"]},{"cell_type":"code","execution_count":36,"id":"1f9cc062","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:29.04915Z","iopub.status.busy":"2023-07-03T07:59:29.048185Z","iopub.status.idle":"2023-07-03T07:59:29.053971Z","shell.execute_reply":"2023-07-03T07:59:29.053107Z"},"papermill":{"duration":0.106282,"end_time":"2023-07-03T07:59:29.055953","exception":false,"start_time":"2023-07-03T07:59:28.949671","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","\n","ex = \"145_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","    \n","# logger_path = f\"./output/exp/ex{ex}/log_ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"b1328d48","metadata":{"papermill":{"duration":0.095172,"end_time":"2023-07-03T07:59:29.24962","exception":false,"start_time":"2023-07-03T07:59:29.154448","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":37,"id":"68cf048c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:29.445662Z","iopub.status.busy":"2023-07-03T07:59:29.445304Z","iopub.status.idle":"2023-07-03T07:59:29.468726Z","shell.execute_reply":"2023-07-03T07:59:29.467832Z"},"papermill":{"duration":0.123102,"end_time":"2023-07-03T07:59:29.47132","exception":false,"start_time":"2023-07-03T07:59:29.348218","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 8.34 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold:{fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, 0    ]\n","                    output2 = output[:, :, [1,2]]\n","                    y1 = y[:, :, 0    ]\n","                    y2 = y[:, :, [1,2]]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.6 + loss2*0.4\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"261a7dc1","metadata":{"papermill":{"duration":0.098557,"end_time":"2023-07-03T07:59:29.665867","exception":false,"start_time":"2023-07-03T07:59:29.56731","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":38,"id":"2966eb7d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:29.859361Z","iopub.status.busy":"2023-07-03T07:59:29.858981Z","iopub.status.idle":"2023-07-03T07:59:29.865716Z","shell.execute_reply":"2023-07-03T07:59:29.864849Z"},"papermill":{"duration":0.105828,"end_time":"2023-07-03T07:59:29.867685","exception":false,"start_time":"2023-07-03T07:59:29.761857","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","\n","\n","\n","    # kaggle_json = {\"title\": f\"fog-ex{ex}\",\n","    #                \"id\": f\"takoihiraokazu/fog-ex{ex}\",\n","    #                \"licenses\": [{\"name\": \"CC0-1.0\"}]}\n","\n","    # with open(f\"./output/exp/ex{ex}/ex{ex}_model/dataset-metadata.json\", 'w') as f:\n","    #     json.dump(kaggle_json, f)\n","\n","\n","    # del LOGGER\n","    # gc.collect()"]},{"cell_type":"markdown","id":"ff569da4","metadata":{"papermill":{"duration":0.095539,"end_time":"2023-07-03T07:59:30.060943","exception":false,"start_time":"2023-07-03T07:59:29.965404","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex146_tdcsfog_gru_Turn.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex146_tdcsfog_gru_Turn.ipynb\" style=\"text-decoration:none\">ex146_tdcsfog_gru_Turn.ipynb</a>"]},{"cell_type":"code","execution_count":39,"id":"2b7b3333","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:30.255866Z","iopub.status.busy":"2023-07-03T07:59:30.255509Z","iopub.status.idle":"2023-07-03T07:59:30.261012Z","shell.execute_reply":"2023-07-03T07:59:30.260065Z"},"papermill":{"duration":0.105743,"end_time":"2023-07-03T07:59:30.262949","exception":false,"start_time":"2023-07-03T07:59:30.157206","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"146_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"9a5ae4bc","metadata":{"papermill":{"duration":0.095361,"end_time":"2023-07-03T07:59:30.457186","exception":false,"start_time":"2023-07-03T07:59:30.361825","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":40,"id":"e1676b8c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:30.653089Z","iopub.status.busy":"2023-07-03T07:59:30.652754Z","iopub.status.idle":"2023-07-03T07:59:30.676679Z","shell.execute_reply":"2023-07-03T07:59:30.675795Z"},"papermill":{"duration":0.126948,"end_time":"2023-07-03T07:59:30.679343","exception":false,"start_time":"2023-07-03T07:59:30.552395","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 8.11 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, 1    ]\n","                    output2 = output[:, :, [0,2]]\n","                    y1 = y[:, :, 1    ]\n","                    y2 = y[:, :, [0,2]]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.6 + loss2*0.4\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"43166d69","metadata":{"papermill":{"duration":0.099462,"end_time":"2023-07-03T07:59:30.876296","exception":false,"start_time":"2023-07-03T07:59:30.776834","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":41,"id":"9ee7705a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:31.071214Z","iopub.status.busy":"2023-07-03T07:59:31.070528Z","iopub.status.idle":"2023-07-03T07:59:31.077186Z","shell.execute_reply":"2023-07-03T07:59:31.076216Z"},"papermill":{"duration":0.105909,"end_time":"2023-07-03T07:59:31.079444","exception":false,"start_time":"2023-07-03T07:59:30.973535","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"d6d71c79","metadata":{"papermill":{"duration":0.098608,"end_time":"2023-07-03T07:59:31.276128","exception":false,"start_time":"2023-07-03T07:59:31.17752","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex147_tdcsfog_gru_Walking.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex147_tdcsfog_gru_Walking.ipynb\" style=\"text-decoration:none\">ex147_tdcsfog_gru_Walking.ipynb</a>"]},{"cell_type":"code","execution_count":42,"id":"c0649d0e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:31.470524Z","iopub.status.busy":"2023-07-03T07:59:31.469715Z","iopub.status.idle":"2023-07-03T07:59:31.476559Z","shell.execute_reply":"2023-07-03T07:59:31.475655Z"},"papermill":{"duration":0.106659,"end_time":"2023-07-03T07:59:31.479181","exception":false,"start_time":"2023-07-03T07:59:31.372522","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"147_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"8ba34408","metadata":{"papermill":{"duration":0.099184,"end_time":"2023-07-03T07:59:31.682357","exception":false,"start_time":"2023-07-03T07:59:31.583173","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":43,"id":"d7d5f8e7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:31.884358Z","iopub.status.busy":"2023-07-03T07:59:31.883967Z","iopub.status.idle":"2023-07-03T07:59:31.909988Z","shell.execute_reply":"2023-07-03T07:59:31.909007Z"},"papermill":{"duration":0.130057,"end_time":"2023-07-03T07:59:31.912081","exception":false,"start_time":"2023-07-03T07:59:31.782024","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 44 µs, sys: 0 ns, total: 44 µs\n","Wall time: 12.6 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, 2    ]\n","                    output2 = output[:, :, [0,1]]\n","                    y1 = y[:, :, 2    ]\n","                    y2 = y[:, :, [0,1]]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.6 + loss2*0.4\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"8f136211","metadata":{"papermill":{"duration":0.101435,"end_time":"2023-07-03T07:59:32.116861","exception":false,"start_time":"2023-07-03T07:59:32.015426","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":44,"id":"3ce7c52b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:32.321532Z","iopub.status.busy":"2023-07-03T07:59:32.321165Z","iopub.status.idle":"2023-07-03T07:59:32.328373Z","shell.execute_reply":"2023-07-03T07:59:32.327492Z"},"papermill":{"duration":0.114488,"end_time":"2023-07-03T07:59:32.33059","exception":false,"start_time":"2023-07-03T07:59:32.216102","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n"]},{"cell_type":"markdown","id":"7a7cf447","metadata":{"papermill":{"duration":0.10551,"end_time":"2023-07-03T07:59:32.540174","exception":false,"start_time":"2023-07-03T07:59:32.434664","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex182_tdcsfog_gru_StartHesitation_Turn.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex182_tdcsfog_gru_StartHesitation_Turn.ipynb\" style=\"text-decoration:none\">ex182_tdcsfog_gru_StartHesitation_Turn.ipynb</a>"]},{"cell_type":"code","execution_count":45,"id":"0e79eb0f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:32.740812Z","iopub.status.busy":"2023-07-03T07:59:32.740454Z","iopub.status.idle":"2023-07-03T07:59:32.74612Z","shell.execute_reply":"2023-07-03T07:59:32.745105Z"},"papermill":{"duration":0.106631,"end_time":"2023-07-03T07:59:32.748095","exception":false,"start_time":"2023-07-03T07:59:32.641464","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"182_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"cfc36f5e","metadata":{"papermill":{"duration":0.095037,"end_time":"2023-07-03T07:59:32.939525","exception":false,"start_time":"2023-07-03T07:59:32.844488","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":46,"id":"d4bd1d35","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:33.136649Z","iopub.status.busy":"2023-07-03T07:59:33.136282Z","iopub.status.idle":"2023-07-03T07:59:33.160397Z","shell.execute_reply":"2023-07-03T07:59:33.159481Z"},"papermill":{"duration":0.126549,"end_time":"2023-07-03T07:59:33.163005","exception":false,"start_time":"2023-07-03T07:59:33.036456","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 8.58 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, [0,1]]\n","                    output2 = output[:, :, 2]\n","                    y1 = y[:, :, [0,1]]\n","                    y2 = y[:, :, 2]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.8 + loss2*0.2\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"79852657","metadata":{"papermill":{"duration":0.096245,"end_time":"2023-07-03T07:59:33.355431","exception":false,"start_time":"2023-07-03T07:59:33.259186","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":47,"id":"cc451bb5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:33.563746Z","iopub.status.busy":"2023-07-03T07:59:33.563085Z","iopub.status.idle":"2023-07-03T07:59:33.570272Z","shell.execute_reply":"2023-07-03T07:59:33.569456Z"},"papermill":{"duration":0.110212,"end_time":"2023-07-03T07:59:33.572067","exception":false,"start_time":"2023-07-03T07:59:33.461855","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"9203c3bd","metadata":{"papermill":{"duration":0.096931,"end_time":"2023-07-03T07:59:33.768706","exception":false,"start_time":"2023-07-03T07:59:33.671775","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex183_tdcsfog_gru_StartHesitation_Walking.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex183_tdcsfog_gru_StartHesitation_Walking.ipynb\" style=\"text-decoration:none\">ex183_tdcsfog_gru_StartHesitation_Walking.ipynb</a>"]},{"cell_type":"code","execution_count":48,"id":"3bbb1179","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:33.961378Z","iopub.status.busy":"2023-07-03T07:59:33.961009Z","iopub.status.idle":"2023-07-03T07:59:33.966215Z","shell.execute_reply":"2023-07-03T07:59:33.96539Z"},"papermill":{"duration":0.104179,"end_time":"2023-07-03T07:59:33.968195","exception":false,"start_time":"2023-07-03T07:59:33.864016","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"183_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"76399ac5","metadata":{"papermill":{"duration":0.11361,"end_time":"2023-07-03T07:59:34.223037","exception":false,"start_time":"2023-07-03T07:59:34.109427","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":49,"id":"9e4e1466","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:34.458296Z","iopub.status.busy":"2023-07-03T07:59:34.457949Z","iopub.status.idle":"2023-07-03T07:59:34.483038Z","shell.execute_reply":"2023-07-03T07:59:34.482152Z"},"papermill":{"duration":0.161206,"end_time":"2023-07-03T07:59:34.48498","exception":false,"start_time":"2023-07-03T07:59:34.323774","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n","Wall time: 10 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, [0,2]]\n","                    output2 = output[:, :, 1]\n","                    y1 = y[:, :, [0,2]]\n","                    y2 = y[:, :, 1]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.8 + loss2*0.2\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"c004e5b7","metadata":{"papermill":{"duration":0.099927,"end_time":"2023-07-03T07:59:34.681273","exception":false,"start_time":"2023-07-03T07:59:34.581346","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":50,"id":"c8e3a9c8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:34.875994Z","iopub.status.busy":"2023-07-03T07:59:34.875107Z","iopub.status.idle":"2023-07-03T07:59:34.882199Z","shell.execute_reply":"2023-07-03T07:59:34.881365Z"},"papermill":{"duration":0.106787,"end_time":"2023-07-03T07:59:34.884208","exception":false,"start_time":"2023-07-03T07:59:34.777421","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"be380a62","metadata":{"papermill":{"duration":0.096762,"end_time":"2023-07-03T07:59:35.077082","exception":false,"start_time":"2023-07-03T07:59:34.98032","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex184_tdcsfog_gru_Turn_Walking.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex184_tdcsfog_gru_Turn_Walking.ipynb\" style=\"text-decoration:none\">ex184_tdcsfog_gru_Turn_Walking.ipynb</a>"]},{"cell_type":"code","execution_count":51,"id":"f2cb3061","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:35.276162Z","iopub.status.busy":"2023-07-03T07:59:35.275173Z","iopub.status.idle":"2023-07-03T07:59:35.281098Z","shell.execute_reply":"2023-07-03T07:59:35.280204Z"},"papermill":{"duration":0.107963,"end_time":"2023-07-03T07:59:35.283175","exception":false,"start_time":"2023-07-03T07:59:35.175212","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"184_tdcsfog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","\n","# logger_path = f\"./output/exp/ex{ex}/ex_{ex}.txt\"\n","# LOGGER = init_logger(log_file=logger_path)"]},{"cell_type":"markdown","id":"5395c612","metadata":{"papermill":{"duration":0.096153,"end_time":"2023-07-03T07:59:35.477122","exception":false,"start_time":"2023-07-03T07:59:35.380969","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":52,"id":"9ced3485","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:35.676499Z","iopub.status.busy":"2023-07-03T07:59:35.676116Z","iopub.status.idle":"2023-07-03T07:59:35.701498Z","shell.execute_reply":"2023-07-03T07:59:35.700483Z"},"papermill":{"duration":0.130544,"end_time":"2023-07-03T07:59:35.703495","exception":false,"start_time":"2023-07-03T07:59:35.572951","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n","Wall time: 8.82 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 1000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    # loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    output1 = output[:, :, [1,2]]\n","                    output2 = output[:, :, 0]\n","                    y1 = y[:, :, [1,2]]\n","                    y2 = y[:, :, 0]\n","                    loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    \n","                    loss = loss1*0.8 + loss2*0.2\n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 1000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                map_score = np.mean([StartHesitation, Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"3130bb77","metadata":{"papermill":{"duration":0.095654,"end_time":"2023-07-03T07:59:35.895664","exception":false,"start_time":"2023-07-03T07:59:35.80001","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":53,"id":"12e25f27","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:36.09153Z","iopub.status.busy":"2023-07-03T07:59:36.091153Z","iopub.status.idle":"2023-07-03T07:59:36.097746Z","shell.execute_reply":"2023-07-03T07:59:36.096858Z"},"papermill":{"duration":0.107691,"end_time":"2023-07-03T07:59:36.099736","exception":false,"start_time":"2023-07-03T07:59:35.992045","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"b6dd67c5","metadata":{"papermill":{"duration":0.096725,"end_time":"2023-07-03T07:59:36.296691","exception":false,"start_time":"2023-07-03T07:59:36.199966","status":"completed"},"tags":[]},"source":["<br>\n","\n","## **models choosed**\n","\n","<br>\n","\n","<font color=maroon size=5>All models above were used for final submission.</font>"]},{"cell_type":"markdown","id":"25f06aec","metadata":{"papermill":{"duration":0.097837,"end_time":"2023-07-03T07:59:36.491391","exception":false,"start_time":"2023-07-03T07:59:36.393554","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","# **defog** 【Training】\n","\n","<br>\n","\n","## **Feature Engineering**\n","\n","\n","### fe039_defog_base_feature\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe039_defog_base_feature.ipynb\" style=\"text-decoration:none\">fe039_defog_base_feature.ipynb</a>"]},{"cell_type":"code","execution_count":54,"id":"18ee9854","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:36.697509Z","iopub.status.busy":"2023-07-03T07:59:36.697121Z","iopub.status.idle":"2023-07-03T07:59:36.702298Z","shell.execute_reply":"2023-07-03T07:59:36.701362Z"},"papermill":{"duration":0.108001,"end_time":"2023-07-03T07:59:36.704239","exception":false,"start_time":"2023-07-03T07:59:36.596238","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"039\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":55,"id":"34e3cd32","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:36.900503Z","iopub.status.busy":"2023-07-03T07:59:36.900151Z","iopub.status.idle":"2023-07-03T07:59:36.905395Z","shell.execute_reply":"2023-07-03T07:59:36.904404Z"},"papermill":{"duration":0.104325,"end_time":"2023-07-03T07:59:36.907309","exception":false,"start_time":"2023-07-03T07:59:36.802984","status":"completed"},"tags":[]},"outputs":[],"source":["sub_dict = {}\n","for n,i in enumerate(defog_metadata[\"Subject\"].unique()):\n","    sub_dict[i] = n"]},{"cell_type":"code","execution_count":56,"id":"3c44a445","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:37.11043Z","iopub.status.busy":"2023-07-03T07:59:37.109393Z","iopub.status.idle":"2023-07-03T07:59:37.125919Z","shell.execute_reply":"2023-07-03T07:59:37.124993Z"},"papermill":{"duration":0.122467,"end_time":"2023-07-03T07:59:37.128013","exception":false,"start_time":"2023-07-03T07:59:37.005546","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Subject</th>\n","      <th>Visit</th>\n","      <th>Medication</th>\n","      <th>sub_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>02ab235146</td>\n","      <td>e1f62e</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>02ea782681</td>\n","      <td>ae2d35</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>06414383cf</td>\n","      <td>8c1f5e</td>\n","      <td>2</td>\n","      <td>off</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>092b4c1819</td>\n","      <td>2874c5</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0a900ed8a2</td>\n","      <td>0e3d49</td>\n","      <td>2</td>\n","      <td>on</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>f3a921edee</td>\n","      <td>1a778d</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>f40e8c6ebe</td>\n","      <td>575c60</td>\n","      <td>1</td>\n","      <td>off</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>f8ddbdd98d</td>\n","      <td>107712</td>\n","      <td>1</td>\n","      <td>on</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>f9efef91fb</td>\n","      <td>5d9cae</td>\n","      <td>2</td>\n","      <td>off</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>f9fc61ce85</td>\n","      <td>040587</td>\n","      <td>1</td>\n","      <td>on</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>137 rows × 5 columns</p>\n","</div>"],"text/plain":["             Id Subject  Visit Medication  sub_id\n","0    02ab235146  e1f62e      2         on       0\n","1    02ea782681  ae2d35      2         on       1\n","2    06414383cf  8c1f5e      2        off       2\n","3    092b4c1819  2874c5      1        off       3\n","4    0a900ed8a2  0e3d49      2         on       4\n","..          ...     ...    ...        ...     ...\n","132  f3a921edee  1a778d      1        off       8\n","133  f40e8c6ebe  575c60      1        off      38\n","134  f8ddbdd98d  107712      1         on      39\n","135  f9efef91fb  5d9cae      2        off      44\n","136  f9fc61ce85  040587      1         on      21\n","\n","[137 rows x 5 columns]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["defog_metadata[\"sub_id\"] = defog_metadata[\"Subject\"].map(sub_dict)\n","defog_metadata"]},{"cell_type":"code","execution_count":57,"id":"4cd9877b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:37.33494Z","iopub.status.busy":"2023-07-03T07:59:37.334593Z","iopub.status.idle":"2023-07-03T07:59:37.339553Z","shell.execute_reply":"2023-07-03T07:59:37.338545Z"},"papermill":{"duration":0.106965,"end_time":"2023-07-03T07:59:37.341488","exception":false,"start_time":"2023-07-03T07:59:37.234523","status":"completed"},"tags":[]},"outputs":[],"source":["with open(f'./output/fe/fe{fe}/fe{fe}_sub_id.pkl', 'wb') as p:\n","    pickle.dump(sub_dict, p)"]},{"cell_type":"code","execution_count":58,"id":"eeb2d639","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:37.539081Z","iopub.status.busy":"2023-07-03T07:59:37.538159Z","iopub.status.idle":"2023-07-03T07:59:37.542893Z","shell.execute_reply":"2023-07-03T07:59:37.54204Z"},"papermill":{"duration":0.105586,"end_time":"2023-07-03T07:59:37.544784","exception":false,"start_time":"2023-07-03T07:59:37.439198","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/defog/*.csv\"\n","\n","# meta = pd.read_csv(DEFOG_META_PATH)\n","# data_list = glob.glob(DEFOG_FOLDER)"]},{"cell_type":"code","execution_count":59,"id":"4606d19a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T07:59:37.748025Z","iopub.status.busy":"2023-07-03T07:59:37.747665Z","iopub.status.idle":"2023-07-03T08:00:02.205808Z","shell.execute_reply":"2023-07-03T08:00:02.204799Z"},"papermill":{"duration":24.562469,"end_time":"2023-07-03T08:00:02.208182","exception":false,"start_time":"2023-07-03T07:59:37.645713","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [00:21<00:00,  4.33it/s]\n"]}],"source":["df_all = []\n","for i in tqdm(train_defog):\n","    df = pd.read_csv(i)\n","    df_all.append(df)\n","df_all = pd.concat(df_all).reset_index(drop=True)\n","\n","# len(df_all)"]},{"cell_type":"code","execution_count":60,"id":"274ede80","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:02.419849Z","iopub.status.busy":"2023-07-03T08:00:02.419465Z","iopub.status.idle":"2023-07-03T08:00:02.437006Z","shell.execute_reply":"2023-07-03T08:00:02.436035Z"},"papermill":{"duration":0.125774,"end_time":"2023-07-03T08:00:02.439962","exception":false,"start_time":"2023-07-03T08:00:02.314188","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Time</th>\n","      <th>AccV</th>\n","      <th>AccML</th>\n","      <th>AccAP</th>\n","      <th>StartHesitation</th>\n","      <th>Turn</th>\n","      <th>Walking</th>\n","      <th>Valid</th>\n","      <th>Task</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>-1.002697</td>\n","      <td>0.022371</td>\n","      <td>0.068304</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>-1.002641</td>\n","      <td>0.019173</td>\n","      <td>0.066162</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>-0.999820</td>\n","      <td>0.019142</td>\n","      <td>0.067536</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>-0.998023</td>\n","      <td>0.018378</td>\n","      <td>0.068409</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>-0.998359</td>\n","      <td>0.016726</td>\n","      <td>0.066448</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>13525697</th>\n","      <td>109120</td>\n","      <td>-0.939241</td>\n","      <td>0.031564</td>\n","      <td>-0.394737</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525698</th>\n","      <td>109121</td>\n","      <td>-0.941096</td>\n","      <td>0.031582</td>\n","      <td>-0.392626</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525699</th>\n","      <td>109122</td>\n","      <td>-0.940131</td>\n","      <td>0.029092</td>\n","      <td>-0.394385</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525700</th>\n","      <td>109123</td>\n","      <td>-0.939872</td>\n","      <td>0.028058</td>\n","      <td>-0.398664</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13525701</th>\n","      <td>109124</td>\n","      <td>-0.939006</td>\n","      <td>0.026628</td>\n","      <td>-0.398454</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>13525702 rows × 9 columns</p>\n","</div>"],"text/plain":["            Time      AccV     AccML     AccAP  StartHesitation  Turn  \\\n","0              0 -1.002697  0.022371  0.068304                0     0   \n","1              1 -1.002641  0.019173  0.066162                0     0   \n","2              2 -0.999820  0.019142  0.067536                0     0   \n","3              3 -0.998023  0.018378  0.068409                0     0   \n","4              4 -0.998359  0.016726  0.066448                0     0   \n","...          ...       ...       ...       ...              ...   ...   \n","13525697  109120 -0.939241  0.031564 -0.394737                0     0   \n","13525698  109121 -0.941096  0.031582 -0.392626                0     0   \n","13525699  109122 -0.940131  0.029092 -0.394385                0     0   \n","13525700  109123 -0.939872  0.028058 -0.398664                0     0   \n","13525701  109124 -0.939006  0.026628 -0.398454                0     0   \n","\n","          Walking  Valid   Task  \n","0               0  False  False  \n","1               0  False  False  \n","2               0  False  False  \n","3               0  False  False  \n","4               0  False  False  \n","...           ...    ...    ...  \n","13525697        0  False  False  \n","13525698        0  False  False  \n","13525699        0  False  False  \n","13525700        0  False  False  \n","13525701        0  False  False  \n","\n","[13525702 rows x 9 columns]"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["df_all"]},{"cell_type":"code","execution_count":61,"id":"dc734a8b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:02.671681Z","iopub.status.busy":"2023-07-03T08:00:02.671309Z","iopub.status.idle":"2023-07-03T08:00:03.188622Z","shell.execute_reply":"2023-07-03T08:00:03.187647Z"},"papermill":{"duration":0.630707,"end_time":"2023-07-03T08:00:03.190987","exception":false,"start_time":"2023-07-03T08:00:02.56028","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["AccV -0.9401728865187444 0.0860651354523073\n","AccML 0.0011727847170219124 0.12000798550797488\n","AccAP -0.13061518435798145 0.28238873112037965\n"]}],"source":["mean_std_dict = {}\n","for c in [\"AccV\", \"AccML\", \"AccAP\"]:\n","    mean = df_all[c].mean()\n","    std = df_all[c].std()\n","    mean_std_dict[c] = [mean,std]\n","    print(c, mean, std)"]},{"cell_type":"code","execution_count":62,"id":"6a27a202","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:03.414165Z","iopub.status.busy":"2023-07-03T08:00:03.413224Z","iopub.status.idle":"2023-07-03T08:00:03.418682Z","shell.execute_reply":"2023-07-03T08:00:03.417621Z"},"papermill":{"duration":0.119235,"end_time":"2023-07-03T08:00:03.420843","exception":false,"start_time":"2023-07-03T08:00:03.301608","status":"completed"},"tags":[]},"outputs":[],"source":["with open(f'./output/fe/fe{fe}/save/fe{fe}_sc.pkl', 'wb') as p:\n","    pickle.dump(mean_std_dict, p)"]},{"cell_type":"code","execution_count":63,"id":"a5e85d17","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:03.676266Z","iopub.status.busy":"2023-07-03T08:00:03.675922Z","iopub.status.idle":"2023-07-03T08:00:18.457943Z","shell.execute_reply":"2023-07-03T08:00:18.456514Z"},"papermill":{"duration":14.891096,"end_time":"2023-07-03T08:00:18.459832","exception":false,"start_time":"2023-07-03T08:00:03.568736","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_metadata: : 137it [00:14,  9.29it/s]\n"]}],"source":["d_list = []\n","num_array = []\n","target_array = []\n","valid_array = []\n","subject_list = []\n","id_list = []\n","mask_array = []\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 1000\n","\n","for i,s in tqdm(zip(defog_metadata[\"Id\"].values, defog_metadata[\"sub_id\"].values), desc=\"defog_metadata: \"):\n","    path = root_data + f\"train/defog/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_defog]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df) // seq_len) + 1\n","        \n","        for c in num_cols:\n","            df[c] = (df[c] - mean_std_dict[c][0]) / mean_std_dict[c][1]\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        \n","        num_array_    = np.zeros([batch, seq_len, 3])\n","        target_array_ = np.zeros([batch, seq_len, 3])\n","        mask_array_   = np.zeros([batch, seq_len])\n","        valid_array_  = np.zeros([batch, seq_len])\n","        \n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*seq_len : ]\n","                num_array_[b, :len(num_), :] = num_\n","                target_ = target[b*seq_len : ]\n","                target_array_[b,:len(target_), :] = target_\n","                valid_ = valid[b*seq_len : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","                mask_array_[b, :len(target_)] = 1\n","            else:\n","                num_ = num[b*seq_len : (b+1)*seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*seq_len : (b+1)*seq_len]\n","                target_array_[b, :, :] = target_\n","                valid_ = valid[b*seq_len : (b+1)*seq_len]\n","                valid_array_[b, :] = valid_\n","                mask_array_[b,:] = 1\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":64,"id":"2bb7af00","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:18.684136Z","iopub.status.busy":"2023-07-03T08:00:18.68379Z","iopub.status.idle":"2023-07-03T08:00:19.544235Z","shell.execute_reply":"2023-07-03T08:00:19.543184Z"},"papermill":{"duration":0.976414,"end_time":"2023-07-03T08:00:19.546713","exception":false,"start_time":"2023-07-03T08:00:18.570299","status":"completed"},"tags":[]},"outputs":[],"source":["num_array    = np.concatenate(num_array, axis=0)\n","target_array = np.concatenate(target_array, axis=0)\n","mask_array   =  np.concatenate(mask_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":65,"id":"368beb0c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:19.77979Z","iopub.status.busy":"2023-07-03T08:00:19.779447Z","iopub.status.idle":"2023-07-03T08:00:19.788731Z","shell.execute_reply":"2023-07-03T08:00:19.787883Z"},"papermill":{"duration":0.124317,"end_time":"2023-07-03T08:00:19.790855","exception":false,"start_time":"2023-07-03T08:00:19.666538","status":"completed"},"tags":[]},"outputs":[],"source":["defog_metadata[\"data_is\"] = d_list\n","\n","defog_metadata.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":66,"id":"dee34e40","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:20.015825Z","iopub.status.busy":"2023-07-03T08:00:20.015449Z","iopub.status.idle":"2023-07-03T08:00:20.08766Z","shell.execute_reply":"2023-07-03T08:00:20.086642Z"},"papermill":{"duration":0.185828,"end_time":"2023-07-03T08:00:20.089822","exception":false,"start_time":"2023-07-03T08:00:19.903994","status":"completed"},"tags":[]},"outputs":[],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"f7821cb9","metadata":{"papermill":{"duration":0.10899,"end_time":"2023-07-03T08:00:20.30941","exception":false,"start_time":"2023-07-03T08:00:20.20042","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe047_defog_5000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe047_defog_5000.ipynb\" style=\"text-decoration:none\">fe047_defog_5000.ipynb</a>"]},{"cell_type":"code","execution_count":67,"id":"da93c7b5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:20.529682Z","iopub.status.busy":"2023-07-03T08:00:20.529302Z","iopub.status.idle":"2023-07-03T08:00:20.534591Z","shell.execute_reply":"2023-07-03T08:00:20.533648Z"},"papermill":{"duration":0.116664,"end_time":"2023-07-03T08:00:20.536584","exception":false,"start_time":"2023-07-03T08:00:20.41992","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"047\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":68,"id":"c2de5b2e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:20.756799Z","iopub.status.busy":"2023-07-03T08:00:20.756469Z","iopub.status.idle":"2023-07-03T08:00:20.761805Z","shell.execute_reply":"2023-07-03T08:00:20.760841Z"},"papermill":{"duration":0.118507,"end_time":"2023-07-03T08:00:20.763818","exception":false,"start_time":"2023-07-03T08:00:20.645311","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff', \n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":69,"id":"39e8d7b4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:20.987208Z","iopub.status.busy":"2023-07-03T08:00:20.986875Z","iopub.status.idle":"2023-07-03T08:00:20.994606Z","shell.execute_reply":"2023-07-03T08:00:20.993727Z"},"papermill":{"duration":0.121131,"end_time":"2023-07-03T08:00:20.996599","exception":false,"start_time":"2023-07-03T08:00:20.875468","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":70,"id":"17b7d0b8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:21.220253Z","iopub.status.busy":"2023-07-03T08:00:21.219879Z","iopub.status.idle":"2023-07-03T08:00:43.738597Z","shell.execute_reply":"2023-07-03T08:00:43.737465Z"},"papermill":{"duration":22.636922,"end_time":"2023-07-03T08:00:43.744047","exception":false,"start_time":"2023-07-03T08:00:21.107125","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_metadata: : 137it [00:22,  6.09it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_metadata[\"Id\"].values, defog_metadata[\"sub_id\"].values), desc=\"defog_metadata: \"):\n","    path = root_data + f\"train/defog/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_defog]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 3])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":71,"id":"1cd30b8a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:00:43.997538Z","iopub.status.busy":"2023-07-03T08:00:43.996993Z","iopub.status.idle":"2023-07-03T08:00:59.735511Z","shell.execute_reply":"2023-07-03T08:00:59.732849Z"},"papermill":{"duration":15.867486,"end_time":"2023-07-03T08:00:59.741501","exception":false,"start_time":"2023-07-03T08:00:43.874015","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":72,"id":"c0dbc6c6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:00.244476Z","iopub.status.busy":"2023-07-03T08:01:00.244096Z","iopub.status.idle":"2023-07-03T08:01:00.280706Z","shell.execute_reply":"2023-07-03T08:01:00.279788Z"},"papermill":{"duration":0.209089,"end_time":"2023-07-03T08:01:00.282715","exception":false,"start_time":"2023-07-03T08:01:00.073626","status":"completed"},"tags":[]},"outputs":[],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"4fd5b407","metadata":{"papermill":{"duration":0.116029,"end_time":"2023-07-03T08:01:00.51634","exception":false,"start_time":"2023-07-03T08:01:00.400311","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>**Training**</font>\n","\n","\n","<br>\n","\n","### helpers"]},{"cell_type":"code","execution_count":73,"id":"7f76ec22","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:00.756592Z","iopub.status.busy":"2023-07-03T08:01:00.755707Z","iopub.status.idle":"2023-07-03T08:01:00.76065Z","shell.execute_reply":"2023-07-03T08:01:00.759496Z"},"papermill":{"duration":0.128778,"end_time":"2023-07-03T08:01:00.763002","exception":false,"start_time":"2023-07-03T08:01:00.634224","status":"completed"},"tags":[]},"outputs":[],"source":["TRAIN_FLAG_DEFOG = True"]},{"cell_type":"markdown","id":"44df20a7","metadata":{"papermill":{"duration":0.122025,"end_time":"2023-07-03T08:01:01.003301","exception":false,"start_time":"2023-07-03T08:01:00.881276","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `set_seed()`"]},{"cell_type":"code","execution_count":74,"id":"e9394f74","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:01.255486Z","iopub.status.busy":"2023-07-03T08:01:01.254569Z","iopub.status.idle":"2023-07-03T08:01:01.260732Z","shell.execute_reply":"2023-07-03T08:01:01.259878Z"},"papermill":{"duration":0.132823,"end_time":"2023-07-03T08:01:01.262748","exception":false,"start_time":"2023-07-03T08:01:01.129925","status":"completed"},"tags":[]},"outputs":[],"source":["def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","id":"7633f5bb","metadata":{"papermill":{"duration":0.116996,"end_time":"2023-07-03T08:01:01.540214","exception":false,"start_time":"2023-07-03T08:01:01.423218","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `timer()`"]},{"cell_type":"code","execution_count":75,"id":"3d6fc83a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:01.784186Z","iopub.status.busy":"2023-07-03T08:01:01.783839Z","iopub.status.idle":"2023-07-03T08:01:01.789171Z","shell.execute_reply":"2023-07-03T08:01:01.788151Z"},"papermill":{"duration":0.131009,"end_time":"2023-07-03T08:01:01.791159","exception":false,"start_time":"2023-07-03T08:01:01.66015","status":"completed"},"tags":[]},"outputs":[],"source":["@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    \n","    yield \n","    # LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(\"=\"*66)\n","    print(\"\\n\"*2)\n","    \n","# setup_logger(out_file=logger_path)"]},{"cell_type":"markdown","id":"3d5e2251","metadata":{"papermill":{"duration":0.118588,"end_time":"2023-07-03T08:01:02.029099","exception":false,"start_time":"2023-07-03T08:01:01.910511","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### def `preprocess()`"]},{"cell_type":"code","execution_count":76,"id":"3570ccf4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:02.268966Z","iopub.status.busy":"2023-07-03T08:01:02.268599Z","iopub.status.idle":"2023-07-03T08:01:02.273689Z","shell.execute_reply":"2023-07-03T08:01:02.27283Z"},"papermill":{"duration":0.126014,"end_time":"2023-07-03T08:01:02.275589","exception":false,"start_time":"2023-07-03T08:01:02.149575","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array, valid_array,):\n","    \n","    attention_mask = mask_array == 0\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'input_data_valid_array': valid_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"7a9265da","metadata":{"papermill":{"duration":0.116784,"end_time":"2023-07-03T08:01:02.50978","exception":false,"start_time":"2023-07-03T08:01:02.392996","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogDataset()`"]},{"cell_type":"code","execution_count":77,"id":"dfdbdc37","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:02.745002Z","iopub.status.busy":"2023-07-03T08:01:02.744308Z","iopub.status.idle":"2023-07-03T08:01:02.754615Z","shell.execute_reply":"2023-07-03T08:01:02.753678Z"},"papermill":{"duration":0.132302,"end_time":"2023-07-03T08:01:02.756618","exception":false,"start_time":"2023-07-03T08:01:02.624316","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, valid_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.valid_array = valid_array\n","        self.train = train\n","        self.y = y\n","    \n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","    \n","    \n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item], self.valid_array[item],)\n","\n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'],  dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),   \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\": torch.tensor(self.y[item], dtype=torch.float32)\n","            }\n","        else:\n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),  \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"32b8b852","metadata":{"papermill":{"duration":0.116361,"end_time":"2023-07-03T08:01:02.992778","exception":false,"start_time":"2023-07-03T08:01:02.876417","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":78,"id":"14b2d39f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:03.234709Z","iopub.status.busy":"2023-07-03T08:01:03.234344Z","iopub.status.idle":"2023-07-03T08:01:03.246096Z","shell.execute_reply":"2023-07-03T08:01:03.244641Z"},"papermill":{"duration":0.133947,"end_time":"2023-07-03T08:01:03.248317","exception":false,"start_time":"2023-07-03T08:01:03.11437","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"12303061","metadata":{"papermill":{"duration":0.116646,"end_time":"2023-07-03T08:01:03.480423","exception":false,"start_time":"2023-07-03T08:01:03.363777","status":"completed"},"tags":[]},"source":["<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":79,"id":"514d784f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:03.719026Z","iopub.status.busy":"2023-07-03T08:01:03.718053Z","iopub.status.idle":"2023-07-03T08:01:03.723304Z","shell.execute_reply":"2023-07-03T08:01:03.722394Z"},"papermill":{"duration":0.128241,"end_time":"2023-07-03T08:01:03.725262","exception":false,"start_time":"2023-07-03T08:01:03.597021","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe047/fe047_id.parquet\"\n","numerical_path = f\"./output/fe/fe047/fe047_num_array.npy\"\n","target_path    = f\"./output/fe/fe047/fe047_target_array.npy\"\n","mask_path      = f\"./output/fe/fe047/fe047_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe047/fe047_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe047/fe047_pred_use_array.npy\""]},{"cell_type":"code","execution_count":80,"id":"e57210ff","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:03.972345Z","iopub.status.busy":"2023-07-03T08:01:03.971887Z","iopub.status.idle":"2023-07-03T08:01:20.098144Z","shell.execute_reply":"2023-07-03T08:01:20.097214Z"},"papermill":{"duration":16.25408,"end_time":"2023-07-03T08:01:20.101445","exception":false,"start_time":"2023-07-03T08:01:03.847365","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    4107\n","2     897\n","3     354\n","1      11\n","Name: group, dtype: int64"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array = np.load(target_path)\n","mask_array = np.load(mask_path)\n","valid_array = np.load(valid_path)\n","pred_use_array = np.load(pred_use_path)\n","\n","target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i,:,0]))\n","    target2.append(np.sum(target_array[i,:,1]))\n","    target3.append(np.sum(target_array[i,:,2]))\n","\n","\n","df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)\n","\n","df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3\n","\n","\n","df_id[\"group\"].value_counts()"]},{"cell_type":"markdown","id":"5e10bfee","metadata":{"papermill":{"duration":0.116407,"end_time":"2023-07-03T08:01:20.340548","exception":false,"start_time":"2023-07-03T08:01:20.224141","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":81,"id":"b372cfb5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:20.655296Z","iopub.status.busy":"2023-07-03T08:01:20.654941Z","iopub.status.idle":"2023-07-03T08:01:20.660582Z","shell.execute_reply":"2023-07-03T08:01:20.659766Z"},"papermill":{"duration":0.181692,"end_time":"2023-07-03T08:01:20.666889","exception":false,"start_time":"2023-07-03T08:01:20.485197","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 15\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"be0b75c2","metadata":{"papermill":{"duration":0.168446,"end_time":"2023-07-03T08:01:21.001949","exception":false,"start_time":"2023-07-03T08:01:20.833503","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex153_defog_gru.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex153_defog_gru.ipynb\" style=\"text-decoration:none\">ex153_defog_gru.ipynb</a>"]},{"cell_type":"code","execution_count":82,"id":"5d8bb04d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:21.333694Z","iopub.status.busy":"2023-07-03T08:01:21.333279Z","iopub.status.idle":"2023-07-03T08:01:21.338713Z","shell.execute_reply":"2023-07-03T08:01:21.337886Z"},"papermill":{"duration":0.171973,"end_time":"2023-07-03T08:01:21.342577","exception":false,"start_time":"2023-07-03T08:01:21.170604","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"5e9a543d","metadata":{"papermill":{"duration":0.168702,"end_time":"2023-07-03T08:01:21.677531","exception":false,"start_time":"2023-07-03T08:01:21.508829","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":83,"id":"4f1068b7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:21.99211Z","iopub.status.busy":"2023-07-03T08:01:21.991723Z","iopub.status.idle":"2023-07-03T08:01:22.022277Z","shell.execute_reply":"2023-07-03T08:01:22.020834Z"},"papermill":{"duration":0.179354,"end_time":"2023-07-03T08:01:22.024603","exception":false,"start_time":"2023-07-03T08:01:21.845249","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 8.34 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"17cd0372","metadata":{"papermill":{"duration":0.119959,"end_time":"2023-07-03T08:01:22.263434","exception":false,"start_time":"2023-07-03T08:01:22.143475","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":84,"id":"d0e7f916","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:22.558415Z","iopub.status.busy":"2023-07-03T08:01:22.558016Z","iopub.status.idle":"2023-07-03T08:01:22.564835Z","shell.execute_reply":"2023-07-03T08:01:22.563845Z"},"papermill":{"duration":0.179311,"end_time":"2023-07-03T08:01:22.566718","exception":false,"start_time":"2023-07-03T08:01:22.387407","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"741a54ba","metadata":{"papermill":{"duration":0.11753,"end_time":"2023-07-03T08:01:22.804158","exception":false,"start_time":"2023-07-03T08:01:22.686628","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex154_defog_gru.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex154_defog_gru.ipynb\" style=\"text-decoration:none\">ex154_defog_gru.ipynb</a>"]},{"cell_type":"code","execution_count":85,"id":"355221dd","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:23.042263Z","iopub.status.busy":"2023-07-03T08:01:23.04185Z","iopub.status.idle":"2023-07-03T08:01:23.04749Z","shell.execute_reply":"2023-07-03T08:01:23.046479Z"},"papermill":{"duration":0.128509,"end_time":"2023-07-03T08:01:23.049649","exception":false,"start_time":"2023-07-03T08:01:22.92114","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"154_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"c3e7dc33","metadata":{"papermill":{"duration":0.116627,"end_time":"2023-07-03T08:01:23.294792","exception":false,"start_time":"2023-07-03T08:01:23.178165","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":86,"id":"0be3e9be","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:23.531589Z","iopub.status.busy":"2023-07-03T08:01:23.530713Z","iopub.status.idle":"2023-07-03T08:01:23.542268Z","shell.execute_reply":"2023-07-03T08:01:23.541335Z"},"papermill":{"duration":0.133038,"end_time":"2023-07-03T08:01:23.544312","exception":false,"start_time":"2023-07-03T08:01:23.411274","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 96,\n","                 model_size = 256,\n","                 linear_out = 256,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"69763f7e","metadata":{"papermill":{"duration":0.11723,"end_time":"2023-07-03T08:01:23.77912","exception":false,"start_time":"2023-07-03T08:01:23.66189","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":87,"id":"25318b4b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:24.017886Z","iopub.status.busy":"2023-07-03T08:01:24.017524Z","iopub.status.idle":"2023-07-03T08:01:24.042486Z","shell.execute_reply":"2023-07-03T08:01:24.041562Z"},"papermill":{"duration":0.149217,"end_time":"2023-07-03T08:01:24.045001","exception":false,"start_time":"2023-07-03T08:01:23.895784","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 6 µs, sys: 2 µs, total: 8 µs\n","Wall time: 12.6 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"599c4536","metadata":{"papermill":{"duration":0.116313,"end_time":"2023-07-03T08:01:24.289206","exception":false,"start_time":"2023-07-03T08:01:24.172893","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":88,"id":"3ba9036a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:24.563961Z","iopub.status.busy":"2023-07-03T08:01:24.563597Z","iopub.status.idle":"2023-07-03T08:01:24.570266Z","shell.execute_reply":"2023-07-03T08:01:24.569399Z"},"papermill":{"duration":0.12546,"end_time":"2023-07-03T08:01:24.572228","exception":false,"start_time":"2023-07-03T08:01:24.446768","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"6876d473","metadata":{"papermill":{"duration":0.116616,"end_time":"2023-07-03T08:01:24.804626","exception":false,"start_time":"2023-07-03T08:01:24.68801","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","\n","# **notype** 【Training】\n","\n","\n","<br>\n","\n","## **Feature Engineering**\n","\n","\n","<br>\n","\n","### fe061_notype_5000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe061_notype_5000.ipynb\" style=\"text-decoration:none\">fe061_notype_5000.ipynb</a>"]},{"cell_type":"code","execution_count":89,"id":"1dd63ffc","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:25.042208Z","iopub.status.busy":"2023-07-03T08:01:25.041557Z","iopub.status.idle":"2023-07-03T08:01:25.047101Z","shell.execute_reply":"2023-07-03T08:01:25.04604Z"},"papermill":{"duration":0.127446,"end_time":"2023-07-03T08:01:25.049179","exception":false,"start_time":"2023-07-03T08:01:24.921733","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"061_notype\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":90,"id":"1e21883a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:25.289196Z","iopub.status.busy":"2023-07-03T08:01:25.288063Z","iopub.status.idle":"2023-07-03T08:01:25.303804Z","shell.execute_reply":"2023-07-03T08:01:25.302725Z"},"papermill":{"duration":0.137415,"end_time":"2023-07-03T08:01:25.307115","exception":false,"start_time":"2023-07-03T08:01:25.1697","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":91,"id":"7ebee6c6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:25.549473Z","iopub.status.busy":"2023-07-03T08:01:25.549091Z","iopub.status.idle":"2023-07-03T08:01:25.554271Z","shell.execute_reply":"2023-07-03T08:01:25.553398Z"},"papermill":{"duration":0.12458,"end_time":"2023-07-03T08:01:25.556094","exception":false,"start_time":"2023-07-03T08:01:25.431514","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\",  \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff',  \n","            'AccML_lag_diff', 'AccML_lead_diff', \n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"Event\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":92,"id":"f16f5ecc","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:25.795819Z","iopub.status.busy":"2023-07-03T08:01:25.794962Z","iopub.status.idle":"2023-07-03T08:01:25.879324Z","shell.execute_reply":"2023-07-03T08:01:25.87838Z"},"papermill":{"duration":0.207337,"end_time":"2023-07-03T08:01:25.881704","exception":false,"start_time":"2023-07-03T08:01:25.674367","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":93,"id":"512b0d42","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:26.171214Z","iopub.status.busy":"2023-07-03T08:01:26.170844Z","iopub.status.idle":"2023-07-03T08:01:46.126876Z","shell.execute_reply":"2023-07-03T08:01:46.125587Z"},"papermill":{"duration":20.124984,"end_time":"2023-07-03T08:01:46.128927","exception":false,"start_time":"2023-07-03T08:01:26.003943","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_meta: : 137it [00:19,  6.87it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values), desc=\"defog_meta: \"):\n","    path = root_data + f\"train/notype/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 1])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":94,"id":"1cd26cd5","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:46.375398Z","iopub.status.busy":"2023-07-03T08:01:46.374501Z","iopub.status.idle":"2023-07-03T08:01:52.998836Z","shell.execute_reply":"2023-07-03T08:01:52.997204Z"},"papermill":{"duration":6.751214,"end_time":"2023-07-03T08:01:53.002967","exception":false,"start_time":"2023-07-03T08:01:46.251753","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":95,"id":"08c8f485","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:56.96581Z","iopub.status.busy":"2023-07-03T08:01:56.965439Z","iopub.status.idle":"2023-07-03T08:01:57.000296Z","shell.execute_reply":"2023-07-03T08:01:56.999282Z"},"papermill":{"duration":0.248504,"end_time":"2023-07-03T08:01:57.002681","exception":false,"start_time":"2023-07-03T08:01:56.754177","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["46"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id[\"Id\"].nunique()"]},{"cell_type":"code","execution_count":96,"id":"5c7a6e29","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:57.263894Z","iopub.status.busy":"2023-07-03T08:01:57.263232Z","iopub.status.idle":"2023-07-03T08:01:57.273426Z","shell.execute_reply":"2023-07-03T08:01:57.272554Z"},"papermill":{"duration":0.140408,"end_time":"2023-07-03T08:01:57.275433","exception":false,"start_time":"2023-07-03T08:01:57.135025","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"5130c230","metadata":{"papermill":{"duration":0.124396,"end_time":"2023-07-03T08:01:57.526669","exception":false,"start_time":"2023-07-03T08:01:57.402273","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe064_notype_10000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe064_notype_10000.ipynb\" style=\"text-decoration:none\">fe064_notype_10000.ipynb</a>"]},{"cell_type":"code","execution_count":97,"id":"69bab2a9","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:57.777024Z","iopub.status.busy":"2023-07-03T08:01:57.776632Z","iopub.status.idle":"2023-07-03T08:01:57.782918Z","shell.execute_reply":"2023-07-03T08:01:57.781261Z"},"papermill":{"duration":0.132442,"end_time":"2023-07-03T08:01:57.785071","exception":false,"start_time":"2023-07-03T08:01:57.652629","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"064_notype\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":98,"id":"b80fed89","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:58.043161Z","iopub.status.busy":"2023-07-03T08:01:58.042809Z","iopub.status.idle":"2023-07-03T08:01:58.052858Z","shell.execute_reply":"2023-07-03T08:01:58.051828Z"},"papermill":{"duration":0.143398,"end_time":"2023-07-03T08:01:58.055313","exception":false,"start_time":"2023-07-03T08:01:57.911915","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":99,"id":"3f11a611","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:58.308782Z","iopub.status.busy":"2023-07-03T08:01:58.308403Z","iopub.status.idle":"2023-07-03T08:01:58.313873Z","shell.execute_reply":"2023-07-03T08:01:58.312845Z"},"papermill":{"duration":0.13283,"end_time":"2023-07-03T08:01:58.316264","exception":false,"start_time":"2023-07-03T08:01:58.183434","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"Event\"]\n","seq_len = 10000\n","shift = 5000\n","offset = 2500"]},{"cell_type":"code","execution_count":100,"id":"c6a5b70f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:58.570226Z","iopub.status.busy":"2023-07-03T08:01:58.569874Z","iopub.status.idle":"2023-07-03T08:01:58.596317Z","shell.execute_reply":"2023-07-03T08:01:58.59539Z"},"papermill":{"duration":0.154221,"end_time":"2023-07-03T08:01:58.598564","exception":false,"start_time":"2023-07-03T08:01:58.444343","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":101,"id":"9a262511","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:01:58.8475Z","iopub.status.busy":"2023-07-03T08:01:58.847103Z","iopub.status.idle":"2023-07-03T08:02:21.015003Z","shell.execute_reply":"2023-07-03T08:02:21.013633Z"},"papermill":{"duration":22.294687,"end_time":"2023-07-03T08:02:21.017054","exception":false,"start_time":"2023-07-03T08:01:58.722367","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_meta: : 137it [00:22,  6.19it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values), desc=\"defog_meta: \"):\n","    path = root_data + f\"train/notype/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 1])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":102,"id":"6bcd9f34","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:21.266842Z","iopub.status.busy":"2023-07-03T08:02:21.266473Z","iopub.status.idle":"2023-07-03T08:02:28.926602Z","shell.execute_reply":"2023-07-03T08:02:28.925588Z"},"papermill":{"duration":7.787373,"end_time":"2023-07-03T08:02:28.929146","exception":false,"start_time":"2023-07-03T08:02:21.141773","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":103,"id":"f871c434","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:31.438874Z","iopub.status.busy":"2023-07-03T08:02:31.438199Z","iopub.status.idle":"2023-07-03T08:02:31.480473Z","shell.execute_reply":"2023-07-03T08:02:31.479385Z"},"papermill":{"duration":0.369723,"end_time":"2023-07-03T08:02:31.48303","exception":false,"start_time":"2023-07-03T08:02:31.113307","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["46"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id[\"Id\"].nunique()"]},{"cell_type":"code","execution_count":104,"id":"e6efb776","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:31.851519Z","iopub.status.busy":"2023-07-03T08:02:31.850358Z","iopub.status.idle":"2023-07-03T08:02:31.859591Z","shell.execute_reply":"2023-07-03T08:02:31.858381Z"},"papermill":{"duration":0.137051,"end_time":"2023-07-03T08:02:31.862172","exception":false,"start_time":"2023-07-03T08:02:31.725121","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"52a50f5e","metadata":{"papermill":{"duration":0.124203,"end_time":"2023-07-03T08:02:32.118022","exception":false,"start_time":"2023-07-03T08:02:31.993819","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe074_notype_15000\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe074_notype_15000.ipynb\" style=\"text-decoration:none\">fe074_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":105,"id":"12d6be7e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:32.368296Z","iopub.status.busy":"2023-07-03T08:02:32.367106Z","iopub.status.idle":"2023-07-03T08:02:32.374146Z","shell.execute_reply":"2023-07-03T08:02:32.373274Z"},"papermill":{"duration":0.134618,"end_time":"2023-07-03T08:02:32.376513","exception":false,"start_time":"2023-07-03T08:02:32.241895","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"074_notype\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":106,"id":"45aa7e12","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:32.680056Z","iopub.status.busy":"2023-07-03T08:02:32.67971Z","iopub.status.idle":"2023-07-03T08:02:32.689528Z","shell.execute_reply":"2023-07-03T08:02:32.688179Z"},"papermill":{"duration":0.14069,"end_time":"2023-07-03T08:02:32.692516","exception":false,"start_time":"2023-07-03T08:02:32.551826","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":107,"id":"b4cc4f7b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:32.954572Z","iopub.status.busy":"2023-07-03T08:02:32.954225Z","iopub.status.idle":"2023-07-03T08:02:32.95939Z","shell.execute_reply":"2023-07-03T08:02:32.958491Z"},"papermill":{"duration":0.13533,"end_time":"2023-07-03T08:02:32.961597","exception":false,"start_time":"2023-07-03T08:02:32.826267","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","target_cols = [\"Event\"]\n","seq_len = 15000\n","shift = 7500\n","offset = 3750"]},{"cell_type":"code","execution_count":108,"id":"c34f6255","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:33.212482Z","iopub.status.busy":"2023-07-03T08:02:33.212105Z","iopub.status.idle":"2023-07-03T08:02:33.226006Z","shell.execute_reply":"2023-07-03T08:02:33.224684Z"},"papermill":{"duration":0.141934,"end_time":"2023-07-03T08:02:33.228313","exception":false,"start_time":"2023-07-03T08:02:33.086379","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = []\n","target_array = []\n","valid_array = []\n","mask_array = []\n","pred_use_array = []\n","time_array = []\n","\n","subject_list = []\n","id_list = []\n","d_list = []"]},{"cell_type":"code","execution_count":109,"id":"0eb6b314","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:33.475652Z","iopub.status.busy":"2023-07-03T08:02:33.475286Z","iopub.status.idle":"2023-07-03T08:02:49.099434Z","shell.execute_reply":"2023-07-03T08:02:49.098385Z"},"papermill":{"duration":15.751825,"end_time":"2023-07-03T08:02:49.102214","exception":false,"start_time":"2023-07-03T08:02:33.350389","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["defog_meta: : 137it [00:15,  8.78it/s]\n"]}],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n","\n","for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values), desc=\"defog_meta: \"):\n","    path = root_data + f\"train/notype/{i}.csv\"\n","    if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","    # if path in data_list:\n","        d_list.append(1)\n","        \n","        df = pd.read_csv(path)\n","        df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","        df[\"valid\"] = df[\"valid\"].astype(int)\n","        \n","        batch = (len(df)-1) // shift\n","        \n","        for c in cols:\n","            df[f\"{c}_lag_diff\"] = df[c].diff()\n","            df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        \n","        sc = StandardScaler()\n","        df[num_cols] = sc.fit_transform(df[num_cols].values)\n","        df[num_cols] = df[num_cols].fillna(0)\n","\n","        num = df[num_cols].values\n","        target = df[target_cols].values\n","        valid = df[\"valid\"].values\n","        time_values = df[\"Time\"].values\n","        \n","        num_array_ = np.zeros([batch,seq_len, 9])\n","        target_array_ = np.zeros([batch, seq_len, 1])\n","        valid_array_ = np.zeros([batch, seq_len], dtype=int)\n","        time_array_ = np.zeros([batch, seq_len], dtype=int)\n","        mask_array_ = np.zeros([batch, seq_len], dtype=int)\n","        pred_use_array_ = np.zeros([batch, seq_len], dtype=int)\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                num_array_[b,:len(num_), :] = num_\n","                target_ = target[b*shift : ]\n","                target_array_[b, :len(target_), :] = target_\n","                mask_array_[b, :len(target_)] = 1\n","                pred_use_array_[b, offset:len(target_)] = 1\n","                time_ = time_values[b*shift : ]\n","                time_array_[b, :len(time_)] = time_\n","                valid_ = valid[b*shift : ]\n","                valid_array_[b, :len(valid_)] = valid_\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, :shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                num_array_[b, :, :] = num_\n","                target_ = target[b*shift : b*shift + seq_len]\n","                target_array_[b, :, :] = target_\n","                mask_array_[b, :] = 1\n","                pred_use_array_[b, offset:shift + offset] = 1\n","                time_ = time_values[b*shift : b*shift + seq_len]\n","                time_array_[b, :] = time_\n","                valid_ = valid[b*shift : b*shift + seq_len]\n","                valid_array_[b, :] = valid_\n","\n","        num_array.append(num_array_)\n","        target_array.append(target_array_)\n","        mask_array.append(mask_array_)\n","        pred_use_array.append(pred_use_array_)\n","        time_array.append(time_array_)\n","        valid_array.append(valid_array_)\n","        subject_list += [s for _ in range(batch)]\n","        id_list      += [i for _ in range(batch)] \n","    else:\n","        d_list.append(0)"]},{"cell_type":"code","execution_count":110,"id":"181151da","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:49.35975Z","iopub.status.busy":"2023-07-03T08:02:49.359402Z","iopub.status.idle":"2023-07-03T08:02:56.133615Z","shell.execute_reply":"2023-07-03T08:02:56.132613Z"},"papermill":{"duration":6.903927,"end_time":"2023-07-03T08:02:56.136133","exception":false,"start_time":"2023-07-03T08:02:49.232206","status":"completed"},"tags":[]},"outputs":[],"source":["num_array = np.concatenate(num_array, axis=0)\n","target_array =np.concatenate(target_array, axis=0)\n","mask_array =  np.concatenate(mask_array, axis=0)\n","pred_use_array = np.concatenate(pred_use_array, axis=0)\n","time_array = np.concatenate(time_array, axis=0)\n","valid_array = np.concatenate(valid_array, axis=0)\n","\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_num_array.npy\", num_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array.npy\", target_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_mask_array.npy\", mask_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_time_array.npy\", time_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_pred_use_array.npy\", pred_use_array)\n","np.save(f\"./output/fe/fe{fe}/fe{fe}_valid_array.npy\", valid_array)"]},{"cell_type":"code","execution_count":111,"id":"7a019170","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:59.064529Z","iopub.status.busy":"2023-07-03T08:02:59.063951Z","iopub.status.idle":"2023-07-03T08:02:59.100616Z","shell.execute_reply":"2023-07-03T08:02:59.099778Z"},"papermill":{"duration":0.317667,"end_time":"2023-07-03T08:02:59.102675","exception":false,"start_time":"2023-07-03T08:02:58.785008","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["46"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["df_id = pd.DataFrame()\n","df_id[\"Id\"] = id_list\n","df_id[\"subject\"] = subject_list\n","\n","df_id[\"Id\"].nunique()"]},{"cell_type":"code","execution_count":112,"id":"b7d1681f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:59.376414Z","iopub.status.busy":"2023-07-03T08:02:59.376027Z","iopub.status.idle":"2023-07-03T08:02:59.384564Z","shell.execute_reply":"2023-07-03T08:02:59.383713Z"},"papermill":{"duration":0.152867,"end_time":"2023-07-03T08:02:59.387177","exception":false,"start_time":"2023-07-03T08:02:59.23431","status":"completed"},"tags":[]},"outputs":[],"source":["df_id.to_parquet(f\"./output/fe/fe{fe}/fe{fe}_id.parquet\")"]},{"cell_type":"markdown","id":"b8347b46","metadata":{"papermill":{"duration":0.137114,"end_time":"2023-07-03T08:02:59.661132","exception":false,"start_time":"2023-07-03T08:02:59.524018","status":"completed"},"tags":[]},"source":["<br>\n","\n","## **Helpers**\n","\n","<br>\n","\n","### def `set_seed()`"]},{"cell_type":"code","execution_count":113,"id":"7a0b16f6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:02:59.93376Z","iopub.status.busy":"2023-07-03T08:02:59.933311Z","iopub.status.idle":"2023-07-03T08:02:59.939251Z","shell.execute_reply":"2023-07-03T08:02:59.938353Z"},"papermill":{"duration":0.145281,"end_time":"2023-07-03T08:02:59.941517","exception":false,"start_time":"2023-07-03T08:02:59.796236","status":"completed"},"tags":[]},"outputs":[],"source":["def set_seed(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","id":"e3a86f94","metadata":{"papermill":{"duration":0.133788,"end_time":"2023-07-03T08:03:00.209676","exception":false,"start_time":"2023-07-03T08:03:00.075888","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `timer()`"]},{"cell_type":"code","execution_count":114,"id":"5d8f1d21","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:00.466524Z","iopub.status.busy":"2023-07-03T08:03:00.466155Z","iopub.status.idle":"2023-07-03T08:03:00.471311Z","shell.execute_reply":"2023-07-03T08:03:00.470293Z"},"papermill":{"duration":0.138634,"end_time":"2023-07-03T08:03:00.473275","exception":false,"start_time":"2023-07-03T08:03:00.334641","status":"completed"},"tags":[]},"outputs":[],"source":["@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    \n","    yield \n","    # LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(f'[{name}] done in {time.time() - t0:.0f} s')\n","    print(\"=\"*66)\n","    \n","# setup_logger(out_file=logger_path)"]},{"cell_type":"markdown","id":"916a5563","metadata":{"papermill":{"duration":0.128569,"end_time":"2023-07-03T08:03:00.728134","exception":false,"start_time":"2023-07-03T08:03:00.599565","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `preprocess()`"]},{"cell_type":"code","execution_count":115,"id":"4c690bf3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:00.985526Z","iopub.status.busy":"2023-07-03T08:03:00.985119Z","iopub.status.idle":"2023-07-03T08:03:00.99043Z","shell.execute_reply":"2023-07-03T08:03:00.989312Z"},"papermill":{"duration":0.137211,"end_time":"2023-07-03T08:03:00.992426","exception":false,"start_time":"2023-07-03T08:03:00.855215","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array, valid_array,):\n","    \n","    attention_mask = mask_array == 0\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'input_data_valid_array': valid_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"502b495e","metadata":{"papermill":{"duration":0.130709,"end_time":"2023-07-03T08:03:01.304293","exception":false,"start_time":"2023-07-03T08:03:01.173584","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `FogDataset()`"]},{"cell_type":"code","execution_count":116,"id":"7a94576a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:01.560015Z","iopub.status.busy":"2023-07-03T08:03:01.559637Z","iopub.status.idle":"2023-07-03T08:03:01.570961Z","shell.execute_reply":"2023-07-03T08:03:01.569647Z"},"papermill":{"duration":0.142923,"end_time":"2023-07-03T08:03:01.573714","exception":false,"start_time":"2023-07-03T08:03:01.430791","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, valid_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.valid_array = valid_array\n","        self.train = train\n","        self.y = y\n","    \n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","    \n","    \n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item], self.valid_array[item],)\n","\n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'],  dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),   \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\": torch.tensor(self.y[item], dtype=torch.float32)\n","            }\n","        else:\n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n","              'input_data_valid_array': torch.tensor(data['input_data_valid_array'], dtype=torch.long),  \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"ca1c2a7b","metadata":{"papermill":{"duration":0.132468,"end_time":"2023-07-03T08:03:01.832511","exception":false,"start_time":"2023-07-03T08:03:01.700043","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `FogRnnModel()`"]},{"cell_type":"code","execution_count":117,"id":"7a1b4c11","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:02.095941Z","iopub.status.busy":"2023-07-03T08:03:02.095141Z","iopub.status.idle":"2023-07-03T08:03:02.109534Z","shell.execute_reply":"2023-07-03T08:03:02.108283Z"},"papermill":{"duration":0.152109,"end_time":"2023-07-03T08:03:02.111872","exception":false,"start_time":"2023-07-03T08:03:01.959763","status":"completed"},"tags":[]},"outputs":[],"source":["class FogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(FogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"9a5d344b","metadata":{"papermill":{"duration":0.141035,"end_time":"2023-07-03T08:03:02.398277","exception":false,"start_time":"2023-07-03T08:03:02.257242","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## <font color=blue>**ROUND 1**</font>\n","\n","<br>\n","<br>\n","\n","\n","## <font color=red>**Predicting**</font>: **Making** <font color=red>**pseudo**</font> **label** (round1: use models of ex153 & ex154)\n","\n","<br>\n","\n","### config"]},{"cell_type":"code","execution_count":118,"id":"d8086e2b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:02.662646Z","iopub.status.busy":"2023-07-03T08:03:02.662224Z","iopub.status.idle":"2023-07-03T08:03:02.668051Z","shell.execute_reply":"2023-07-03T08:03:02.666997Z"},"papermill":{"duration":0.141228,"end_time":"2023-07-03T08:03:02.670118","exception":false,"start_time":"2023-07-03T08:03:02.52889","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 15\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"8cc50b97","metadata":{"papermill":{"duration":0.134435,"end_time":"2023-07-03T08:03:02.936057","exception":false,"start_time":"2023-07-03T08:03:02.801622","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex153_defog_gru_inference_notype_10000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex153_defog_gru_inference_notype_10000.ipynb\" style=\"text-decoration:none\">ex153_defog_gru_inference_notype_10000.ipynb</a>"]},{"cell_type":"code","execution_count":119,"id":"d7dd3849","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:03.196837Z","iopub.status.busy":"2023-07-03T08:03:03.196471Z","iopub.status.idle":"2023-07-03T08:03:03.20226Z","shell.execute_reply":"2023-07-03T08:03:03.201355Z"},"papermill":{"duration":0.138859,"end_time":"2023-07-03T08:03:03.204166","exception":false,"start_time":"2023-07-03T08:03:03.065307","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"74c0d0a7","metadata":{"papermill":{"duration":0.128029,"end_time":"2023-07-03T08:03:03.458253","exception":false,"start_time":"2023-07-03T08:03:03.330224","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data"]},{"cell_type":"code","execution_count":120,"id":"012e1d11","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:03.719198Z","iopub.status.busy":"2023-07-03T08:03:03.718851Z","iopub.status.idle":"2023-07-03T08:03:16.194767Z","shell.execute_reply":"2023-07-03T08:03:16.190643Z"},"papermill":{"duration":12.613751,"end_time":"2023-07-03T08:03:16.19875","exception":false,"start_time":"2023-07-03T08:03:03.584999","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 10000\n","\n","id_path        = f\"./output/fe/fe064_notype/fe064_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe064_notype/fe064_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe064_notype/fe064_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe064_notype/fe064_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe064_notype/fe064_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe064_notype/fe064_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe064_notype/fe064_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"41e4b3e4","metadata":{"papermill":{"duration":0.126301,"end_time":"2023-07-03T08:03:16.454371","exception":false,"start_time":"2023-07-03T08:03:16.32807","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":121,"id":"4f76ff0e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:16.711692Z","iopub.status.busy":"2023-07-03T08:03:16.711341Z","iopub.status.idle":"2023-07-03T08:03:16.718118Z","shell.execute_reply":"2023-07-03T08:03:16.717187Z"},"papermill":{"duration":0.137951,"end_time":"2023-07-03T08:03:16.720119","exception":false,"start_time":"2023-07-03T08:03:16.582168","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":121,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":122,"id":"7ec42e81","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:16.980499Z","iopub.status.busy":"2023-07-03T08:03:16.980101Z","iopub.status.idle":"2023-07-03T08:03:16.99056Z","shell.execute_reply":"2023-07-03T08:03:16.98969Z"},"papermill":{"duration":0.143179,"end_time":"2023-07-03T08:03:16.992426","exception":false,"start_time":"2023-07-03T08:03:16.849247","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            model = FogRnnModel()\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, 10000, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)"]},{"cell_type":"code","execution_count":123,"id":"ac30b799","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:17.307679Z","iopub.status.busy":"2023-07-03T08:03:17.30676Z","iopub.status.idle":"2023-07-03T08:03:17.3152Z","shell.execute_reply":"2023-07-03T08:03:17.314286Z"},"papermill":{"duration":0.142385,"end_time":"2023-07-03T08:03:17.317161","exception":false,"start_time":"2023-07-03T08:03:17.174776","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")"]},{"cell_type":"markdown","id":"6c8bd697","metadata":{"papermill":{"duration":0.129851,"end_time":"2023-07-03T08:03:17.58601","exception":false,"start_time":"2023-07-03T08:03:17.456159","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex153_defog_gru_inference_notype_15000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex153_defog_gru_inference_notype_15000.ipynb\" style=\"text-decoration:none\">ex153_defog_gru_inference_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":124,"id":"5535bf29","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:17.845925Z","iopub.status.busy":"2023-07-03T08:03:17.845569Z","iopub.status.idle":"2023-07-03T08:03:17.850907Z","shell.execute_reply":"2023-07-03T08:03:17.849923Z"},"papermill":{"duration":0.137882,"end_time":"2023-07-03T08:03:17.852921","exception":false,"start_time":"2023-07-03T08:03:17.715039","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"8b8511dc","metadata":{"papermill":{"duration":0.12743,"end_time":"2023-07-03T08:03:18.106723","exception":false,"start_time":"2023-07-03T08:03:17.979293","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data"]},{"cell_type":"code","execution_count":125,"id":"cdbf0796","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:18.373682Z","iopub.status.busy":"2023-07-03T08:03:18.373269Z","iopub.status.idle":"2023-07-03T08:03:29.575121Z","shell.execute_reply":"2023-07-03T08:03:29.574103Z"},"papermill":{"duration":11.337707,"end_time":"2023-07-03T08:03:29.577956","exception":false,"start_time":"2023-07-03T08:03:18.240249","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 15000\n","\n","id_path        = f\"./output/fe/fe074_notype/fe074_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe074_notype/fe074_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe074_notype/fe074_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe074_notype/fe074_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe074_notype/fe074_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe074_notype/fe074_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe074_notype/fe074_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"ba08deb4","metadata":{"papermill":{"duration":0.127442,"end_time":"2023-07-03T08:03:29.83438","exception":false,"start_time":"2023-07-03T08:03:29.706938","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":126,"id":"df4d0a6c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:30.091997Z","iopub.status.busy":"2023-07-03T08:03:30.091Z","iopub.status.idle":"2023-07-03T08:03:30.099163Z","shell.execute_reply":"2023-07-03T08:03:30.098288Z"},"papermill":{"duration":0.138835,"end_time":"2023-07-03T08:03:30.101146","exception":false,"start_time":"2023-07-03T08:03:29.962311","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":127,"id":"1f19a414","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:30.35746Z","iopub.status.busy":"2023-07-03T08:03:30.357086Z","iopub.status.idle":"2023-07-03T08:03:30.367398Z","shell.execute_reply":"2023-07-03T08:03:30.366362Z"},"papermill":{"duration":0.140522,"end_time":"2023-07-03T08:03:30.369243","exception":false,"start_time":"2023-07-03T08:03:30.228721","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            model = FogRnnModel()\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, seq_len, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)"]},{"cell_type":"code","execution_count":128,"id":"17dbf28e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:30.626583Z","iopub.status.busy":"2023-07-03T08:03:30.625621Z","iopub.status.idle":"2023-07-03T08:03:30.634258Z","shell.execute_reply":"2023-07-03T08:03:30.633379Z"},"papermill":{"duration":0.13864,"end_time":"2023-07-03T08:03:30.636434","exception":false,"start_time":"2023-07-03T08:03:30.497794","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")"]},{"cell_type":"markdown","id":"672fdb75","metadata":{"papermill":{"duration":0.132659,"end_time":"2023-07-03T08:03:30.899815","exception":false,"start_time":"2023-07-03T08:03:30.767156","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex154_defog_gru_inference_notype_15000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex154_defog_gru_inference_notype_15000.ipynb\" style=\"text-decoration:none\">ex154_defog_gru_inference_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":129,"id":"479a5111","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:31.161103Z","iopub.status.busy":"2023-07-03T08:03:31.160754Z","iopub.status.idle":"2023-07-03T08:03:31.165886Z","shell.execute_reply":"2023-07-03T08:03:31.164964Z"},"papermill":{"duration":0.138124,"end_time":"2023-07-03T08:03:31.16792","exception":false,"start_time":"2023-07-03T08:03:31.029796","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"154_defog\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"1da4053f","metadata":{"papermill":{"duration":0.128859,"end_time":"2023-07-03T08:03:31.429865","exception":false,"start_time":"2023-07-03T08:03:31.301006","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data"]},{"cell_type":"code","execution_count":130,"id":"2ab94ab9","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:31.686417Z","iopub.status.busy":"2023-07-03T08:03:31.68542Z","iopub.status.idle":"2023-07-03T08:03:41.322632Z","shell.execute_reply":"2023-07-03T08:03:41.321628Z"},"papermill":{"duration":9.768324,"end_time":"2023-07-03T08:03:41.325107","exception":false,"start_time":"2023-07-03T08:03:31.556783","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 15000\n","\n","id_path        = f\"./output/fe/fe074_notype/fe074_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe074_notype/fe074_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe074_notype/fe074_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe074_notype/fe074_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe074_notype/fe074_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe074_notype/fe074_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe074_notype/fe074_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"2099dd2b","metadata":{"papermill":{"duration":0.126472,"end_time":"2023-07-03T08:03:41.623281","exception":false,"start_time":"2023-07-03T08:03:41.496809","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":131,"id":"56af2b14","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:41.883935Z","iopub.status.busy":"2023-07-03T08:03:41.883572Z","iopub.status.idle":"2023-07-03T08:03:41.893644Z","shell.execute_reply":"2023-07-03T08:03:41.892761Z"},"papermill":{"duration":0.142191,"end_time":"2023-07-03T08:03:41.895734","exception":false,"start_time":"2023-07-03T08:03:41.753543","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":132,"id":"fae4842d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:42.153095Z","iopub.status.busy":"2023-07-03T08:03:42.152753Z","iopub.status.idle":"2023-07-03T08:03:42.163584Z","shell.execute_reply":"2023-07-03T08:03:42.162518Z"},"papermill":{"duration":0.141758,"end_time":"2023-07-03T08:03:42.166172","exception":false,"start_time":"2023-07-03T08:03:42.024414","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            # model = FogRnnModel()\n","            model = FogRnnModel(numeraical_linear_size = 96,\n","                                model_size = 256,\n","                                linear_out = 256,)\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, seq_len, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)"]},{"cell_type":"code","execution_count":133,"id":"ccc9d925","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:42.4235Z","iopub.status.busy":"2023-07-03T08:03:42.421929Z","iopub.status.idle":"2023-07-03T08:03:42.4304Z","shell.execute_reply":"2023-07-03T08:03:42.429533Z"},"papermill":{"duration":0.138308,"end_time":"2023-07-03T08:03:42.432408","exception":false,"start_time":"2023-07-03T08:03:42.2941","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")"]},{"cell_type":"markdown","id":"79e6d040","metadata":{"papermill":{"duration":0.127922,"end_time":"2023-07-03T08:03:42.687196","exception":false,"start_time":"2023-07-03T08:03:42.559274","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## **Feature Engineering with** <font color=red>**pseudo**</font>  **label**\n","\n","<br>\n","\n","### fe073_notype_pseudo_ex153_10000.ipynb\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe073_notype_pseudo_ex153_10000.ipynb\" style=\"text-decoration:none\">fe073_notype_pseudo_ex153_10000.ipynb</a>"]},{"cell_type":"code","execution_count":134,"id":"83a25c27","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:42.945783Z","iopub.status.busy":"2023-07-03T08:03:42.94542Z","iopub.status.idle":"2023-07-03T08:03:42.950806Z","shell.execute_reply":"2023-07-03T08:03:42.949775Z"},"papermill":{"duration":0.13822,"end_time":"2023-07-03T08:03:42.952961","exception":false,"start_time":"2023-07-03T08:03:42.814741","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"073_notype_pseudo\"\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":135,"id":"aa4acc8d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:43.211048Z","iopub.status.busy":"2023-07-03T08:03:43.210715Z","iopub.status.idle":"2023-07-03T08:03:43.220655Z","shell.execute_reply":"2023-07-03T08:03:43.219762Z"},"papermill":{"duration":0.141665,"end_time":"2023-07-03T08:03:43.222667","exception":false,"start_time":"2023-07-03T08:03:43.081002","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":136,"id":"d546994e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:43.481392Z","iopub.status.busy":"2023-07-03T08:03:43.481039Z","iopub.status.idle":"2023-07-03T08:03:43.487616Z","shell.execute_reply":"2023-07-03T08:03:43.486783Z"},"papermill":{"duration":0.136458,"end_time":"2023-07-03T08:03:43.489629","exception":false,"start_time":"2023-07-03T08:03:43.353171","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":137,"id":"3b52692e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:43.744688Z","iopub.status.busy":"2023-07-03T08:03:43.74431Z","iopub.status.idle":"2023-07-03T08:03:43.75897Z","shell.execute_reply":"2023-07-03T08:03:43.75815Z"},"papermill":{"duration":0.145684,"end_time":"2023-07-03T08:03:43.761075","exception":false,"start_time":"2023-07-03T08:03:43.615391","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_10000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"code","execution_count":138,"id":"174a0b01","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:44.026768Z","iopub.status.busy":"2023-07-03T08:03:44.026102Z","iopub.status.idle":"2023-07-03T08:03:44.03084Z","shell.execute_reply":"2023-07-03T08:03:44.029984Z"},"papermill":{"duration":0.13753,"end_time":"2023-07-03T08:03:44.032732","exception":false,"start_time":"2023-07-03T08:03:43.895202","status":"completed"},"tags":[]},"outputs":[],"source":["# df"]},{"cell_type":"code","execution_count":139,"id":"88d41707","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:44.299762Z","iopub.status.busy":"2023-07-03T08:03:44.299403Z","iopub.status.idle":"2023-07-03T08:03:44.304005Z","shell.execute_reply":"2023-07-03T08:03:44.302772Z"},"papermill":{"duration":0.136681,"end_time":"2023-07-03T08:03:44.305988","exception":false,"start_time":"2023-07-03T08:03:44.169307","status":"completed"},"tags":[]},"outputs":[],"source":["# pred"]},{"cell_type":"markdown","id":"58ef095e","metadata":{"papermill":{"duration":0.128013,"end_time":"2023-07-03T08:03:44.604286","exception":false,"start_time":"2023-07-03T08:03:44.476273","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe075_notype_pseudo_ex153_15000.ipynb\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe075_notype_pseudo_ex153_15000.ipynb\" style=\"text-decoration:none\">fe075_notype_pseudo_ex153_15000.ipynb</a>"]},{"cell_type":"code","execution_count":140,"id":"272a2f9c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:44.86322Z","iopub.status.busy":"2023-07-03T08:03:44.862237Z","iopub.status.idle":"2023-07-03T08:03:44.867821Z","shell.execute_reply":"2023-07-03T08:03:44.866871Z"},"papermill":{"duration":0.135919,"end_time":"2023-07-03T08:03:44.86973","exception":false,"start_time":"2023-07-03T08:03:44.733811","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"075_notype_pseudo\"\n","ex = \"153_defog\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":141,"id":"5ada88c2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:45.177869Z","iopub.status.busy":"2023-07-03T08:03:45.177168Z","iopub.status.idle":"2023-07-03T08:03:45.186242Z","shell.execute_reply":"2023-07-03T08:03:45.185368Z"},"papermill":{"duration":0.142372,"end_time":"2023-07-03T08:03:45.188299","exception":false,"start_time":"2023-07-03T08:03:45.045927","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":142,"id":"519d476e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:45.464413Z","iopub.status.busy":"2023-07-03T08:03:45.463228Z","iopub.status.idle":"2023-07-03T08:03:45.46986Z","shell.execute_reply":"2023-07-03T08:03:45.468972Z"},"papermill":{"duration":0.148264,"end_time":"2023-07-03T08:03:45.471875","exception":false,"start_time":"2023-07-03T08:03:45.323611","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":143,"id":"7ed7724b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:45.731448Z","iopub.status.busy":"2023-07-03T08:03:45.731072Z","iopub.status.idle":"2023-07-03T08:03:45.744598Z","shell.execute_reply":"2023-07-03T08:03:45.743731Z"},"papermill":{"duration":0.146888,"end_time":"2023-07-03T08:03:45.746521","exception":false,"start_time":"2023-07-03T08:03:45.599633","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_15000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"code","execution_count":144,"id":"beb498c3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:46.004956Z","iopub.status.busy":"2023-07-03T08:03:46.003997Z","iopub.status.idle":"2023-07-03T08:03:46.008608Z","shell.execute_reply":"2023-07-03T08:03:46.007729Z"},"papermill":{"duration":0.136714,"end_time":"2023-07-03T08:03:46.010556","exception":false,"start_time":"2023-07-03T08:03:45.873842","status":"completed"},"tags":[]},"outputs":[],"source":["# df"]},{"cell_type":"code","execution_count":145,"id":"0a988a76","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:46.266047Z","iopub.status.busy":"2023-07-03T08:03:46.26511Z","iopub.status.idle":"2023-07-03T08:03:46.26947Z","shell.execute_reply":"2023-07-03T08:03:46.268499Z"},"papermill":{"duration":0.134218,"end_time":"2023-07-03T08:03:46.271418","exception":false,"start_time":"2023-07-03T08:03:46.1372","status":"completed"},"tags":[]},"outputs":[],"source":["# pred"]},{"cell_type":"markdown","id":"83339d52","metadata":{"papermill":{"duration":0.129487,"end_time":"2023-07-03T08:03:46.528154","exception":false,"start_time":"2023-07-03T08:03:46.398667","status":"completed"},"tags":[]},"source":["<br>\n","\n","### fe086_notype_pseudo_ex154_15000.ipynb\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe086_notype_pseudo_ex154_15000.ipynb\" style=\"text-decoration:none\">fe086_notype_pseudo_ex154_15000.ipynb</a>"]},{"cell_type":"code","execution_count":146,"id":"126b2199","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:46.790866Z","iopub.status.busy":"2023-07-03T08:03:46.790494Z","iopub.status.idle":"2023-07-03T08:03:46.796071Z","shell.execute_reply":"2023-07-03T08:03:46.795144Z"},"papermill":{"duration":0.13759,"end_time":"2023-07-03T08:03:46.797993","exception":false,"start_time":"2023-07-03T08:03:46.660403","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"086_notype_pseudo\"\n","ex = \"154_defog\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":147,"id":"22fc2fda","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:47.06071Z","iopub.status.busy":"2023-07-03T08:03:47.060345Z","iopub.status.idle":"2023-07-03T08:03:47.069804Z","shell.execute_reply":"2023-07-03T08:03:47.068868Z"},"papermill":{"duration":0.145561,"end_time":"2023-07-03T08:03:47.071977","exception":false,"start_time":"2023-07-03T08:03:46.926416","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":148,"id":"3bad4522","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:47.341554Z","iopub.status.busy":"2023-07-03T08:03:47.341177Z","iopub.status.idle":"2023-07-03T08:03:47.347092Z","shell.execute_reply":"2023-07-03T08:03:47.346149Z"},"papermill":{"duration":0.138487,"end_time":"2023-07-03T08:03:47.349317","exception":false,"start_time":"2023-07-03T08:03:47.21083","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":149,"id":"c4e13a19","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:47.619252Z","iopub.status.busy":"2023-07-03T08:03:47.61888Z","iopub.status.idle":"2023-07-03T08:03:47.633609Z","shell.execute_reply":"2023-07-03T08:03:47.632642Z"},"papermill":{"duration":0.147074,"end_time":"2023-07-03T08:03:47.635762","exception":false,"start_time":"2023-07-03T08:03:47.488688","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_15000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"code","execution_count":150,"id":"600d8735","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:47.892697Z","iopub.status.busy":"2023-07-03T08:03:47.892323Z","iopub.status.idle":"2023-07-03T08:03:47.896686Z","shell.execute_reply":"2023-07-03T08:03:47.895714Z"},"papermill":{"duration":0.133916,"end_time":"2023-07-03T08:03:47.898693","exception":false,"start_time":"2023-07-03T08:03:47.764777","status":"completed"},"tags":[]},"outputs":[],"source":["# df"]},{"cell_type":"code","execution_count":151,"id":"6e86be0c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:48.15839Z","iopub.status.busy":"2023-07-03T08:03:48.157412Z","iopub.status.idle":"2023-07-03T08:03:48.16207Z","shell.execute_reply":"2023-07-03T08:03:48.161199Z"},"papermill":{"duration":0.135398,"end_time":"2023-07-03T08:03:48.164001","exception":false,"start_time":"2023-07-03T08:03:48.028603","status":"completed"},"tags":[]},"outputs":[],"source":["# pred"]},{"cell_type":"markdown","id":"52aef741","metadata":{"papermill":{"duration":0.127116,"end_time":"2023-07-03T08:03:48.417335","exception":false,"start_time":"2023-07-03T08:03:48.290219","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","##  <font color=red>**Training**</font> **with** <font color=red>**pseudo**</font> **label** (round1)\n","\n","\n","\n","<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":152,"id":"e78d702c","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:03:48.716823Z","iopub.status.busy":"2023-07-03T08:03:48.716464Z","iopub.status.idle":"2023-07-03T08:04:03.107043Z","shell.execute_reply":"2023-07-03T08:04:03.10562Z"},"papermill":{"duration":14.523687,"end_time":"2023-07-03T08:04:03.111987","exception":false,"start_time":"2023-07-03T08:03:48.5883","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe047/fe047_id.parquet\"\n","numerical_path = f\"./output/fe/fe047/fe047_num_array.npy\"\n","target_path    = f\"./output/fe/fe047/fe047_target_array.npy\"\n","mask_path      = f\"./output/fe/fe047/fe047_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe047/fe047_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe047/fe047_pred_use_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)"]},{"cell_type":"code","execution_count":153,"id":"46e1f227","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:03.376938Z","iopub.status.busy":"2023-07-03T08:04:03.376589Z","iopub.status.idle":"2023-07-03T08:04:03.619456Z","shell.execute_reply":"2023-07-03T08:04:03.618477Z"},"papermill":{"duration":0.378271,"end_time":"2023-07-03T08:04:03.621505","exception":false,"start_time":"2023-07-03T08:04:03.243234","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    4107\n","2     897\n","3     354\n","1      11\n","Name: group, dtype: int64"]},"execution_count":153,"metadata":{},"output_type":"execute_result"}],"source":["target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i,:,0]))\n","    target2.append(np.sum(target_array[i,:,1]))\n","    target3.append(np.sum(target_array[i,:,2]))\n","\n","df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)\n","\n","df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3\n","\n","df_id[\"group\"].value_counts()"]},{"cell_type":"code","execution_count":154,"id":"e747c277","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:03.87988Z","iopub.status.busy":"2023-07-03T08:04:03.879509Z","iopub.status.idle":"2023-07-03T08:04:14.203238Z","shell.execute_reply":"2023-07-03T08:04:14.202009Z"},"papermill":{"duration":10.454796,"end_time":"2023-07-03T08:04:14.206491","exception":false,"start_time":"2023-07-03T08:04:03.751695","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_id_path        = f\"./output/fe/fe061_notype/fe061_notype_id.parquet\"\n","pseudo_numerical_path = f\"./output/fe/fe061_notype/fe061_notype_num_array.npy\"\n","pseudo_mask_path      = f\"./output/fe/fe061_notype/fe061_notype_mask_array.npy\"\n","pseudo_valid_path     = f\"./output/fe/fe061_notype/fe061_notype_valid_array.npy\"\n","pseudo_pred_use_path  = f\"./output/fe/fe061_notype/fe061_notype_pred_use_array.npy\"\n","\n","pseudo_numerical_array = np.load(pseudo_numerical_path)\n","pseudo_mask_array      = np.load(pseudo_mask_path)\n","pseudo_valid_array     = np.load(pseudo_valid_path)\n","pseudo_pred_use_array  = np.load(pseudo_pred_use_path)"]},{"cell_type":"markdown","id":"1ae4aa16","metadata":{"papermill":{"duration":0.149246,"end_time":"2023-07-03T08:04:14.510564","exception":false,"start_time":"2023-07-03T08:04:14.361318","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":155,"id":"a3c0bc0e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:14.768908Z","iopub.status.busy":"2023-07-03T08:04:14.768551Z","iopub.status.idle":"2023-07-03T08:04:14.785789Z","shell.execute_reply":"2023-07-03T08:04:14.784721Z"},"papermill":{"duration":0.150239,"end_time":"2023-07-03T08:04:14.788204","exception":false,"start_time":"2023-07-03T08:04:14.637965","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 10\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"86fc403c","metadata":{"papermill":{"duration":0.128907,"end_time":"2023-07-03T08:04:15.045175","exception":false,"start_time":"2023-07-03T08:04:14.916268","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex175_defog_gru_pseudo.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex175_defog_gru_pseudo.ipynb\" style=\"text-decoration:none\">ex175_defog_gru_pseudo.ipynb</a>"]},{"cell_type":"code","execution_count":156,"id":"2ed1fd35","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:15.309558Z","iopub.status.busy":"2023-07-03T08:04:15.309108Z","iopub.status.idle":"2023-07-03T08:04:15.315309Z","shell.execute_reply":"2023-07-03T08:04:15.314384Z"},"papermill":{"duration":0.13824,"end_time":"2023-07-03T08:04:15.317436","exception":false,"start_time":"2023-07-03T08:04:15.179196","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"175_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":157,"id":"10e273f8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:15.600203Z","iopub.status.busy":"2023-07-03T08:04:15.599291Z","iopub.status.idle":"2023-07-03T08:04:15.604213Z","shell.execute_reply":"2023-07-03T08:04:15.6033Z"},"papermill":{"duration":0.143285,"end_time":"2023-07-03T08:04:15.606449","exception":false,"start_time":"2023-07-03T08:04:15.463164","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_target = \"073_notype_pseudo\""]},{"cell_type":"markdown","id":"ae466cb3","metadata":{"papermill":{"duration":0.128212,"end_time":"2023-07-03T08:04:15.864116","exception":false,"start_time":"2023-07-03T08:04:15.735904","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":158,"id":"1b8ef019","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:16.126255Z","iopub.status.busy":"2023-07-03T08:04:16.12539Z","iopub.status.idle":"2023-07-03T08:04:16.160287Z","shell.execute_reply":"2023-07-03T08:04:16.159179Z"},"papermill":{"duration":0.170004,"end_time":"2023-07-03T08:04:16.162417","exception":false,"start_time":"2023-07-03T08:04:15.992413","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 0 ns, sys: 5 µs, total: 5 µs\n","Wall time: 9.06 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"d8fdb639","metadata":{"papermill":{"duration":0.128484,"end_time":"2023-07-03T08:04:16.418343","exception":false,"start_time":"2023-07-03T08:04:16.289859","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":159,"id":"0abd93de","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:16.678292Z","iopub.status.busy":"2023-07-03T08:04:16.67794Z","iopub.status.idle":"2023-07-03T08:04:16.684501Z","shell.execute_reply":"2023-07-03T08:04:16.683551Z"},"papermill":{"duration":0.139745,"end_time":"2023-07-03T08:04:16.68676","exception":false,"start_time":"2023-07-03T08:04:16.547015","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"2539712f","metadata":{"papermill":{"duration":0.130039,"end_time":"2023-07-03T08:04:16.944638","exception":false,"start_time":"2023-07-03T08:04:16.814599","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex179_defog_gru_pseudo.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex179_defog_gru_pseudo.ipynb\" style=\"text-decoration:none\">ex179_defog_gru_pseudo.ipynb</a>"]},{"cell_type":"code","execution_count":160,"id":"e54d5195","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:17.260872Z","iopub.status.busy":"2023-07-03T08:04:17.260511Z","iopub.status.idle":"2023-07-03T08:04:17.266071Z","shell.execute_reply":"2023-07-03T08:04:17.265129Z"},"papermill":{"duration":0.139015,"end_time":"2023-07-03T08:04:17.268041","exception":false,"start_time":"2023-07-03T08:04:17.129026","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"179_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":161,"id":"a5bbd62f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:17.540511Z","iopub.status.busy":"2023-07-03T08:04:17.539529Z","iopub.status.idle":"2023-07-03T08:04:17.544365Z","shell.execute_reply":"2023-07-03T08:04:17.543297Z"},"papermill":{"duration":0.141954,"end_time":"2023-07-03T08:04:17.546377","exception":false,"start_time":"2023-07-03T08:04:17.404423","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 5000\n","\n","pseudo_target = \"075_notype_pseudo\""]},{"cell_type":"markdown","id":"3e004d50","metadata":{"papermill":{"duration":0.129229,"end_time":"2023-07-03T08:04:17.803378","exception":false,"start_time":"2023-07-03T08:04:17.674149","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":162,"id":"6921b3f0","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:18.064474Z","iopub.status.busy":"2023-07-03T08:04:18.064093Z","iopub.status.idle":"2023-07-03T08:04:18.090155Z","shell.execute_reply":"2023-07-03T08:04:18.088885Z"},"papermill":{"duration":0.160459,"end_time":"2023-07-03T08:04:18.092231","exception":false,"start_time":"2023-07-03T08:04:17.931772","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n","Wall time: 8.82 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), seq_len, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, seq_len, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"55b7474b","metadata":{"papermill":{"duration":0.126764,"end_time":"2023-07-03T08:04:18.34718","exception":false,"start_time":"2023-07-03T08:04:18.220416","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":163,"id":"0cbb7565","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:18.604514Z","iopub.status.busy":"2023-07-03T08:04:18.60327Z","iopub.status.idle":"2023-07-03T08:04:18.611791Z","shell.execute_reply":"2023-07-03T08:04:18.610522Z"},"papermill":{"duration":0.140613,"end_time":"2023-07-03T08:04:18.613826","exception":false,"start_time":"2023-07-03T08:04:18.473213","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"ea48e6f7","metadata":{"papermill":{"duration":0.129276,"end_time":"2023-07-03T08:04:18.874757","exception":false,"start_time":"2023-07-03T08:04:18.745481","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex204_defog_gru_pseudo.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex204_defog_gru_pseudo.ipynb\" style=\"text-decoration:none\">ex204_defog_gru_pseudo.ipynb</a>"]},{"cell_type":"code","execution_count":164,"id":"1117e221","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:19.139448Z","iopub.status.busy":"2023-07-03T08:04:19.139067Z","iopub.status.idle":"2023-07-03T08:04:19.144322Z","shell.execute_reply":"2023-07-03T08:04:19.14339Z"},"papermill":{"duration":0.143013,"end_time":"2023-07-03T08:04:19.146304","exception":false,"start_time":"2023-07-03T08:04:19.003291","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"204_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":165,"id":"4d0b6eb4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:19.400843Z","iopub.status.busy":"2023-07-03T08:04:19.400529Z","iopub.status.idle":"2023-07-03T08:04:19.404739Z","shell.execute_reply":"2023-07-03T08:04:19.403778Z"},"papermill":{"duration":0.133955,"end_time":"2023-07-03T08:04:19.406852","exception":false,"start_time":"2023-07-03T08:04:19.272897","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_target = \"086_notype_pseudo\""]},{"cell_type":"markdown","id":"a9e282dc","metadata":{"papermill":{"duration":0.127097,"end_time":"2023-07-03T08:04:19.65988","exception":false,"start_time":"2023-07-03T08:04:19.532783","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":166,"id":"5ccb1156","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:19.91622Z","iopub.status.busy":"2023-07-03T08:04:19.915837Z","iopub.status.idle":"2023-07-03T08:04:19.94617Z","shell.execute_reply":"2023-07-03T08:04:19.94529Z"},"papermill":{"duration":0.162601,"end_time":"2023-07-03T08:04:19.948407","exception":false,"start_time":"2023-07-03T08:04:19.785806","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 8.34 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), 5000, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            # model = FogRnnModel()\n","            model = FogRnnModel(numeraical_linear_size = 96,\n","                                model_size = 256,\n","                                linear_out = 256,)            \n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, 5000, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"2e1ba4ec","metadata":{"papermill":{"duration":0.126367,"end_time":"2023-07-03T08:04:20.20711","exception":false,"start_time":"2023-07-03T08:04:20.080743","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":167,"id":"6886f739","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:20.465043Z","iopub.status.busy":"2023-07-03T08:04:20.464202Z","iopub.status.idle":"2023-07-03T08:04:20.471271Z","shell.execute_reply":"2023-07-03T08:04:20.470393Z"},"papermill":{"duration":0.13743,"end_time":"2023-07-03T08:04:20.473248","exception":false,"start_time":"2023-07-03T08:04:20.335818","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"56398d4f","metadata":{"papermill":{"duration":0.126948,"end_time":"2023-07-03T08:04:20.771047","exception":false,"start_time":"2023-07-03T08:04:20.644099","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## <font color=blue>**ROUND 2**</font>\n","\n","<br>\n","<br>\n","\n","## <font color=red>**Predicting**</font>: **Making** <font color=red>**pseudo**</font> **label** (round2: use models of ex175 in round 1)\n","\n","\n","<br>\n","\n","### <font color=maroon>ex175_defog_gru_inference_notype_15000.ipynbb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex175_defog_gru_inference_notype_15000.ipynb\" style=\"text-decoration:none\">ex175_defog_gru_inference_notype_15000.ipynb</a>"]},{"cell_type":"code","execution_count":168,"id":"9e1bdf69","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:21.026583Z","iopub.status.busy":"2023-07-03T08:04:21.02622Z","iopub.status.idle":"2023-07-03T08:04:21.031338Z","shell.execute_reply":"2023-07-03T08:04:21.030356Z"},"papermill":{"duration":0.135206,"end_time":"2023-07-03T08:04:21.033204","exception":false,"start_time":"2023-07-03T08:04:20.897998","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"175_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"markdown","id":"8f237d62","metadata":{"papermill":{"duration":0.127254,"end_time":"2023-07-03T08:04:21.2921","exception":false,"start_time":"2023-07-03T08:04:21.164846","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### load data & preprocessing"]},{"cell_type":"code","execution_count":169,"id":"8498669d","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:21.552214Z","iopub.status.busy":"2023-07-03T08:04:21.551777Z","iopub.status.idle":"2023-07-03T08:04:34.36526Z","shell.execute_reply":"2023-07-03T08:04:34.360318Z"},"papermill":{"duration":12.951827,"end_time":"2023-07-03T08:04:34.371395","exception":false,"start_time":"2023-07-03T08:04:21.419568","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 15000\n","\n","id_path        = f\"./output/fe/fe074_notype/fe074_notype_id.parquet\"\n","numerical_path = f\"./output/fe/fe074_notype/fe074_notype_num_array.npy\"\n","target_path    = f\"./output/fe/fe074_notype/fe074_notype_target_array.npy\"\n","mask_path      = f\"./output/fe/fe074_notype/fe074_notype_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe074_notype/fe074_notype_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe074_notype/fe074_notype_pred_use_array.npy\"\n","time_path      = f\"./output/fe/fe074_notype/fe074_notype_time_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)\n","time_array      = np.load(time_path)"]},{"cell_type":"markdown","id":"a0031494","metadata":{"papermill":{"duration":0.126876,"end_time":"2023-07-03T08:04:34.645052","exception":false,"start_time":"2023-07-03T08:04:34.518176","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### config"]},{"cell_type":"code","execution_count":170,"id":"c2ea6225","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:34.901519Z","iopub.status.busy":"2023-07-03T08:04:34.901137Z","iopub.status.idle":"2023-07-03T08:04:34.909318Z","shell.execute_reply":"2023-07-03T08:04:34.908344Z"},"papermill":{"duration":0.13907,"end_time":"2023-07-03T08:04:34.911389","exception":false,"start_time":"2023-07-03T08:04:34.772319","status":"completed"},"tags":[]},"outputs":[],"source":["# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 15\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"99ff4919","metadata":{"papermill":{"duration":0.135252,"end_time":"2023-07-03T08:04:35.175615","exception":false,"start_time":"2023-07-03T08:04:35.040363","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main (predict)"]},{"cell_type":"code","execution_count":171,"id":"30eb0cf1","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:35.431252Z","iopub.status.busy":"2023-07-03T08:04:35.430306Z","iopub.status.idle":"2023-07-03T08:04:35.437886Z","shell.execute_reply":"2023-07-03T08:04:35.436888Z"},"papermill":{"duration":0.137717,"end_time":"2023-07-03T08:04:35.439882","exception":false,"start_time":"2023-07-03T08:04:35.302165","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":171,"metadata":{},"output_type":"execute_result"}],"source":["models_list = os.listdir(f\"./output/exp/ex{ex}/ex{ex}_model\")\n","models_list"]},{"cell_type":"code","execution_count":172,"id":"c45306f7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:35.697123Z","iopub.status.busy":"2023-07-03T08:04:35.696769Z","iopub.status.idle":"2023-07-03T08:04:35.707804Z","shell.execute_reply":"2023-07-03T08:04:35.706889Z"},"papermill":{"duration":0.142632,"end_time":"2023-07-03T08:04:35.709665","exception":false,"start_time":"2023-07-03T08:04:35.567033","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","# with timer(\"gru\"):\n","    set_seed(seed)\n","    for fold in range(1, 6):\n","        with timer(f\"fold {fold}\"):\n","            val_numerical_array = numerical_array.copy()\n","            val_target_array = target_array.copy()\n","            val_mask_array = mask_array.copy()\n","            val_valid_array = valid_array.copy()\n","            val_pred_array = pred_use_array.copy()\n","\n","            val_ = FogDataset(val_numerical_array, \n","                              val_mask_array,\n","                              val_valid_array, \n","                              train=True,\n","                              y=val_target_array)\n","\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False,\n","                                    # num_workers=8\n","                                   )\n","\n","            model = FogRnnModel()\n","            # model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n","            model.load_state_dict(torch.load(f\"./output/exp/ex{ex}/ex{ex}_model/\" + models_list[fold-1]))\n","            model = model.to(device)\n","            model.eval()  # switch model to the evaluation mode\n","            \n","            val_preds = np.ndarray((0, seq_len, 3))\n","            tk0 = tqdm(val_loader, total=len(val_loader))\n","            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                # Predicting on validation set\n","                for d in tk0:\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","            # np.save(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)\n","            np.save(f\"./output/exp/ex{ex}/ex{ex}_R2_{fold}_oof_{seq_len}.npy\",val_preds)            "]},{"cell_type":"code","execution_count":173,"id":"3c30c3a3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:35.966273Z","iopub.status.busy":"2023-07-03T08:04:35.965926Z","iopub.status.idle":"2023-07-03T08:04:35.974162Z","shell.execute_reply":"2023-07-03T08:04:35.973107Z"},"papermill":{"duration":0.138977,"end_time":"2023-07-03T08:04:35.976537","exception":false,"start_time":"2023-07-03T08:04:35.83756","status":"completed"},"tags":[]},"outputs":[],"source":["if PREDICT_FLAG:\n","    id_array = df_id[\"Id\"].values\n","    for i in range(1, 6):\n","        pred_all = []\n","        # pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n","        pred = np.load(f\"./output/exp/ex{ex}/ex{ex}_R2_{i}_oof_{seq_len}.npy\")\n","        for v in tqdm(range(len(pred_use_array))):\n","            use_ = pred_use_array[v, :] == 1\n","            pred_ = pred[v, use_ == 1, :]\n","            time_ = time_array[v, use_ == 1]\n","            Id = id_array[v]\n","            pred_df = pd.DataFrame()\n","            pred_df[\"Time\"] = time_\n","            pred_df[\"Id\"] = Id\n","            pred_df[\"StartHesitation\"] = pred_[:, 0]\n","            pred_df[\"Turn\"] = pred_[:, 1]\n","            pred_df[\"Walking\"] = pred_[:, 2]\n","            pred_all.append(pred_df)\n","        pred_all = pd.concat(pred_all).reset_index(drop=True)\n","        # pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")\n","        pred_all.to_parquet(f\"./output/exp/ex{ex}/ex{ex}_R2_{i}_pred_{seq_len}.parquet\")    "]},{"cell_type":"markdown","id":"59ed32b5","metadata":{"papermill":{"duration":0.133406,"end_time":"2023-07-03T08:04:36.239411","exception":false,"start_time":"2023-07-03T08:04:36.106005","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","## **Feature Engineering with** <font color=red>**pseudo**</font>  **label** \n","\n","<br>\n","\n","\n","### <font color=maroon>fe078_notype_pseudo_ex175_15000.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/fe/fe078_notype_pseudo_ex175_15000.ipynb\" style=\"text-decoration:none\">fe078_notype_pseudo_ex175_15000.ipynb</a>"]},{"cell_type":"code","execution_count":174,"id":"4efe54eb","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:36.499296Z","iopub.status.busy":"2023-07-03T08:04:36.498946Z","iopub.status.idle":"2023-07-03T08:04:36.504655Z","shell.execute_reply":"2023-07-03T08:04:36.503674Z"},"papermill":{"duration":0.137206,"end_time":"2023-07-03T08:04:36.506757","exception":false,"start_time":"2023-07-03T08:04:36.369551","status":"completed"},"tags":[]},"outputs":[],"source":["fe = \"078_notype_pseudo\"\n","ex = \"175_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/fe/fe{fe}\"):\n","    os.makedirs(f\"./output/fe/fe{fe}\")\n","    os.makedirs(f\"./output/fe/fe{fe}/save\")"]},{"cell_type":"code","execution_count":175,"id":"fb2435d6","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:36.769827Z","iopub.status.busy":"2023-07-03T08:04:36.769469Z","iopub.status.idle":"2023-07-03T08:04:36.797113Z","shell.execute_reply":"2023-07-03T08:04:36.796147Z"},"papermill":{"duration":0.160905,"end_time":"2023-07-03T08:04:36.799788","exception":false,"start_time":"2023-07-03T08:04:36.638883","status":"completed"},"tags":[]},"outputs":[],"source":["# DEFOG_META_PATH = \"../data/defog_metadata.csv\"\n","# DEFOG_FOLDER = \"../data/train/notype/*.csv\"\n","\n","defog_meta = pd.read_parquet(\"./output/fe/fe039/fe039_defog_meta.parquet\")"]},{"cell_type":"code","execution_count":176,"id":"055b7c44","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:37.113409Z","iopub.status.busy":"2023-07-03T08:04:37.113025Z","iopub.status.idle":"2023-07-03T08:04:37.118881Z","shell.execute_reply":"2023-07-03T08:04:37.117924Z"},"papermill":{"duration":0.142989,"end_time":"2023-07-03T08:04:37.121065","exception":false,"start_time":"2023-07-03T08:04:36.978076","status":"completed"},"tags":[]},"outputs":[],"source":["cols = [\"AccV\", \"AccML\", \"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff', 'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","target_use_cols = [\"Event\"]\n","target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n","seq_len = 5000\n","shift = 2500\n","offset = 1250"]},{"cell_type":"code","execution_count":177,"id":"7d51a326","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:37.383268Z","iopub.status.busy":"2023-07-03T08:04:37.382913Z","iopub.status.idle":"2023-07-03T08:04:37.397586Z","shell.execute_reply":"2023-07-03T08:04:37.396763Z"},"papermill":{"duration":0.145188,"end_time":"2023-07-03T08:04:37.399563","exception":false,"start_time":"2023-07-03T08:04:37.254375","status":"completed"},"tags":[]},"outputs":[],"source":["# data_list = glob.glob(DEFOG_FOLDER)\n","if TRAIN_FLAG:\n","    for fold in range(1, 6):\n","        print(fold)\n","        # pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_notype_{fold}_pred_15000.parquet\")\n","        pred = pd.read_parquet(f\"./output/exp/ex{ex}/ex{ex}_R2_{fold}_pred_15000.parquet\")\n","        target_array = []\n","        for i,s in tqdm(zip(defog_meta[\"Id\"].values, defog_meta[\"sub_id\"].values)):\n","            path = root_data + f\"train/notype/{i}.csv\"\n","            if path in [x.replace(\"\\\\\", \"/\") for x in train_notype]:\n","            # if path in data_list:\n","                df = pd.read_csv(path)\n","                df_ = pred[pred[\"Id\"] == i].reset_index(drop=True)\n","                df = df.merge(df_, how=\"left\", on=\"Time\")\n","                df[\"target_max\"] = np.argmax(df[[\"StartHesitation\", \"Turn\", \"Walking\"]].values, axis=1)\n","\n","                df.loc[df[\"target_max\"] == 0, \"StartHesitation\"] = 1\n","                df.loc[df[\"target_max\"] == 0, [\"Turn\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 1, \"Turn\"] = 1\n","                df.loc[df[\"target_max\"] == 1, [\"StartHesitation\",\"Walking\"]] = 0\n","\n","                df.loc[df[\"target_max\"] == 2, \"Walking\"] = 1\n","                df.loc[df[\"target_max\"] == 2, [\"StartHesitation\",\"Turn\"]] = 0\n","\n","                df.loc[df[\"Event\"] == 0, [\"StartHesitation\", \"Turn\", \"Walking\"]] = 0\n","\n","                df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n","                df[\"valid\"] = df[\"valid\"].astype(int)\n","                batch = (len(df)-1) // shift\n","                target = df[target_cols].values\n","                target_array_ = np.zeros([batch, seq_len, 3])\n","                for n,b in enumerate(range(batch)):\n","                    if b == (batch - 1):\n","                        target_ = target[b*shift : ]\n","                        target_array_[b, :len(target_), :] = target_\n","                    elif b == 0:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","                    else:\n","                        target_ = target[b*shift : b*shift + seq_len]\n","                        target_array_[b, :, :] = target_\n","\n","                target_array.append(target_array_)\n","        target_array = np.concatenate(target_array, axis=0)\n","        np.save(f\"./output/fe/fe{fe}/fe{fe}_target_array_{fold}.npy\", target_array)"]},{"cell_type":"markdown","id":"85dcee3b","metadata":{"papermill":{"duration":0.129277,"end_time":"2023-07-03T08:04:37.657161","exception":false,"start_time":"2023-07-03T08:04:37.527884","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","##  <font color=red>**Training**</font> **with** <font color=red>**pseudo**</font> **label** (round2)\n","\n","<br>\n","\n","### load data & preprocessing"]},{"cell_type":"code","execution_count":178,"id":"0c512c73","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:37.915726Z","iopub.status.busy":"2023-07-03T08:04:37.915318Z","iopub.status.idle":"2023-07-03T08:04:52.351149Z","shell.execute_reply":"2023-07-03T08:04:52.350042Z"},"papermill":{"duration":14.56854,"end_time":"2023-07-03T08:04:52.354557","exception":false,"start_time":"2023-07-03T08:04:37.786017","status":"completed"},"tags":[]},"outputs":[],"source":["id_path        = f\"./output/fe/fe047/fe047_id.parquet\"\n","numerical_path = f\"./output/fe/fe047/fe047_num_array.npy\"\n","target_path    = f\"./output/fe/fe047/fe047_target_array.npy\"\n","mask_path      = f\"./output/fe/fe047/fe047_mask_array.npy\"\n","valid_path     = f\"./output/fe/fe047/fe047_valid_array.npy\"\n","pred_use_path  = f\"./output/fe/fe047/fe047_pred_use_array.npy\"\n","\n","df_id           = pd.read_parquet(id_path)\n","numerical_array = np.load(numerical_path)\n","target_array    = np.load(target_path)\n","mask_array      = np.load(mask_path)\n","valid_array     = np.load(valid_path)\n","pred_use_array  = np.load(pred_use_path)"]},{"cell_type":"code","execution_count":179,"id":"7e70c780","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:52.622276Z","iopub.status.busy":"2023-07-03T08:04:52.621832Z","iopub.status.idle":"2023-07-03T08:04:52.88004Z","shell.execute_reply":"2023-07-03T08:04:52.879085Z"},"papermill":{"duration":0.396441,"end_time":"2023-07-03T08:04:52.882524","exception":false,"start_time":"2023-07-03T08:04:52.486083","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0    4107\n","2     897\n","3     354\n","1      11\n","Name: group, dtype: int64"]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["target1 = []\n","target2 = []\n","target3 = []\n","for i in range(len(target_array)):\n","    target1.append(np.sum(target_array[i,:,0]))\n","    target2.append(np.sum(target_array[i,:,1]))\n","    target3.append(np.sum(target_array[i,:,2]))\n","\n","df_id[\"target1\"] = target1\n","df_id[\"target2\"] = target2\n","df_id[\"target3\"] = target3\n","df_id[\"target1_1\"] = df_id[\"target1\"] > 0\n","df_id[\"target2_1\"] = df_id[\"target2\"] > 0\n","df_id[\"target3_1\"] = df_id[\"target3\"] > 0\n","df_id[\"target1_1\"] = df_id[\"target1_1\"].astype(np.int)\n","df_id[\"target2_1\"] = df_id[\"target2_1\"].astype(np.int)\n","df_id[\"target3_1\"] = df_id[\"target3_1\"].astype(np.int)\n","\n","df_id[\"group\"] = 0\n","df_id.loc[df_id[\"target1_1\"] > 0,\"group\"] = 1\n","df_id.loc[df_id[\"target2_1\"] > 0,\"group\"] = 2\n","df_id.loc[df_id[\"target3_1\"] > 0,\"group\"] = 3\n","\n","df_id[\"group\"].value_counts()"]},{"cell_type":"code","execution_count":180,"id":"7399b678","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:04:53.148008Z","iopub.status.busy":"2023-07-03T08:04:53.147634Z","iopub.status.idle":"2023-07-03T08:05:02.641986Z","shell.execute_reply":"2023-07-03T08:05:02.640963Z"},"papermill":{"duration":9.632054,"end_time":"2023-07-03T08:05:02.645063","exception":false,"start_time":"2023-07-03T08:04:53.013009","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_id_path        = f\"./output/fe/fe061_notype/fe061_notype_id.parquet\"\n","pseudo_numerical_path = f\"./output/fe/fe061_notype/fe061_notype_num_array.npy\"\n","pseudo_mask_path      = f\"./output/fe/fe061_notype/fe061_notype_mask_array.npy\"\n","pseudo_valid_path     = f\"./output/fe/fe061_notype/fe061_notype_valid_array.npy\"\n","pseudo_pred_use_path  = f\"./output/fe/fe061_notype/fe061_notype_pred_use_array.npy\"\n","\n","pseudo_numerical_array = np.load(pseudo_numerical_path)\n","pseudo_mask_array      = np.load(pseudo_mask_path)\n","pseudo_valid_array     = np.load(pseudo_valid_path)\n","pseudo_pred_use_array  = np.load(pseudo_pred_use_path)"]},{"cell_type":"markdown","id":"3acb478f","metadata":{"papermill":{"duration":0.179905,"end_time":"2023-07-03T08:05:03.013683","exception":false,"start_time":"2023-07-03T08:05:02.833778","status":"completed"},"tags":[]},"source":["<br>\n","\n","### config"]},{"cell_type":"code","execution_count":181,"id":"876b1fa8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:03.383177Z","iopub.status.busy":"2023-07-03T08:05:03.382781Z","iopub.status.idle":"2023-07-03T08:05:03.391782Z","shell.execute_reply":"2023-07-03T08:05:03.390939Z"},"papermill":{"duration":0.199713,"end_time":"2023-07-03T08:05:03.395453","exception":false,"start_time":"2023-07-03T08:05:03.19574","status":"completed"},"tags":[]},"outputs":[],"source":["seq_len = 5000\n","\n","# config\n","seed = 0\n","shuffle = True\n","n_splits = 5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model config\n","batch_size = 24\n","n_epochs = 10\n","lr = 1e-3\n","weight_decay = 0.05\n","num_warmup_steps = 10"]},{"cell_type":"markdown","id":"3701d7f1","metadata":{"papermill":{"duration":0.134229,"end_time":"2023-07-03T08:05:03.709892","exception":false,"start_time":"2023-07-03T08:05:03.575663","status":"completed"},"tags":[]},"source":["<br>\n","\n","### <font color=maroon>ex185_defog_gru_pseudo2.ipynb</font>\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://github.com/TakoiHirokazu/Kaggle-Parkinsons-Freezing-of-Gait-Prediction/blob/main/takoi/exp/ex185_defog_gru_pseudo2.ipynb\" style=\"text-decoration:none\">ex185_defog_gru_pseudo2.ipynb</a>"]},{"cell_type":"code","execution_count":182,"id":"4cbe5761","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:03.967142Z","iopub.status.busy":"2023-07-03T08:05:03.966214Z","iopub.status.idle":"2023-07-03T08:05:03.972012Z","shell.execute_reply":"2023-07-03T08:05:03.97094Z"},"papermill":{"duration":0.136626,"end_time":"2023-07-03T08:05:03.974163","exception":false,"start_time":"2023-07-03T08:05:03.837537","status":"completed"},"tags":[]},"outputs":[],"source":["debug = False\n","ex = \"185_notype_pseudo_target\"\n","if not os.path.exists(f\"./output/exp/ex{ex}\"):\n","    os.makedirs(f\"./output/exp/ex{ex}\")\n","    os.makedirs(f\"./output/exp/ex{ex}/ex{ex}_model\")"]},{"cell_type":"code","execution_count":183,"id":"96381c06","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:04.261767Z","iopub.status.busy":"2023-07-03T08:05:04.26141Z","iopub.status.idle":"2023-07-03T08:05:04.266252Z","shell.execute_reply":"2023-07-03T08:05:04.265348Z"},"papermill":{"duration":0.167553,"end_time":"2023-07-03T08:05:04.268176","exception":false,"start_time":"2023-07-03T08:05:04.100623","status":"completed"},"tags":[]},"outputs":[],"source":["pseudo_target = \"078_notype_pseudo\""]},{"cell_type":"markdown","id":"25b977e8","metadata":{"papermill":{"duration":0.137354,"end_time":"2023-07-03T08:05:04.578654","exception":false,"start_time":"2023-07-03T08:05:04.4413","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### main"]},{"cell_type":"code","execution_count":184,"id":"72f96899","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:04.835283Z","iopub.status.busy":"2023-07-03T08:05:04.834921Z","iopub.status.idle":"2023-07-03T08:05:04.867872Z","shell.execute_reply":"2023-07-03T08:05:04.866907Z"},"papermill":{"duration":0.163525,"end_time":"2023-07-03T08:05:04.870152","exception":false,"start_time":"2023-07-03T08:05:04.706627","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n","Wall time: 8.82 µs\n"]}],"source":["%%time\n","\n","# with timer(\"gru\"):\n","if TRAIN_FLAG:\n","    set_seed(seed)\n","    y_oof = np.empty([len(target_array), seq_len, 3])      # Abrachan: out of fold\n","    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state = seed)\n","    for fold, (train_idx, valid_idx) in enumerate(gkf.split(numerical_array, \n","                                                            y = df_id[\"group\"].values,\n","                                                            groups=df_id[\"subject\"].values)):\n","        # LOGGER.info(f\"start fold:{fold+1}\")\n","        print(f\"start fold: {fold+1}\")\n","        \n","        with timer(f\"fold {fold+1}\"):\n","            train_numerical_array = numerical_array[train_idx]\n","            train_target_array = target_array[train_idx]\n","            train_mask_array = mask_array[train_idx]\n","            train_valid_array = valid_array[train_idx]\n","            \n","            pseudo_target_array = np.load(f\"./output/fe/fe{pseudo_target}/fe{pseudo_target}_target_array_{fold+1}.npy\")\n","            train_numerical_array = np.concatenate([train_numerical_array, pseudo_numerical_array], axis=0)\n","            train_target_array = np.concatenate([train_target_array, pseudo_target_array], axis=0)\n","            train_mask_array = np.concatenate([train_mask_array, pseudo_mask_array], axis=0)\n","            train_valid_array = np.concatenate([train_valid_array, pseudo_valid_array], axis=0)\n","\n","            val_numerical_array = numerical_array[valid_idx]\n","            val_target_array = target_array[valid_idx]\n","            val_mask_array = mask_array[valid_idx]\n","            val_valid_array = valid_array[valid_idx]\n","            val_pred_array = pred_use_array[valid_idx]\n","            \n","            train_ = FogDataset(train_numerical_array,\n","                                train_mask_array,\n","                                train_valid_array,\n","                                train=True,\n","                                y=train_target_array)\n","            val_ = FogDataset(val_numerical_array,\n","                              val_mask_array,\n","                              val_valid_array,\n","                              train=True,\n","                              y=val_target_array)\n","            \n","            train_loader = DataLoader(dataset=train_, \n","                                      batch_size=batch_size, \n","                                      shuffle = True, \n","                                      # num_workers=8,\n","                                     )\n","            val_loader = DataLoader(dataset=val_, \n","                                    batch_size=batch_size, \n","                                    shuffle = False , \n","                                    # num_workers=8\n","                                   )\n","            \n","            \n","            model = FogRnnModel()\n","            model = model.to(device)\n","            \n","            param_optimizer = list(model.named_parameters())\n","            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","            optimizer_grouped_parameters = [\n","                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","                 'weight_decay': weight_decay\n","                },\n","                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","                 'weight_decay': 0.0\n","                }]\n","            optimizer = AdamW(optimizer_grouped_parameters,\n","                              lr=lr,\n","                              weight_decay=weight_decay,\n","                              )\n","            num_train_optimization_steps = int(len(train_loader) * n_epochs)\n","            scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                        num_warmup_steps=num_warmup_steps,\n","                                                        num_training_steps=num_train_optimization_steps)\n","            criterion = nn.BCEWithLogitsLoss()\n","            best_val_score = 0\n","            \n","            for epoch in range(n_epochs):\n","                model.train() \n","                train_losses_batch = []\n","                val_losses_batch = []\n","                epoch_loss = 0\n","                train_preds = np.ndarray((0,3))   # array([], shape=(0, 3), dtype=float64)\n","                \n","                tk0 = tqdm_nb(train_loader, total=len(train_loader), desc=\"train_loader: \")\n","                for d in tk0:\n","                    # ======================================================\n","                    # data loader\n","                    # ======================================================\n","                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                    input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                    input_data_valid_array     = d['input_data_valid_array'].to(device)\n","                    attention_mask             = d['attention_mask'].to(device)\n","                    y                          = d[\"y\"].to(device)\n","                    \n","                    optimizer.zero_grad()\n","                    output = model(input_data_numerical_array, \n","                                   input_data_mask_array,\n","                                   attention_mask)\n","                    loss = criterion(output[input_data_mask_array == 1], y[input_data_mask_array == 1])\n","                    \n","                    # output1 = output[:, :, [1,2]]\n","                    # output2 = output[:, :, 0]\n","                    # y1 = y[:, :, [1,2]]\n","                    # y2 = y[:, :, 0]\n","                    # loss1 = criterion(output1[input_data_mask_array == 1], y1[input_data_mask_array == 1])\n","                    # loss2 = criterion(output2[input_data_mask_array == 1], y2[input_data_mask_array == 1])\n","                    # loss = loss1*0.8 + loss2*0.2\n","                    \n","                    loss.backward()\n","                    optimizer.step()\n","                    scheduler.step()\n","                    train_losses_batch.append(loss.item())\n","                train_loss = np.mean(train_losses_batch)\n","                \n","                \n","                # ======================================================\n","                # eval\n","                # ======================================================\n","                model.eval()       # switch model to the evaluation mode\n","                \n","                val_preds = np.ndarray((0, seq_len, 3))\n","                tk0 = tqdm_nb(val_loader, total=len(val_loader), desc=\"val_loader  : \")\n","                with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","                    # Predicting on validation set\n","                    for d in tk0:\n","                        input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","                        input_data_mask_array      = d['input_data_mask_array'].to(device)\n","                        attention_mask             = d['attention_mask'].to(device)\n","                        \n","                        output = model(input_data_numerical_array, \n","                                       input_data_mask_array,\n","                                       attention_mask)\n","                        val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n","                \n","                pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n","                StartHesitation = average_precision_score(val_target_array[pred_valid_index][:, 0],\n","                                                          val_preds[pred_valid_index][:, 0])\n","                Turn = average_precision_score(val_target_array[pred_valid_index][:, 1],\n","                                               val_preds[pred_valid_index][:, 1])\n","                Walking = average_precision_score(val_target_array[pred_valid_index][:, 2],\n","                                                  val_preds[pred_valid_index][:, 2])\n","                # map_score = np.mean([StartHesitation, Turn, Walking])\n","                map_score = np.mean([Turn, Walking])\n","                \n","                # LOGGER.info(f\"fold: {fold+1} epoch: {epoch+1},train loss {train_loss} map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                print(f\"fold {fold+1} epoch {epoch+1}\\ntrain loss {train_loss} map:{map_score}\\nstart_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","                \n","                if map_score >= best_val_score:\n","                    print(\"save weight\")\n","                    best_val_score = map_score\n","                    best_val_preds = val_preds.copy()\n","                    torch.save(model.state_dict(), f\"./output/exp/ex{ex}/ex{ex}_model/ex{ex}_fold{fold+1}_epoch{epoch+1}__map{best_val_score:.6f}.pth\")\n","                print()\n","            y_oof[valid_idx] = best_val_preds\n","    \n","    np.save(f\"./output/exp/ex{ex}/ex{ex}_oof.npy\", y_oof)"]},{"cell_type":"markdown","id":"06466499","metadata":{"papermill":{"duration":0.129279,"end_time":"2023-07-03T08:05:05.172658","exception":false,"start_time":"2023-07-03T08:05:05.043379","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### oof score"]},{"cell_type":"code","execution_count":185,"id":"428a32fa","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:05.432702Z","iopub.status.busy":"2023-07-03T08:05:05.432339Z","iopub.status.idle":"2023-07-03T08:05:05.438959Z","shell.execute_reply":"2023-07-03T08:05:05.438003Z"},"papermill":{"duration":0.138397,"end_time":"2023-07-03T08:05:05.440906","exception":false,"start_time":"2023-07-03T08:05:05.302509","status":"completed"},"tags":[]},"outputs":[],"source":["if TRAIN_FLAG:\n","    val_pred_index = (mask_array == 1) & (pred_use_array == 1) & (valid_array == 1)\n","    StartHesitation = average_precision_score(target_array[val_pred_index][:,0], \n","                                              y_oof[val_pred_index][:,0])\n","    Turn            = average_precision_score(target_array[val_pred_index][:,1], \n","                                              y_oof[val_pred_index][:,1])\n","    Walking         = average_precision_score(target_array[val_pred_index][:,2],\n","                                              y_oof[val_pred_index][:,2])\n","\n","    map_score = np.mean([StartHesitation, Turn, Walking])\n","    # LOGGER.info(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")\n","    print(f\"cv map:{map_score} start_hesi:{StartHesitation} turn:{Turn} walking :{Walking}\")"]},{"cell_type":"markdown","id":"a401485a","metadata":{"papermill":{"duration":0.135203,"end_time":"2023-07-03T08:05:05.708467","exception":false,"start_time":"2023-07-03T08:05:05.573264","status":"completed"},"tags":[]},"source":["<br>\n","\n","## **models choosed**\n","\n","<br>\n","\n","<font color=maroon size=4>The following numbered models were used for the final submission:</font>\n","* <font color=maroon size=4>ex153</font>\n","* <font color=maroon size=4>ex179</font>\n","* <font color=maroon size=4>ex185</font>\n","* <font color=maroon size=4>ex204</font>"]},{"cell_type":"markdown","id":"aa83b21e","metadata":{"papermill":{"duration":0.136785,"end_time":"2023-07-03T08:05:05.980063","exception":false,"start_time":"2023-07-03T08:05:05.843278","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","<br>\n","\n","\n","# 【**Inference**】\n","\n","<br>\n","\n","Code below originates from: \n","* <a href=\"https://www.kaggle.com/code/takoihiraokazu/cv-ensemble-sub-0607-1\" style=\"text-decoration:none\">[cv]ensemble_sub_0607_1</a>"]},{"cell_type":"markdown","id":"2ace1087","metadata":{"papermill":{"duration":0.12952,"end_time":"2023-07-03T08:05:06.240164","exception":false,"start_time":"2023-07-03T08:05:06.110644","status":"completed"},"tags":[]},"source":["<br>\n","\n","## Config"]},{"cell_type":"code","execution_count":186,"id":"a10b6a47","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:06.50531Z","iopub.status.busy":"2023-07-03T08:05:06.504962Z","iopub.status.idle":"2023-07-03T08:05:06.509277Z","shell.execute_reply":"2023-07-03T08:05:06.50838Z"},"papermill":{"duration":0.136484,"end_time":"2023-07-03T08:05:06.511275","exception":false,"start_time":"2023-07-03T08:05:06.374791","status":"completed"},"tags":[]},"outputs":[],"source":["# SUB_PATH          = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv\"\n","# DEFOG_DATA_PATH   = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/defog/*.csv\"\n","# TDCSFOG_DATA_PATH = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog/*.csv\""]},{"cell_type":"code","execution_count":187,"id":"714b9c8f","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:06.773404Z","iopub.status.busy":"2023-07-03T08:05:06.773042Z","iopub.status.idle":"2023-07-03T08:05:06.777905Z","shell.execute_reply":"2023-07-03T08:05:06.776907Z"},"papermill":{"duration":0.137218,"end_time":"2023-07-03T08:05:06.7799","exception":false,"start_time":"2023-07-03T08:05:06.642682","status":"completed"},"tags":[]},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","bs = 32"]},{"cell_type":"code","execution_count":188,"id":"49427a56","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:07.043599Z","iopub.status.busy":"2023-07-03T08:05:07.043209Z","iopub.status.idle":"2023-07-03T08:05:07.047431Z","shell.execute_reply":"2023-07-03T08:05:07.046495Z"},"papermill":{"duration":0.141875,"end_time":"2023-07-03T08:05:07.049399","exception":false,"start_time":"2023-07-03T08:05:06.907524","status":"completed"},"tags":[]},"outputs":[],"source":["# sub = pd.read_csv(SUB_PATH)\n","\n","# # sub = pd.read_csv(root_data + 'sample_submission.csv')"]},{"cell_type":"code","execution_count":189,"id":"922ddbe7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:07.30978Z","iopub.status.busy":"2023-07-03T08:05:07.308901Z","iopub.status.idle":"2023-07-03T08:05:07.313842Z","shell.execute_reply":"2023-07-03T08:05:07.312973Z"},"papermill":{"duration":0.137651,"end_time":"2023-07-03T08:05:07.316035","exception":false,"start_time":"2023-07-03T08:05:07.178384","status":"completed"},"tags":[]},"outputs":[],"source":["df_all = []"]},{"cell_type":"markdown","id":"0db58d0d","metadata":{"papermill":{"duration":0.129602,"end_time":"2023-07-03T08:05:07.575202","exception":false,"start_time":"2023-07-03T08:05:07.4456","status":"completed"},"tags":[]},"source":["<br>\n","\n","## Helpers\n","\n","<br>\n","\n","### def `preprocess()`"]},{"cell_type":"code","execution_count":190,"id":"5a0b70ab","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:07.841597Z","iopub.status.busy":"2023-07-03T08:05:07.8405Z","iopub.status.idle":"2023-07-03T08:05:07.848486Z","shell.execute_reply":"2023-07-03T08:05:07.847533Z"},"papermill":{"duration":0.141629,"end_time":"2023-07-03T08:05:07.850665","exception":false,"start_time":"2023-07-03T08:05:07.709036","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess(numerical_array, mask_array):\n","    \n","    attention_mask = mask_array == 0\n","\n","    return {'input_data_numerical_array': numerical_array,\n","            'input_data_mask_array': mask_array,\n","            'attention_mask': attention_mask,\n","           }"]},{"cell_type":"markdown","id":"9e03aef5","metadata":{"papermill":{"duration":0.129361,"end_time":"2023-07-03T08:05:08.110943","exception":false,"start_time":"2023-07-03T08:05:07.981582","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `FogDataset()`"]},{"cell_type":"code","execution_count":191,"id":"e47fc119","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:08.373645Z","iopub.status.busy":"2023-07-03T08:05:08.373267Z","iopub.status.idle":"2023-07-03T08:05:08.384615Z","shell.execute_reply":"2023-07-03T08:05:08.383658Z"},"papermill":{"duration":0.146284,"end_time":"2023-07-03T08:05:08.386559","exception":false,"start_time":"2023-07-03T08:05:08.240275","status":"completed"},"tags":[]},"outputs":[],"source":["class FogDataset(Dataset):\n","    def __init__(self, numerical_array, mask_array, train = True, y = None):\n","        self.numerical_array = numerical_array\n","        self.mask_array = mask_array\n","        self.train = train\n","        self.y = y\n","    \n","    \n","    def __len__(self):\n","        return len(self.numerical_array)\n","    \n","    \n","    def __getitem__(self, item):\n","        data = preprocess(self.numerical_array[item], self.mask_array[item])\n","\n","        # Return the processed data where the lists are converted to `torch.tensor`s\n","        if self.train : \n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'],  dtype=torch.long),              \n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","              \"y\": torch.tensor(self.y[item], dtype=torch.float32)\n","            }\n","        else:\n","            return {\n","              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'], dtype=torch.float32),\n","              'input_data_mask_array': torch.tensor(data['input_data_mask_array'], dtype=torch.long),\n","              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n","               }"]},{"cell_type":"markdown","id":"3142d67a","metadata":{"papermill":{"duration":0.137639,"end_time":"2023-07-03T08:05:08.701941","exception":false,"start_time":"2023-07-03T08:05:08.564302","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `TdcsfogRnnModel()`"]},{"cell_type":"code","execution_count":192,"id":"b0ded0fc","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:09.020406Z","iopub.status.busy":"2023-07-03T08:05:09.020016Z","iopub.status.idle":"2023-07-03T08:05:09.033581Z","shell.execute_reply":"2023-07-03T08:05:09.032579Z"},"papermill":{"duration":0.164747,"end_time":"2023-07-03T08:05:09.035836","exception":false,"start_time":"2023-07-03T08:05:08.871089","status":"completed"},"tags":[]},"outputs":[],"source":["class TdcsfogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=12,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(TdcsfogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"ff1a09c2","metadata":{"papermill":{"duration":0.131332,"end_time":"2023-07-03T08:05:09.307616","exception":false,"start_time":"2023-07-03T08:05:09.176284","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `TdcsfogRnnModel2()`"]},{"cell_type":"code","execution_count":193,"id":"915855b4","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:09.590372Z","iopub.status.busy":"2023-07-03T08:05:09.589952Z","iopub.status.idle":"2023-07-03T08:05:09.603219Z","shell.execute_reply":"2023-07-03T08:05:09.602221Z"},"papermill":{"duration":0.162199,"end_time":"2023-07-03T08:05:09.605484","exception":false,"start_time":"2023-07-03T08:05:09.443285","status":"completed"},"tags":[]},"outputs":[],"source":["class TdcsfogRnnModel2(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=12,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(TdcsfogRnnModel2, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         # nn.Linear(linear_out, out_size)\n","                                         )\n","        self.out1 = nn.Linear(linear_out, out_size)\n","        self.out2 = nn.Linear(linear_out, out_size)\n","        \n","        \n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        # return output\n","        \n","        output1 = self.out1(output)\n","        output2 = self.out2(output)\n","        return output1, output2"]},{"cell_type":"markdown","id":"58435673","metadata":{"papermill":{"duration":0.13429,"end_time":"2023-07-03T08:05:09.881487","exception":false,"start_time":"2023-07-03T08:05:09.747197","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `DefogRnnModel()`"]},{"cell_type":"code","execution_count":194,"id":"6dd3261a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:10.145158Z","iopub.status.busy":"2023-07-03T08:05:10.144813Z","iopub.status.idle":"2023-07-03T08:05:10.155591Z","shell.execute_reply":"2023-07-03T08:05:10.154707Z"},"papermill":{"duration":0.144609,"end_time":"2023-07-03T08:05:10.157831","exception":false,"start_time":"2023-07-03T08:05:10.013222","status":"completed"},"tags":[]},"outputs":[],"source":["class DefogRnnModel(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(DefogRnnModel, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"79fe6cc4","metadata":{"papermill":{"duration":0.130038,"end_time":"2023-07-03T08:05:10.415826","exception":false,"start_time":"2023-07-03T08:05:10.285788","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `DefogRnnModel2()`"]},{"cell_type":"code","execution_count":195,"id":"32d7e4d7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:10.674626Z","iopub.status.busy":"2023-07-03T08:05:10.67426Z","iopub.status.idle":"2023-07-03T08:05:10.685945Z","shell.execute_reply":"2023-07-03T08:05:10.685042Z"},"papermill":{"duration":0.144342,"end_time":"2023-07-03T08:05:10.687906","exception":false,"start_time":"2023-07-03T08:05:10.543564","status":"completed"},"tags":[]},"outputs":[],"source":["class DefogRnnModel2(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 96,\n","                 model_size = 256,\n","                 linear_out = 256,\n","                 out_size=3):\n","        \n","        super(DefogRnnModel2, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.rnn = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'rnn' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"9625be5a","metadata":{"papermill":{"duration":0.127352,"end_time":"2023-07-03T08:05:10.94166","exception":false,"start_time":"2023-07-03T08:05:10.814308","status":"completed"},"tags":[]},"source":["<br>\n","\n","### class `Defog3Model()`"]},{"cell_type":"code","execution_count":196,"id":"57cfc254","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:11.202449Z","iopub.status.busy":"2023-07-03T08:05:11.202073Z","iopub.status.idle":"2023-07-03T08:05:11.213528Z","shell.execute_reply":"2023-07-03T08:05:11.212648Z"},"papermill":{"duration":0.143788,"end_time":"2023-07-03T08:05:11.215426","exception":false,"start_time":"2023-07-03T08:05:11.071638","status":"completed"},"tags":[]},"outputs":[],"source":["class Defog3Model(nn.Module):\n","    def __init__(self, \n","                 dropout=0.2,\n","                 input_numerical_size=9,\n","                 numeraical_linear_size = 64,\n","                 model_size = 128,\n","                 linear_out = 128,\n","                 out_size=3):\n","        \n","        super(Defog3Model, self).__init__()\n","        \n","        self.numerical_linear  = nn.Sequential(nn.Linear(input_numerical_size, numeraical_linear_size),\n","                                               nn.LayerNorm(numeraical_linear_size))\n","        \n","        self.lstm = nn.GRU(numeraical_linear_size, \n","                          model_size,\n","                          num_layers = 2, \n","                          batch_first=True,\n","                          bidirectional=True)\n","        \n","        self.linear_out  = nn.Sequential(nn.Linear(model_size*2, linear_out),\n","                                         nn.LayerNorm(linear_out),\n","                                         nn.ReLU(),\n","                                         nn.Dropout(dropout),\n","                                         nn.Linear(linear_out, out_size))\n","        self._reinitialize()\n","        \n","        \n","        \n","    def _reinitialize(self):\n","        \"\"\"Tensorflow/Keras-like initialization\"\"\"\n","        for name, p in self.named_parameters():\n","            if 'lstm' in name:\n","                if 'weight_ih' in name:\n","                    nn.init.xavier_uniform_(p.data)\n","                elif 'weight_hh' in name:\n","                    nn.init.orthogonal_(p.data)\n","                elif 'bias_ih' in name:\n","                    p.data.fill_(0)\n","                    # Set forget-gate bias to 1\n","                    n = p.size(0)\n","                    p.data[(n // 4):(n // 2)].fill_(1)\n","                elif 'bias_hh' in name:\n","                    p.data.fill_(0)\n","        \n","        \n","        \n","    def forward(self, numerical_array, mask_array, attention_mask):\n","        numerical_embedding = self.numerical_linear(numerical_array)\n","        output, _ = self.rnn(numerical_embedding)\n","        output = self.linear_out(output)\n","        return output"]},{"cell_type":"markdown","id":"ca20b96d","metadata":{"papermill":{"duration":0.126754,"end_time":"2023-07-03T08:05:11.472783","exception":false,"start_time":"2023-07-03T08:05:11.346029","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `make_pred()`"]},{"cell_type":"code","execution_count":197,"id":"31c186c8","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:11.731499Z","iopub.status.busy":"2023-07-03T08:05:11.730791Z","iopub.status.idle":"2023-07-03T08:05:11.737472Z","shell.execute_reply":"2023-07-03T08:05:11.736519Z"},"papermill":{"duration":0.14006,"end_time":"2023-07-03T08:05:11.739575","exception":false,"start_time":"2023-07-03T08:05:11.599515","status":"completed"},"tags":[]},"outputs":[],"source":["def make_pred(test_loader, model):\n","    test_preds = []\n","    # tk0 = tqdm(test_loader, total=len(test_loader), desc=\"test_loader: \")\n","    with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","        # Predicting on validation set\n","        # for d in tk0:\n","        for d in test_loader:\n","            input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","            input_data_mask_array      = d['input_data_mask_array'].to(device)\n","            attention_mask             = d['attention_mask'].to(device)\n","            output = model(input_data_numerical_array, \n","                           input_data_mask_array,\n","                           attention_mask)\n","            test_preds.append(output.sigmoid().cpu().numpy())\n","    test_preds = np.concatenate(test_preds, axis=0)\n","    return test_preds"]},{"cell_type":"markdown","id":"68250fec","metadata":{"papermill":{"duration":0.128205,"end_time":"2023-07-03T08:05:12.005779","exception":false,"start_time":"2023-07-03T08:05:11.877574","status":"completed"},"tags":[]},"source":["<br>\n","\n","### def `make_pred2()`"]},{"cell_type":"code","execution_count":198,"id":"0ca06cc3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:12.314197Z","iopub.status.busy":"2023-07-03T08:05:12.313559Z","iopub.status.idle":"2023-07-03T08:05:12.321005Z","shell.execute_reply":"2023-07-03T08:05:12.320116Z"},"papermill":{"duration":0.140232,"end_time":"2023-07-03T08:05:12.322976","exception":false,"start_time":"2023-07-03T08:05:12.182744","status":"completed"},"tags":[]},"outputs":[],"source":["def make_pred2(test_loader, model):\n","    test_preds = []\n","    # tk0 = tqdm(test_loader, total=len(test_loader), desc=\"test_loader: \")\n","    with torch.no_grad():  # Do not calculate gradient since we are only predicting\n","        # Predicting on validation set\n","        # for d in tk0:\n","        for d in test_loader:\n","            input_data_numerical_array = d['input_data_numerical_array'].to(device)\n","            input_data_mask_array      = d['input_data_mask_array'].to(device)\n","            attention_mask             = d['attention_mask'].to(device)\n","            \n","            output, _ = model(input_data_numerical_array, \n","                             input_data_mask_array,\n","                             attention_mask)\n","            test_preds.append(output.sigmoid().cpu().numpy())\n","    test_preds = np.concatenate(test_preds, axis=0)\n","    return test_preds"]},{"cell_type":"markdown","id":"644bf0b6","metadata":{"papermill":{"duration":0.12752,"end_time":"2023-07-03T08:05:12.576971","exception":false,"start_time":"2023-07-03T08:05:12.449451","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>tdcsfog models</font>\n","\n","### checkpoint paths"]},{"cell_type":"code","execution_count":199,"id":"d0c53cf2","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:12.834466Z","iopub.status.busy":"2023-07-03T08:05:12.834094Z","iopub.status.idle":"2023-07-03T08:05:12.838632Z","shell.execute_reply":"2023-07-03T08:05:12.83776Z"},"papermill":{"duration":0.135452,"end_time":"2023-07-03T08:05:12.840675","exception":false,"start_time":"2023-07-03T08:05:12.705223","status":"completed"},"tags":[]},"outputs":[],"source":["# tdcsfog_path1   = [f\"/kaggle/input/fog-ex143/ex143_{i}.pth\" for i in range(5)] # len 3000 cv TdcsfogRnnModel\n","# tdcsfog_path3_1 = [f\"/kaggle/input/fog-ex145/ex145_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel  \n","# tdcsfog_path3_2 = [f\"/kaggle/input/fog-ex146/ex146_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel \n","# tdcsfog_path3_3 = [f\"/kaggle/input/fog-ex147/ex147_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel\n","# tdcsfog_path4_1 = [f\"/kaggle/input/fog-ex182/ex182_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel  \n","# tdcsfog_path4_2 = [f\"/kaggle/input/fog-ex183/ex183_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel \n","# tdcsfog_path4_3 = [f\"/kaggle/input/fog-ex184/ex184_{i}.pth\" for i in range(5)] # len 3000 TdcsfogRnnModel"]},{"cell_type":"code","execution_count":200,"id":"bcdca373","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:13.10312Z","iopub.status.busy":"2023-07-03T08:05:13.102766Z","iopub.status.idle":"2023-07-03T08:05:13.127034Z","shell.execute_reply":"2023-07-03T08:05:13.126109Z"},"papermill":{"duration":0.160965,"end_time":"2023-07-03T08:05:13.129452","exception":false,"start_time":"2023-07-03T08:05:12.968487","status":"completed"},"tags":[]},"outputs":[],"source":["tdcsfog_path1     = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex143*\")\n","tdcsfog_path3_1   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex145*\")\n","tdcsfog_path3_2   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex146*\")\n","tdcsfog_path3_3   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex147*\")\n","tdcsfog_path4_1   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex182*\")\n","tdcsfog_path4_2   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex183*\")\n","tdcsfog_path4_3   = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex184*\")"]},{"cell_type":"markdown","id":"56995e92","metadata":{"papermill":{"duration":0.128833,"end_time":"2023-07-03T08:05:13.388251","exception":false,"start_time":"2023-07-03T08:05:13.259418","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex143** (tdcsfog1: 0.2)\n","\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":201,"id":"6a13983a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:13.64913Z","iopub.status.busy":"2023-07-03T08:05:13.648778Z","iopub.status.idle":"2023-07-03T08:05:20.532278Z","shell.execute_reply":"2023-07-03T08:05:20.531258Z"},"papermill":{"duration":7.020017,"end_time":"2023-07-03T08:05:20.534665","exception":false,"start_time":"2023-07-03T08:05:13.514648","status":"completed"},"tags":[]},"outputs":[],"source":["# TdcsfogRnnModel()\n","\n","tdcsfog_model_list1 = []\n","for i in tdcsfog_path1:  # ex143\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list1.append(model)"]},{"cell_type":"markdown","id":"902c2b4d","metadata":{"papermill":{"duration":0.131638,"end_time":"2023-07-03T08:05:20.796924","exception":false,"start_time":"2023-07-03T08:05:20.665286","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":202,"id":"92bf4ec4","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:05:21.055064Z","iopub.status.busy":"2023-07-03T08:05:21.05471Z","iopub.status.idle":"2023-07-03T08:05:21.537027Z","shell.execute_reply":"2023-07-03T08:05:21.536147Z"},"papermill":{"duration":0.617972,"end_time":"2023-07-03T08:05:21.543151","exception":false,"start_time":"2023-07-03T08:05:20.925179","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_tdcsfog: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 196 ms, sys: 30.8 ms, total: 226 ms\n","Wall time: 458 ms\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# tdcsfog1\n","# =========================\n","th_len = 5000\n","w = 0.20\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = ['AccV', 'AccML', 'AccAP', \n","            'AccV_lag_diff',  'AccV_lead_diff', 'AccV_cumsum', \n","            'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","            'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","\n","# tdcsfog_list = glob.glob(TDCSFOG_DATA_PATH)\n","# for p in tqdm(tdcsfog_list):\n","for p in tqdm(test_tdcsfog, desc=\"test_tdcsfog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    df = pd.read_csv(p)\n","    \n","    if len(df) > th_len:\n","        seq_len = 5000\n","        shift = 2500\n","        offset = 1250\n","    else:\n","        seq_len = 3000\n","        shift = 1500\n","        offset = 750\n","        \n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 12])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_ = num.copy()\n","        time_ = time.copy()\n","        num_len = len(num_)\n","\n","        num_array[b,:num_len,:] = num_\n","        time_array[b,:num_len] = time_\n","        mask_array[b,:num_len] = 1\n","        pred_use_array[b,:num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b, :num_len, :] = num_\n","                time_array[b,:num_len] = time_\n","                mask_array[b,:num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b, :shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,offset : shift+offset] = 1\n","            \n","            \n","\n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(tdcsfog_model_list1):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(tdcsfog_model_list1)\n","        else:\n","            pred += make_pred(test_loader,m) / len(tdcsfog_model_list1)\n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i, mask_ == 1, :]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:, 0] * w\n","        df_[\"Turn\"] = pred_[:, 1] * w\n","        df_[\"Walking\"] = pred_[:, 2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"f394314b","metadata":{"papermill":{"duration":0.12985,"end_time":"2023-07-03T08:05:21.806165","exception":false,"start_time":"2023-07-03T08:05:21.676315","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex145, ex146, ex147** (tdcsfog3: 0.4)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":203,"id":"6e2d3676","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:22.06546Z","iopub.status.busy":"2023-07-03T08:05:22.06439Z","iopub.status.idle":"2023-07-03T08:05:22.654662Z","shell.execute_reply":"2023-07-03T08:05:22.653693Z"},"papermill":{"duration":0.723235,"end_time":"2023-07-03T08:05:22.657085","exception":false,"start_time":"2023-07-03T08:05:21.93385","status":"completed"},"tags":[]},"outputs":[],"source":["# TdcsfogRnnModel()\n","\n","tdcsfog_model_list3_1 = []\n","for i in tdcsfog_path3_1:  # ex145\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list3_1.append(model)\n","\n","\n","tdcsfog_model_list3_2 = []\n","for i in tdcsfog_path3_2:  # ex146\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list3_2.append(model)\n","\n","\n","tdcsfog_model_list3_3 = []\n","for i in tdcsfog_path3_3:  # ex147\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list3_3.append(model)"]},{"cell_type":"markdown","id":"5de13970","metadata":{"papermill":{"duration":0.127401,"end_time":"2023-07-03T08:05:22.914919","exception":false,"start_time":"2023-07-03T08:05:22.787518","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":204,"id":"81708e4f","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:05:23.177762Z","iopub.status.busy":"2023-07-03T08:05:23.177412Z","iopub.status.idle":"2023-07-03T08:05:23.571105Z","shell.execute_reply":"2023-07-03T08:05:23.569892Z"},"papermill":{"duration":0.530368,"end_time":"2023-07-03T08:05:23.573243","exception":false,"start_time":"2023-07-03T08:05:23.042875","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_tdcsfog: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 367 ms, sys: 226 µs, total: 367 ms\n","Wall time: 368 ms\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# tdcsfog3\n","# =========================\n","th_len = 5000\n","w = 0.40\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = ['AccV', 'AccML', 'AccAP', \n","            'AccV_lag_diff',  'AccV_lead_diff', 'AccV_cumsum', \n","            'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","            'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","\n","# tdcsfog_list = glob.glob(TDCSFOG_DATA_PATH)\n","# for p in tqdm(tdcsfog_list):\n","for p in tqdm(test_tdcsfog, desc=\"test_tdcsfog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    df = pd.read_csv(p)\n","    \n","    if len(df) > th_len:\n","        seq_len = 5000\n","        shift = 2500\n","        offset = 1250\n","    else:\n","        seq_len = 3000\n","        shift = 1500\n","        offset = 750\n","        \n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 12])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_ = num.copy()\n","        time_ = time.copy()\n","        num_len = len(num_)\n","\n","        num_array[b,:num_len,:] = num_\n","        time_array[b,:num_len] = time_\n","        mask_array[b,:num_len] = 1\n","        pred_use_array[b,:num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b, :num_len, :] = num_\n","                time_array[b,:num_len] = time_\n","                mask_array[b,:num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b, :shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,offset : shift+offset] = 1\n","            \n","            \n","\n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(tdcsfog_model_list3_1):\n","        if n == 0:\n","            pred1 = make_pred(test_loader,m) / len(tdcsfog_model_list3_1)\n","        else:\n","            pred1 += make_pred(test_loader,m) / len(tdcsfog_model_list3_1)\n","    for n,m in enumerate(tdcsfog_model_list3_2):\n","        if n == 0:\n","            pred2 = make_pred(test_loader,m) / len(tdcsfog_model_list3_2)\n","        else:\n","            pred2 += make_pred(test_loader,m) / len(tdcsfog_model_list3_2)\n","    for n,m in enumerate(tdcsfog_model_list3_3):\n","        if n == 0:\n","            pred3 = make_pred(test_loader,m) / len(tdcsfog_model_list3_3)\n","        else:\n","            pred3 += make_pred(test_loader,m) / len(tdcsfog_model_list3_3)\n","    pred = pred1.copy()\n","    pred[:,:,1] = pred2[:,:,1]\n","    pred[:,:,2] = pred3[:,:,2]\n","    \n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i, mask_ == 1, :]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:, 0] * w\n","        df_[\"Turn\"] = pred_[:, 1] * w\n","        df_[\"Walking\"] = pred_[:, 2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"88b6282b","metadata":{"papermill":{"duration":0.133205,"end_time":"2023-07-03T08:05:23.837516","exception":false,"start_time":"2023-07-03T08:05:23.704311","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex182, ex183, ex184** (tdcsfog4: 0.4)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":205,"id":"5963d461","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:24.154291Z","iopub.status.busy":"2023-07-03T08:05:24.153933Z","iopub.status.idle":"2023-07-03T08:05:24.782074Z","shell.execute_reply":"2023-07-03T08:05:24.781101Z"},"papermill":{"duration":0.770808,"end_time":"2023-07-03T08:05:24.78466","exception":false,"start_time":"2023-07-03T08:05:24.013852","status":"completed"},"tags":[]},"outputs":[],"source":["# TdcsfogRnnModel()\n","\n","tdcsfog_model_list4_1 = []\n","for i in tdcsfog_path4_1:  # ex182\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list4_1.append(model)\n","\n","\n","tdcsfog_model_list4_2 = []\n","for i in tdcsfog_path4_2:  # ex183\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list4_2.append(model)\n","\n","\n","tdcsfog_model_list4_3 = []\n","for i in tdcsfog_path4_3:  # ex184\n","    model = TdcsfogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    tdcsfog_model_list4_3.append(model)"]},{"cell_type":"markdown","id":"b724e9e1","metadata":{"papermill":{"duration":0.127734,"end_time":"2023-07-03T08:05:25.042906","exception":false,"start_time":"2023-07-03T08:05:24.915172","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":206,"id":"3ecdbfd8","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:05:25.302876Z","iopub.status.busy":"2023-07-03T08:05:25.302502Z","iopub.status.idle":"2023-07-03T08:05:25.695508Z","shell.execute_reply":"2023-07-03T08:05:25.69438Z"},"papermill":{"duration":0.525471,"end_time":"2023-07-03T08:05:25.697759","exception":false,"start_time":"2023-07-03T08:05:25.172288","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_tdcsfog: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 365 ms, sys: 1.43 ms, total: 367 ms\n","Wall time: 367 ms\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# tdcsfog4\n","# =========================\n","th_len = 5000\n","w = 0.40\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = ['AccV', 'AccML', 'AccAP', \n","            'AccV_lag_diff',  'AccV_lead_diff', 'AccV_cumsum', \n","            'AccML_lag_diff', 'AccML_lead_diff', 'AccML_cumsum', \n","            'AccAP_lag_diff', 'AccAP_lead_diff', 'AccAP_cumsum']\n","\n","# tdcsfog_list = glob.glob(TDCSFOG_DATA_PATH)\n","# for p in tqdm(tdcsfog_list):\n","for p in tqdm(test_tdcsfog, desc=\"test_tdcsfog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    df = pd.read_csv(p)\n","    \n","    if len(df) > th_len:\n","        seq_len = 5000\n","        shift = 2500\n","        offset = 1250\n","    else:\n","        seq_len = 3000\n","        shift = 1500\n","        offset = 750\n","        \n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","        df[f\"{c}_cumsum\"] = df[c].cumsum()\n","    sc = RobustScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 12])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_ = num.copy()\n","        time_ = time.copy()\n","        num_len = len(num_)\n","\n","        num_array[b,:num_len,:] = num_\n","        time_array[b,:num_len] = time_\n","        mask_array[b,:num_len] = 1\n","        pred_use_array[b,:num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b, :num_len, :] = num_\n","                time_array[b,:num_len] = time_\n","                mask_array[b,:num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b, :shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,offset : shift+offset] = 1\n","            \n","            \n","\n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(tdcsfog_model_list4_1):\n","        if n == 0:\n","            pred1 = make_pred(test_loader,m) / len(tdcsfog_model_list4_1)\n","        else:\n","            pred1 += make_pred(test_loader,m) / len(tdcsfog_model_list4_1)\n","    for n,m in enumerate(tdcsfog_model_list4_2):\n","        if n == 0:\n","            pred2 = make_pred(test_loader,m) / len(tdcsfog_model_list4_2)\n","        else:\n","            pred2 += make_pred(test_loader,m) / len(tdcsfog_model_list4_2)\n","    for n,m in enumerate(tdcsfog_model_list4_3):\n","        if n == 0:\n","            pred3 = make_pred(test_loader,m) / len(tdcsfog_model_list4_3)\n","        else:\n","            pred3 += make_pred(test_loader,m) / len(tdcsfog_model_list4_3)\n","    pred = pred1.copy()\n","    pred[:,:,0] = pred1[:,:,0]*0.5 + pred2[:,:,0]*0.5\n","    pred[:,:,1] = pred1[:,:,1]*0.5 + pred3[:,:,1]*0.5\n","    pred[:,:,2] = pred2[:,:,2]*0.5 + pred3[:,:,2]*0.5\n","    \n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i, mask_ == 1, :]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:, 0] * w\n","        df_[\"Turn\"] = pred_[:, 1] * w\n","        df_[\"Walking\"] = pred_[:, 2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"d9164dbb","metadata":{"papermill":{"duration":0.129362,"end_time":"2023-07-03T08:05:25.967161","exception":false,"start_time":"2023-07-03T08:05:25.837799","status":"completed"},"tags":[]},"source":["<br>\n","\n","## <font color=red>defog models</font>\n","\n","### checkpoint paths"]},{"cell_type":"code","execution_count":207,"id":"83fc4b2e","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:26.228076Z","iopub.status.busy":"2023-07-03T08:05:26.227226Z","iopub.status.idle":"2023-07-03T08:05:26.232096Z","shell.execute_reply":"2023-07-03T08:05:26.231118Z"},"papermill":{"duration":0.137808,"end_time":"2023-07-03T08:05:26.234164","exception":false,"start_time":"2023-07-03T08:05:26.096356","status":"completed"},"tags":[]},"outputs":[],"source":["# defog_path2 = [f\"/kaggle/input/fog-ex153/ex153_{i}.pth\" for i in range(5)] # len 30000 defog1 \n","# defog_path4 = [f\"/kaggle/input/fog-ex179/ex179_{i}.pth\" for i in range(5)] # len 30000 defog1\n","# defog_path5 = [f\"/kaggle/input/fog-ex185/ex185_{i}.pth\" for i in range(5)] # len 30000 defog1\n","# defog_path6 = [f\"/kaggle/input/fog-ex204/ex204_{i}.pth\" for i in range(5)] # len 30000 defog2\n","\n","# defog_path7 = [f\"/kaggle/input/pd-exp238/fold{i}_best.pth\" for i in [0, 1, 2, 3, 4]]  # len 30000 Defog3Model"]},{"cell_type":"code","execution_count":208,"id":"c3e88e92","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:26.49693Z","iopub.status.busy":"2023-07-03T08:05:26.49657Z","iopub.status.idle":"2023-07-03T08:05:26.504213Z","shell.execute_reply":"2023-07-03T08:05:26.503381Z"},"papermill":{"duration":0.143862,"end_time":"2023-07-03T08:05:26.506306","exception":false,"start_time":"2023-07-03T08:05:26.362444","status":"completed"},"tags":[]},"outputs":[],"source":["defog_path2 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex153*\")\n","defog_path4 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex179*\")\n","defog_path5 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex185*\")\n","defog_path6 = glob.glob(\"/kaggle/input/parkinson-fog-prediction/ex204*\")\n","\n","# defog_path7 = glob.glob(\".\\\\output\\\\exp\\\\ex238_\\\\ex238_\\\\*\")"]},{"cell_type":"markdown","id":"885b370d","metadata":{"papermill":{"duration":0.130204,"end_time":"2023-07-03T08:05:26.765787","exception":false,"start_time":"2023-07-03T08:05:26.635583","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex153** (defog2: 0.35)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":209,"id":"868de7e7","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:27.031097Z","iopub.status.busy":"2023-07-03T08:05:27.030151Z","iopub.status.idle":"2023-07-03T08:05:27.231952Z","shell.execute_reply":"2023-07-03T08:05:27.230985Z"},"papermill":{"duration":0.338373,"end_time":"2023-07-03T08:05:27.234583","exception":false,"start_time":"2023-07-03T08:05:26.89621","status":"completed"},"tags":[]},"outputs":[],"source":["# DefogRnnModel()\n","\n","defog_model_list2 = []\n","for i in defog_path2:         # ex153\n","    model = DefogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list2.append(model)"]},{"cell_type":"markdown","id":"0dcb9ad2","metadata":{"papermill":{"duration":0.131736,"end_time":"2023-07-03T08:05:27.496245","exception":false,"start_time":"2023-07-03T08:05:27.364509","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":210,"id":"9ba7d614","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:27.762691Z","iopub.status.busy":"2023-07-03T08:05:27.76202Z","iopub.status.idle":"2023-07-03T08:05:27.76654Z","shell.execute_reply":"2023-07-03T08:05:27.76551Z"},"papermill":{"duration":0.138307,"end_time":"2023-07-03T08:05:27.768921","exception":false,"start_time":"2023-07-03T08:05:27.630614","status":"completed"},"tags":[]},"outputs":[],"source":["# for p in train_defog:\n","#     id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","#     print(id_values)"]},{"cell_type":"code","execution_count":211,"id":"caea1f4e","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:05:28.02825Z","iopub.status.busy":"2023-07-03T08:05:28.027887Z","iopub.status.idle":"2023-07-03T08:05:30.306411Z","shell.execute_reply":"2023-07-03T08:05:30.305399Z"},"papermill":{"duration":2.412703,"end_time":"2023-07-03T08:05:30.309144","exception":false,"start_time":"2023-07-03T08:05:27.896441","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 2.08 s, sys: 24.7 ms, total: 2.1 s\n","Wall time: 2.26 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# defog2\n","# =========================\n","th_len = 200000\n","w = 0.35\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list2):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list2)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list2)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"cb6ba596","metadata":{"papermill":{"duration":0.129907,"end_time":"2023-07-03T08:05:30.570507","exception":false,"start_time":"2023-07-03T08:05:30.4406","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex179** (defog4: 0.25)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":212,"id":"35b6a5de","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:30.833469Z","iopub.status.busy":"2023-07-03T08:05:30.833099Z","iopub.status.idle":"2023-07-03T08:05:31.025873Z","shell.execute_reply":"2023-07-03T08:05:31.024912Z"},"papermill":{"duration":0.327745,"end_time":"2023-07-03T08:05:31.028171","exception":false,"start_time":"2023-07-03T08:05:30.700426","status":"completed"},"tags":[]},"outputs":[],"source":["defog_model_list4 = []\n","for i in defog_path4:       # ex179\n","    model = DefogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list4.append(model)"]},{"cell_type":"markdown","id":"0eedb45e","metadata":{"papermill":{"duration":0.132938,"end_time":"2023-07-03T08:05:31.34518","exception":false,"start_time":"2023-07-03T08:05:31.212242","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":213,"id":"e24a1c66","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:05:31.609158Z","iopub.status.busy":"2023-07-03T08:05:31.608781Z","iopub.status.idle":"2023-07-03T08:05:33.700254Z","shell.execute_reply":"2023-07-03T08:05:33.69916Z"},"papermill":{"duration":2.225145,"end_time":"2023-07-03T08:05:33.703567","exception":false,"start_time":"2023-07-03T08:05:31.478422","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 2.07 s, sys: 4.07 ms, total: 2.07 s\n","Wall time: 2.07 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# defog4\n","# =========================\n","th_len = 200000\n","w = 0.25\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list4):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list4)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list4)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"b3452fa3","metadata":{"papermill":{"duration":0.128418,"end_time":"2023-07-03T08:05:33.963919","exception":false,"start_time":"2023-07-03T08:05:33.835501","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex185** (defog5: 0.25)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":214,"id":"a073376a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:34.347483Z","iopub.status.busy":"2023-07-03T08:05:34.347038Z","iopub.status.idle":"2023-07-03T08:05:34.767548Z","shell.execute_reply":"2023-07-03T08:05:34.766603Z"},"papermill":{"duration":0.637797,"end_time":"2023-07-03T08:05:34.770645","exception":false,"start_time":"2023-07-03T08:05:34.132848","status":"completed"},"tags":[]},"outputs":[],"source":["defog_model_list5 = []\n","for i in defog_path5:        # ex185\n","    model = DefogRnnModel()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list5.append(model)"]},{"cell_type":"markdown","id":"9c77cb15","metadata":{"papermill":{"duration":0.18718,"end_time":"2023-07-03T08:05:35.144798","exception":false,"start_time":"2023-07-03T08:05:34.957618","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":215,"id":"5331281e","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:05:35.502167Z","iopub.status.busy":"2023-07-03T08:05:35.501814Z","iopub.status.idle":"2023-07-03T08:05:37.607792Z","shell.execute_reply":"2023-07-03T08:05:37.606871Z"},"papermill":{"duration":2.28097,"end_time":"2023-07-03T08:05:37.609693","exception":false,"start_time":"2023-07-03T08:05:35.328723","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 2.07 s, sys: 7.34 ms, total: 2.08 s\n","Wall time: 2.08 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","# =========================\n","# defog5\n","# =========================\n","th_len = 200000\n","w = 0.25\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list5):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list5)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list5)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"b1607984","metadata":{"papermill":{"duration":0.131069,"end_time":"2023-07-03T08:05:37.874495","exception":false,"start_time":"2023-07-03T08:05:37.743426","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex204** (defog6: 0.10)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":216,"id":"a075af86","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:38.137942Z","iopub.status.busy":"2023-07-03T08:05:38.137567Z","iopub.status.idle":"2023-07-03T08:05:38.747362Z","shell.execute_reply":"2023-07-03T08:05:38.746384Z"},"papermill":{"duration":0.744318,"end_time":"2023-07-03T08:05:38.749686","exception":false,"start_time":"2023-07-03T08:05:38.005368","status":"completed"},"tags":[]},"outputs":[],"source":["# DefogRnnModel2()\n","\n","defog_model_list6 = []\n","for i in defog_path6:           # ex204\n","    model = DefogRnnModel2()\n","    model.load_state_dict(torch.load(i))\n","    model = model.to(device)\n","    model.eval()\n","    defog_model_list6.append(model)"]},{"cell_type":"markdown","id":"61c7f8c1","metadata":{"papermill":{"duration":0.127928,"end_time":"2023-07-03T08:05:39.009659","exception":false,"start_time":"2023-07-03T08:05:38.881731","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":217,"id":"17043223","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-03T08:05:39.271519Z","iopub.status.busy":"2023-07-03T08:05:39.271128Z","iopub.status.idle":"2023-07-03T08:05:50.358186Z","shell.execute_reply":"2023-07-03T08:05:50.356949Z"},"papermill":{"duration":11.22099,"end_time":"2023-07-03T08:05:50.360291","exception":false,"start_time":"2023-07-03T08:05:39.139301","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["test_defog: 100%|██████████| 1/1 [00:11<00:00, 11.06s/it]"]},{"name":"stdout","output_type":"stream","text":["CPU times: user 9.35 s, sys: 1.69 s, total: 11 s\n","Wall time: 11.1 s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","\n","# =========================\n","# defog6\n","# =========================\n","th_len = 200000\n","# w = 0.10\n","w = 0.15\n","\n","cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","            'AccV_lag_diff',  'AccV_lead_diff', \n","            'AccML_lag_diff', 'AccML_lead_diff',\n","            'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# defog_list = glob.glob(DEFOG_DATA_PATH)\n","# for p in tqdm(defog_list):\n","for p in tqdm(test_defog, desc=\"test_defog: \"):\n","    # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","    id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","    df = pd.read_csv(p)\n","    if len(df) > th_len:\n","        seq_len = 30000\n","        shift = 15000\n","        offset = 7500\n","    else:\n","        seq_len = 15000\n","        shift = 7500\n","        offset = 3750\n","    batch = (len(df)-1) // shift\n","    if batch == 0:\n","        batch = 1\n","    for c in cols:\n","        df[f\"{c}_lag_diff\"] = df[c].diff()\n","        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","    sc = StandardScaler()\n","    df[num_cols] = sc.fit_transform(df[num_cols].values)\n","    df[num_cols] = df[num_cols].fillna(0)\n","    num = df[num_cols].values\n","    time = df[\"Time\"].values\n","    \n","    num_array = np.zeros([batch,seq_len, 9])\n","    mask_array = np.zeros([batch,seq_len], dtype=int)\n","    time_array = np.zeros([batch,seq_len], dtype=int)\n","    pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","    if len(df) <= seq_len:\n","        b = 0\n","        num_len = len(num)\n","        num_array[b,  :num_len, :] = num\n","        time_array[b, :num_len] = time\n","        mask_array[b, :num_len] = 1\n","        pred_use_array[b, :num_len] = 1\n","    else:\n","        for n,b in enumerate(range(batch)):\n","            if b == (batch - 1):\n","                num_ = num[b*shift : ]\n","                time_ = time[b*shift : ]\n","                num_len = len(num_)\n","\n","                num_array[b,  :num_len, :] = num_\n","                time_array[b, :num_len] = time_\n","                mask_array[b, :num_len] = 1\n","                pred_use_array[b, offset:num_len] = 1\n","            elif b == 0:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b,  :, :] = num_\n","                time_array[b, :] = time_\n","                mask_array[b, :] = 1\n","                pred_use_array[b,:shift+offset] = 1\n","            else:\n","                num_ = num[b*shift : b*shift+seq_len]\n","                time_ = time[b*shift : b*shift + seq_len]\n","\n","                num_array[b, :, :] = num_\n","                time_array[b,:] = time_\n","                mask_array[b,:] = 1\n","                pred_use_array[b,offset:shift+offset] = 1  \n","    \n","    test_ = FogDataset(num_array, mask_array, train=False)\n","    test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","    for n,m in enumerate(defog_model_list6):\n","        if n == 0:\n","            pred = make_pred(test_loader,m) / len(defog_model_list6)\n","        else:\n","            pred += make_pred(test_loader,m) / len(defog_model_list6)\n","    \n","    pred_list = []\n","    for i in range(batch):\n","        mask_ = pred_use_array[i]\n","        pred_ = pred[i,mask_ == 1,:]\n","        time_ = time_array[i, mask_ == 1]\n","        \n","        df_ = pd.DataFrame()\n","        df_[\"StartHesitation\"] = pred_[:,0] * w\n","        df_[\"Turn\"] = pred_[:,1] * w\n","        df_[\"Walking\"] = pred_[:,2] * w\n","        df_[\"Time\"] = time_\n","        df_[\"Id\"] = id_values\n","        df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","        pred_list.append(df_)\n","    pred = pd.concat(pred_list).reset_index(drop=True)\n","    df_all.append(pred)"]},{"cell_type":"markdown","id":"3326b09f","metadata":{"papermill":{"duration":0.133272,"end_time":"2023-07-03T08:05:50.624917","exception":false,"start_time":"2023-07-03T08:05:50.491645","status":"completed"},"tags":[]},"source":["<br>\n","\n","### **ex238** (defog7: 0.05)\n","\n","#### load checkpoint"]},{"cell_type":"code","execution_count":218,"id":"0496c73b","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:50.888989Z","iopub.status.busy":"2023-07-03T08:05:50.888629Z","iopub.status.idle":"2023-07-03T08:05:50.89317Z","shell.execute_reply":"2023-07-03T08:05:50.892214Z"},"papermill":{"duration":0.138566,"end_time":"2023-07-03T08:05:50.895113","exception":false,"start_time":"2023-07-03T08:05:50.756547","status":"completed"},"tags":[]},"outputs":[],"source":["# # Defog3Model()\n","\n","# defog_model_list7 = []\n","# for path in defog_path7:    # ex238\n","#     model = Defog3Model()\n","#     state = torch.load(path, map_location=torch.device(\"cpu\"))\n","#     model.load_state_dict(state[\"model\"])\n","#     model = model.to(device)\n","#     model.eval()\n","#     defog_model_list7.append(model)\n","#     print(f\"load weights from {path}\")"]},{"cell_type":"markdown","id":"a695259f","metadata":{"papermill":{"duration":0.133555,"end_time":"2023-07-03T08:05:51.158647","exception":false,"start_time":"2023-07-03T08:05:51.025092","status":"completed"},"tags":[]},"source":["<br>\n","\n","#### predict"]},{"cell_type":"code","execution_count":219,"id":"3ab6fbbf","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:51.466698Z","iopub.status.busy":"2023-07-03T08:05:51.466311Z","iopub.status.idle":"2023-07-03T08:05:51.473551Z","shell.execute_reply":"2023-07-03T08:05:51.472668Z"},"papermill":{"duration":0.140825,"end_time":"2023-07-03T08:05:51.475614","exception":false,"start_time":"2023-07-03T08:05:51.334789","status":"completed"},"tags":[]},"outputs":[],"source":["# %%time\n","\n","# # =========================\n","# # defog7\n","# # =========================\n","# th_len = 200000\n","# w = 0.05\n","\n","# cols = [\"AccV\",\"AccML\",\"AccAP\"]\n","# num_cols = [\"AccV\", \"AccML\", \"AccAP\",\n","#             'AccV_lag_diff',  'AccV_lead_diff', \n","#             'AccML_lag_diff', 'AccML_lead_diff',\n","#             'AccAP_lag_diff', 'AccAP_lead_diff']\n","\n","# # defog_list = glob.glob(DEFOG_DATA_PATH)\n","# # for p in tqdm(defog_list):\n","# for p in tqdm(test_defog, desc=\"test_defog: \"):\n","#     # id_values = p.split(\"/\")[-1].split(\".\")[0]\n","#     id_values = p.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n","    \n","#     df = pd.read_csv(p)\n","#     if len(df) > th_len:\n","#         seq_len = 30000\n","#         shift = 15000\n","#         offset = 7500\n","#     else:\n","#         seq_len = 15000\n","#         shift = 7500\n","#         offset = 3750\n","#     batch = (len(df)-1) // shift\n","#     if batch == 0:\n","#         batch = 1\n","#     for c in cols:\n","#         df[f\"{c}_lag_diff\"] = df[c].diff()\n","#         df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n","#     sc = StandardScaler()\n","#     df[num_cols] = sc.fit_transform(df[num_cols].values)\n","#     df[num_cols] = df[num_cols].fillna(0)\n","#     num = df[num_cols].values\n","#     time = df[\"Time\"].values\n","    \n","#     num_array = np.zeros([batch,seq_len, 9])\n","#     mask_array = np.zeros([batch,seq_len], dtype=int)\n","#     time_array = np.zeros([batch,seq_len], dtype=int)\n","#     pred_use_array = np.zeros([batch,seq_len], dtype=int)\n","    \n","#     if len(df) <= seq_len:\n","#         b = 0\n","#         num_len = len(num)\n","#         num_array[b,  :num_len, :] = num\n","#         time_array[b, :num_len] = time\n","#         mask_array[b, :num_len] = 1\n","#         pred_use_array[b, :num_len] = 1\n","#     else:\n","#         for n,b in enumerate(range(batch)):\n","#             if b == (batch - 1):\n","#                 num_ = num[b*shift : ]\n","#                 time_ = time[b*shift : ]\n","#                 num_len = len(num_)\n","\n","#                 num_array[b,  :num_len, :] = num_\n","#                 time_array[b, :num_len] = time_\n","#                 mask_array[b, :num_len] = 1\n","#                 pred_use_array[b, offset:num_len] = 1\n","#             elif b == 0:\n","#                 num_ = num[b*shift : b*shift+seq_len]\n","#                 time_ = time[b*shift : b*shift + seq_len]\n","\n","#                 num_array[b,  :, :] = num_\n","#                 time_array[b, :] = time_\n","#                 mask_array[b, :] = 1\n","#                 pred_use_array[b,:shift+offset] = 1\n","#             else:\n","#                 num_ = num[b*shift : b*shift+seq_len]\n","#                 time_ = time[b*shift : b*shift + seq_len]\n","\n","#                 num_array[b, :, :] = num_\n","#                 time_array[b,:] = time_\n","#                 mask_array[b,:] = 1\n","#                 pred_use_array[b,offset:shift+offset] = 1  \n","    \n","#     test_ = FogDataset(num_array, mask_array, train=False)\n","#     test_loader = DataLoader(dataset=test_, batch_size=bs, shuffle = False)\n","#     for n,m in enumerate(defog_model_list7):\n","#         if n == 0:\n","#             pred = make_pred(test_loader,m) / len(defog_model_list7)\n","#         else:\n","#             pred += make_pred(test_loader,m) / len(defog_model_list7)\n","    \n","#     pred_list = []\n","#     for i in range(batch):\n","#         mask_ = pred_use_array[i]\n","#         pred_ = pred[i,mask_ == 1,:]\n","#         time_ = time_array[i, mask_ == 1]\n","        \n","#         df_ = pd.DataFrame()\n","#         df_[\"StartHesitation\"] = pred_[:,0] * w\n","#         df_[\"Turn\"] = pred_[:,1] * w\n","#         df_[\"Walking\"] = pred_[:,2] * w\n","#         df_[\"Time\"] = time_\n","#         df_[\"Id\"] = id_values\n","#         df_[\"Id\"] = df_[\"Id\"].astype(str) + \"_\" + df_[\"Time\"].astype(str)\n","        \n","#         pred_list.append(df_)\n","#     pred = pd.concat(pred_list).reset_index(drop=True)\n","#     df_all.append(pred)"]},{"cell_type":"markdown","id":"74af3ac8","metadata":{"papermill":{"duration":0.130085,"end_time":"2023-07-03T08:05:51.741096","exception":false,"start_time":"2023-07-03T08:05:51.611011","status":"completed"},"tags":[]},"source":["<br>\n","<br>\n","\n","\n","# **Submission** "]},{"cell_type":"code","execution_count":220,"id":"8a9fe8e3","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:52.003522Z","iopub.status.busy":"2023-07-03T08:05:52.002591Z","iopub.status.idle":"2023-07-03T08:05:54.438503Z","shell.execute_reply":"2023-07-03T08:05:54.437386Z"},"papermill":{"duration":2.56988,"end_time":"2023-07-03T08:05:54.440917","exception":false,"start_time":"2023-07-03T08:05:51.871037","status":"completed"},"tags":[]},"outputs":[],"source":["df_all = pd.concat(df_all).reset_index(drop=True)\n","df_all = df_all.groupby(by=\"Id\")[['StartHesitation', 'Turn', 'Walking']].sum().reset_index()\n","df_all[['Id', 'StartHesitation', 'Turn', 'Walking']].to_csv(\"submission.csv\",index=False)"]},{"cell_type":"code","execution_count":221,"id":"032ec39a","metadata":{"execution":{"iopub.execute_input":"2023-07-03T08:05:54.707075Z","iopub.status.busy":"2023-07-03T08:05:54.706726Z","iopub.status.idle":"2023-07-03T08:05:54.723531Z","shell.execute_reply":"2023-07-03T08:05:54.722515Z"},"papermill":{"duration":0.151419,"end_time":"2023-07-03T08:05:54.725629","exception":false,"start_time":"2023-07-03T08:05:54.57421","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>StartHesitation</th>\n","      <th>Turn</th>\n","      <th>Walking</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>003f117e14_0</td>\n","      <td>0.002476</td>\n","      <td>0.002984</td>\n","      <td>0.000762</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>003f117e14_1</td>\n","      <td>0.002400</td>\n","      <td>0.002903</td>\n","      <td>0.000708</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>003f117e14_10</td>\n","      <td>0.001943</td>\n","      <td>0.002561</td>\n","      <td>0.000587</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003f117e14_100</td>\n","      <td>0.001559</td>\n","      <td>0.002188</td>\n","      <td>0.000472</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>003f117e14_1000</td>\n","      <td>0.002783</td>\n","      <td>0.042777</td>\n","      <td>0.000950</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>286365</th>\n","      <td>02ab235146_99995</td>\n","      <td>0.000067</td>\n","      <td>0.033726</td>\n","      <td>0.004219</td>\n","    </tr>\n","    <tr>\n","      <th>286366</th>\n","      <td>02ab235146_99996</td>\n","      <td>0.000066</td>\n","      <td>0.032923</td>\n","      <td>0.004129</td>\n","    </tr>\n","    <tr>\n","      <th>286367</th>\n","      <td>02ab235146_99997</td>\n","      <td>0.000065</td>\n","      <td>0.032285</td>\n","      <td>0.004020</td>\n","    </tr>\n","    <tr>\n","      <th>286368</th>\n","      <td>02ab235146_99998</td>\n","      <td>0.000064</td>\n","      <td>0.031890</td>\n","      <td>0.003912</td>\n","    </tr>\n","    <tr>\n","      <th>286369</th>\n","      <td>02ab235146_99999</td>\n","      <td>0.000062</td>\n","      <td>0.031264</td>\n","      <td>0.003791</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>286370 rows × 4 columns</p>\n","</div>"],"text/plain":["                      Id  StartHesitation      Turn   Walking\n","0           003f117e14_0         0.002476  0.002984  0.000762\n","1           003f117e14_1         0.002400  0.002903  0.000708\n","2          003f117e14_10         0.001943  0.002561  0.000587\n","3         003f117e14_100         0.001559  0.002188  0.000472\n","4        003f117e14_1000         0.002783  0.042777  0.000950\n","...                  ...              ...       ...       ...\n","286365  02ab235146_99995         0.000067  0.033726  0.004219\n","286366  02ab235146_99996         0.000066  0.032923  0.004129\n","286367  02ab235146_99997         0.000065  0.032285  0.004020\n","286368  02ab235146_99998         0.000064  0.031890  0.003912\n","286369  02ab235146_99999         0.000062  0.031264  0.003791\n","\n","[286370 rows x 4 columns]"]},"execution_count":221,"metadata":{},"output_type":"execute_result"}],"source":["df_all"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":471.31325,"end_time":"2023-07-03T08:05:57.869358","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-03T07:58:06.556108","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}