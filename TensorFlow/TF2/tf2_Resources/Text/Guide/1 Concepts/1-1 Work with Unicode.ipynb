{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><font color=maroon size=6 style=\"line-height:40px;\"><b>Unicode strings</b></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>References:</b></font>\n",
    "1. TensorFlow > <a href=\"https://www.tensorflow.org/resources\" style=\"text-decoration:none;\">Resources</a> \n",
    "    * `TensorFlow > Resources > Text > Guide > `<a href=\"https://www.tensorflow.org/text/guide/unicode\" style=\"text-decoration:none;\">Unicode strings</a>\n",
    "        * Run in <a href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/guide/unicode.ipynb\" style=\"text-decoration:none;\">Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "NLP models often handle different languages with different character sets.  <font style=\"color:maroon;font-size:120%\">***Unicode*** is a standard encoding system that is used to represent characters from almost all languages.  Every Unicode character is encoded using a unique integer [code point](https://en.wikipedia.org/wiki/Code_point) between `0` and `0x10FFFF`. A *Unicode string* is a sequence of zero or more code points.</font>\n",
    "\n",
    "This tutorial shows how to represent Unicode strings in TensorFlow and manipulate them using Unicode equivalents of standard string ops. It separates Unicode strings into tokens based on script detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `tf.string` data type\n",
    "<br>\n",
    "\n",
    "The basic TensorFlow `tf.string` `dtype` allows you to build tensors of byte strings.<br>\n",
    "<br>\n",
    "\n",
    "<font style=\"color:maroon;font-size:130%\">**Unicode strings are [utf-8](https://en.wikipedia.org/wiki/UTF-8) encoded by default.**</font>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"Thanks üòä\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"Thanks üòä\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:130%;line-height:30px\">A `tf.string` tensor treats **byte strings** as atomic units. This enables it to store byte strings of varying lengths. The string length is not included in the tensor dimensions.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:130%;line-height:30px\">If you use Python to construct strings, note that [string literals](https://docs.python.org/3/reference/lexical_analysis.html) are Unicode-encoded by default.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Unicode\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">There are two standard ways to represent a Unicode string in TensorFlow:\n",
    "\n",
    "* `string` **scalar** ‚Äî where the sequence of code points is encoded using a known [character encoding](https://en.wikipedia.org/wiki/Character_encoding).\n",
    "* `int32` **vector** ‚Äî where each position contains a single code point.</font>\n",
    "\n",
    "For example, the following three values all represent the Unicode string `\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"` (which means \"language processing\" in Chinese):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a vector of Unicode code points.\n",
    "text_chars = tf.constant([ord(char) for char in u\"ËØ≠Ë®ÄÂ§ÑÁêÜ\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting between representations\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">TensorFlow provides operations to convert between these different representations:\n",
    "\n",
    "* `tf.strings.unicode_decode`: Converts an **encoded string** scalar to a vector of **code points**.\n",
    "* `tf.strings.unicode_encode`: Converts a vector of code points to an encoded string scalar.\n",
    "* `tf.strings.unicode_transcode`: Converts an encoded string scalar to a different encoding.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86', shape=(), dtype=string)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_utf8)\n",
    "\n",
    "tf.strings.unicode_decode(text_utf8,\n",
    "                          input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([35821 35328 22788 29702], shape=(4,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text_chars)\n",
    "\n",
    "tf.strings.unicode_encode(text_chars,\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8,\n",
    "                             input_encoding='UTF8',\n",
    "                             output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch dimensions\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">When decoding multiple strings, the number of characters in each string may not be equal.  The return result is a [`tf.RaggedTensor`](https://colab.research.google.com/github/tensorflow/text/blob/master/guide/ragged_tensor.ipynb), where the **innermost** dimension length varies depending on the number of characters in each string.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'h\\xc3\\x83llo', b'What is the weather tomorrow', b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a']\n",
      "\n",
      "<tf.RaggedTensor [[104, 195, 108, 108, 111],\n",
      " [87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116,\n",
      "  104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]               ,\n",
      " [71, 246, 246, 100, 110, 105, 103, 104, 116], [128522]]>\n",
      "\n",
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
    "batch_utf8 = [s.encode('UTF-8') for s in \n",
    "              [u'h√Éllo', u'What is the weather tomorrow', u'G√∂√∂dnight', u'üòä']]\n",
    "print(batch_utf8)\n",
    "print()\n",
    "\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "print(batch_chars_ragged)\n",
    "print()\n",
    "\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "    print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">You can use this `tf.RaggedTensor` directly, or convert it to a dense `tf.Tensor` with padding or a `tf.sparse.SparseTensor` using the methods `tf.RaggedTensor.to_tensor` and `tf.RaggedTensor.to_sparse`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 1  0]\n",
      " [ 1  1]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 1  4]\n",
      " [ 1  5]\n",
      " [ 1  6]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 13]\n",
      " [ 1 14]\n",
      " [ 1 15]\n",
      " [ 1 16]\n",
      " [ 1 17]\n",
      " [ 1 18]\n",
      " [ 1 19]\n",
      " [ 1 20]\n",
      " [ 1 21]\n",
      " [ 1 22]\n",
      " [ 1 23]\n",
      " [ 1 24]\n",
      " [ 1 25]\n",
      " [ 1 26]\n",
      " [ 1 27]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 2  3]\n",
      " [ 2  4]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2  7]\n",
      " [ 2  8]\n",
      " [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n",
      "[   104    195    108    108    111     87    104     97    116     32\n",
      "    105    115     32    116    104    101     32    119    101     97\n",
      "    116    104    101    114     32    116    111    109    111    114\n",
      "    114    111    119     71    246    246    100    110    105    103\n",
      "    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n",
      "\n",
      "tf.Tensor([ 4 28], shape=(2,), dtype=int64)\n",
      "\n",
      "[[   104,    195,    108,    108,    111,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]\n",
      " [    87,    104,     97,    116,     32,    105,    115,     32,    116,    104,    101,     32,    119,    101,     97,    116,    104,    101,    114,     32,    116,    111,    109,    111,    114,    114,    111,    119]\n",
      " [    71,    246,    246,    100,    110,    105,    103,    104,    116,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]\n",
      " [128522,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "print(batch_chars_sparse)\n",
    "print()\n",
    "\n",
    "print(batch_chars_sparse.dense_shape)\n",
    "print()\n",
    "\n",
    "nrows, ncols = batch_chars_sparse.dense_shape.numpy()  # [ 4 28]\n",
    "elements = [['_' for i in range(ncols)] for j in range(nrows)]\n",
    "\n",
    "for (row, col), value in zip(batch_chars_sparse.indices.numpy(), \n",
    "                             batch_chars_sparse.values.numpy()):\n",
    "    elements[row][col] = str(value)\n",
    "\n",
    "# max_width = max(len(value) for row in elements for value in row)\n",
    "value_lengths = []\n",
    "for row in elements:\n",
    "    for value in row:\n",
    "        value_lengths.append(len(value))\n",
    "\n",
    "max_width = max(value_lengths)\n",
    "print('[%s]' % '\\n '.join('[%s]' % ', '.join(value.rjust(max_width) for value in row)\n",
    "                          for row in elements))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:130%;line-height:30px\">When encoding multiple strings with the **same lengths**, use a **`tf.Tensor`** as the input.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [99, 111, 119]],\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:130%;line-height:30px\">When encoding multiple strings with **varying length**, use a **`tf.RaggedTensor`** as the input.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[104, 195, 108, 108, 111],\n",
       " [87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116,\n",
       "  104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]               ,\n",
       " [71, 246, 246, 100, 110, 105, 103, 104, 116], [128522]]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_chars_ragged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:130%;line-height:30px\">If you have a tensor with multiple strings **in padded or sparse format**, convert it first into a `tf.RaggedTensor` before calling `tf.strings.unicode_encode`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character length\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">Use the `unit` parameter of the `tf.strings.length` op to indicate how **character lengths** should be computed.<br>\n",
    "\n",
    "**`unit` defaults to `\"BYTE\"`**, but it can be set to other values, such as `\"UTF8_CHAR\"` or `\"UTF16_CHAR\"`, to determine the number of Unicode codepoints in each encoded string.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; \n",
      "8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# Note that the final character takes up 4 bytes in UTF8.\n",
    "thanks = u'Thanks üòä'.encode('UTF-8')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; \\n{} UTF-8 characters'.format(num_bytes, num_chars))\n",
    "\n",
    "# ÂØπ‰∫é UTF8_CHAR Êù•ËØ¥Ôºö\n",
    "# \"Thanks\" Êúâ 6 ‰∏™ byteÔºõ6 ‰∏™ character„ÄÇ\n",
    "# \" \" Êúâ 1 ‰∏™ byteÔºõ1 ‰∏™ character„ÄÇ\n",
    "# üòä Êúâ 4 ‰∏™ byteÔºõ1 ‰∏™ character„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Thanks \\xf0\\x9f\\x98\\x8a'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character substrings\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">The `tf.strings.substr` op accepts the `unit` parameter, and uses it to determine what kind of **offsets** the **`pos`** and `len` paremeters contain.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, unit='BYTE' (default). Returns a single byte with len=1\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()\n",
    "\n",
    "# Ê≠§Êó∂Á¨¨ 7 ‰∏™ byte ‰πãÂêéÁöÑÁ¨¨‰∏Ä‰∏™ byte ÊÅ∞Â•ΩÊòØ üòä ÁöÑ Á¨¨‰∏Ä‰∏™ byte„ÄÇ\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xf0\\x9f\\x98\\x8a'\n"
     ]
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', returns a single 4 byte character in this case\n",
    "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())\n",
    "\n",
    "# Ê≠§Êó∂Á¨¨ 7 ‰∏™ character ‰πãÂêéÁöÑÁ¨¨‰∏Ä‰∏™ character ÊÅ∞Â•ΩÊòØ üòä„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b's'\n"
     ]
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', returns a single 4 byte character in this case\n",
    "print(tf.strings.substr(thanks, pos=5, len=1, unit='UTF8_CHAR').numpy())\n",
    "\n",
    "# Ê≠§Êó∂Á¨¨ 5 ‰∏™ character ‰πãÂêéÁöÑÁ¨¨‰∏Ä‰∏™ character ÊÅ∞Â•ΩÊòØ \"Thanks üòä\" ‰∏≠ÁöÑ s„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Unicode strings\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">The `tf.strings.unicode_split` operation splits unicode strings into substrings of **individual characters**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte offsets for characters\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">To align the character tensor generated by `tf.strings.unicode_decode` with the original string, it's useful to know the offset for where each character begins.  The method `tf.strings.unicode_decode_with_offsets` is similar to `unicode_decode`, except that it returns a second tensor containing the start offset of each character.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint 127880\n",
      "At byte offset 4: codepoint 127881\n",
      "At byte offset 8: codepoint 127882\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u'üéàüéâüéä', 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "    print('At byte offset {}: codepoint {}'.format(offset, codepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">Each Unicode code point belongs to a single collection of codepoints known as a [**script**](https://en.wikipedia.org/wiki/Script_%28Unicode%29) .  **A *character's script* is helpful in determining which language the character might be in**.<br>\n",
    "For example, knowing that '–ë' is in Cyrillic script indicates that modern text containing that character is likely from a Slavic language such as Russian or Ukrainian.\n",
    "\n",
    "TensorFlow provides the `tf.strings.unicode_script` operation to determine which script a given codepoint uses. The script codes are `int32` values corresponding to [International Components for\n",
    "Unicode](http://site.icu-project.org/home) (ICU) [`UScriptCode`](http://icu-project.org/apiref/icu4c/uscript_8h.html) values.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['Ëä∏', '–ë']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.strings.unicode_script` operation can also be applied to multidimensional `tf.Tensor`s or `tf.RaggedTensor`s of codepoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[25, 25, 25, 25, 25],\n",
      " [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25,\n",
      "  0, 25, 25, 25, 25, 25, 25, 25, 25]                                      ,\n",
      " [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[104, 195, 108, 108, 111],\n",
      " [87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116,\n",
      "  104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]               ,\n",
      " [71, 246, 246, 100, 110, 105, 103, 104, 116], [128522]]>\n",
      "\n",
      "tf.Tensor(\n",
      "[b'h\\xc3\\x83llo' b'What is the weather tomorrow'\n",
      " b'G\\xc3\\xb6\\xc3\\xb6dnight' b'\\xf0\\x9f\\x98\\x8a'], shape=(4,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(batch_chars_ragged)\n",
    "print()\n",
    "print(tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Simple segmentation\n",
    "\n",
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">Segmentation is the task of splitting text into word-like units. This is often easy when space characters are used to separate words, but some languages (like Chinese and Japanese) do not use spaces, and some languages (like German) contain long compounds that must be split in order to analyze their meaning. In web text, different languages and scripts are frequently mixed together, as in \"NYÊ†™‰æ°\" (New York Stock Exchange).\n",
    "\n",
    "We can perform very rough segmentation (without implementing any ML models) by using changes in script to approximate word boundaries. This will work for strings like the \"NYÊ†™‰æ°\" example above. It will also work for most languages that use spaces, **as the *space characters* of various scripts are all classified as USCRIPT_COMMON, a special script code that differs from that of any actual text**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "#\n",
    "# The sentences to process.  Edit this line to try out different inputs!\n",
    "sentence_texts = [u'Hello, world.', u'‰∏ñÁïå„Åì„Çì„Å´„Å°„ÅØ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, decode the sentences into character codepoints, and find the script identifeir for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46],\n",
      " [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0],\n",
      " [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] \n",
    "# is the codepoint for the j'th character in the i'th sentence.\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "print()\n",
    "\n",
    "\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:maroon;font-size:120%;line-height:30px\">Use the **script identifiers** to determine where word boundaries should be added.</font>  Add a word boundary at the beginning of each sentence, and for each character whose script differs from the previous character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n",
    "# sentence is the start of a word.\n",
    "sentence_char_starts_word = tf.concat([ tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "                                        tf.not_equal(sentence_char_script[:, 1:], \n",
    "                                                     sentence_char_script[:, :-1])],\n",
    "                                        axis=1)\n",
    "\n",
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] is the index of the character that starts the i'th word (in\n",
    "# the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use those start offsets to build a `RaggedTensor` containing the list of words from all batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46],\n",
      " [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(values=sentence_char_codepoint.values,\n",
    "                                                      row_starts=word_starts)\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish, segment the word codepoints `RaggedTensor` back into sentences and encode into UTF-8 strings for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]],\n",
      " [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[b'Hello', b', ', b'world', b'.'],\n",
       " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
       "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(values=word_char_codepoint,\n",
    "                                                                row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)\n",
    "\n",
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfg]",
   "language": "python",
   "name": "conda-env-tfg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
