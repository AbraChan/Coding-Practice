{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><font color=maroon size=6><b>Save and load Keras models</b></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>References:</b></font>\n",
    "1. TF2 Core: <a href=\"https://www.tensorflow.org/guide\" style=\"text-decoration:none;\">TensorFlow Guide</a> \n",
    "    * `TensorFlow > Learn > TensorFlow Core > `Guide > <a href=\"https://www.tensorflow.org/guide/keras/save_and_serialize\" style=\"text-decoration:none;\">Save and load Keras models </a>\n",
    "        * Run in <a href=\"https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/save_and_serialize.ipynb\" style=\"text-decoration:none;\">Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "<font size=3 color=maroon>A Keras model consists of multiple components:</font>\n",
    "\n",
    "- The architecture, or configuration, which specifies what layers the model contain, and how they're connected.\n",
    "- A set of weights values (the \"state of the model\").\n",
    "- An optimizer (defined by compiling the model).\n",
    "- A set of losses and metrics (defined by compiling the model or calling `add_loss()` or `add_metric()`).\n",
    "\n",
    "<font size=3 color=maroon>The Keras API makes it possible to save all of these pieces to disk at once, or to only selectively save some of them:</font>\n",
    "\n",
    "- Saving everything into a single archive in the TensorFlow SavedModel format (or in the older Keras H5 format). This is the standard practice.\n",
    "- Saving the architecture / configuration only, typically as a JSON file.\n",
    "- Saving the weights values only. This is generally used when training the model.\n",
    "\n",
    "Let's take a look at each of these options. When would you use one or the other, and how do they work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to save and load a model\n",
    "\n",
    "<font size=3 color=maroon>If you only have 10 seconds to read this guide, here's what you need to know.</font>\n",
    "\n",
    "**Saving a Keras model:**\n",
    "\n",
    "```python\n",
    "model = ...  # Get model (Sequential, Functional Model, or Model subclass)\n",
    "model.save('path/to/location')\n",
    "```\n",
    "\n",
    "**Loading the model back:**\n",
    "\n",
    "```python\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('path/to/location')\n",
    "```\n",
    "\n",
    "Now, let's look at the details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon>**Whole-model saving & loading**</font>\n",
    "\n",
    "You can save an entire model to a single artifact. It will include:\n",
    "\n",
    "- The model's architecture/config\n",
    "- The model's weight values (which were learned during training)\n",
    "- The model's compilation information (if `compile()` was called)\n",
    "- The optimizer and its state, if any (this enables you to restart training where you left)\n",
    "\n",
    "### <font size=3 color=maroon>**APIs**</font>\n",
    "\n",
    "- `model.save()` or `tf.keras.models.save_model()`\n",
    "- `tf.keras.models.load_model()`\n",
    "\n",
    "<font size=3 color=maroon>There are two formats you can use to save an entire model to disk:\n",
    "* **the TensorFlow SavedModel format**, \n",
    "* and the older Keras **H5 format**.\n",
    "\n",
    "The recommended format is *SavedModel*. It is the default when you use `model.save()`.</font>\n",
    "\n",
    "You can switch to the H5 format by:\n",
    "\n",
    "- Passing `save_format='h5'` to `save()`.\n",
    "- Passing a filename that ends in `.h5` or `.keras` to `save()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=maroon>SavedModel format</font>\n",
    "\n",
    "<font size=3 color=maroon>SavedModel is the more comprehensive save format that saves the model architecture, weights, and the traced Tensorflow subgraphs of the call functions. This enables Keras to restore both built-in layers as well as custom objects.</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step - loss: 4.5967\n",
      "INFO:tensorflow:Assets written to: save_model/2_5_try1_SaveModel-format\\assets\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4.3150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x192f1450be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train the model.\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "\n",
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "model.save(\"save_model/2_5_try1_SaveModel-format\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "reconstructed_model = keras.models.load_model(\"save_model/2_5_try1_SaveModel-format\")\n",
    "\n",
    "# Let's check:\n",
    "np.testing.assert_allclose(model.predict(test_input), reconstructed_model.predict(test_input))\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer state, so training can resume:\n",
    "reconstructed_model.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What the SavedModel contains\n",
    "\n",
    "Calling `model.save('my_model')` creates a folder named `my_model`, containing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\n",
      "keras_metadata.pb\n",
      "saved_model.pb\n",
      "variables\n"
     ]
    }
   ],
   "source": [
    "!ls save_model/2_5_try1_SaveModel-format/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>\n",
    "    \n",
    "* The model architecture, and training configuration (including the optimizer, losses, and metrics) are stored in `saved_model.pb`.\n",
    "    \n",
    "* The weights are saved in the `variables/` directory.\n",
    "    \n",
    "</font>\n",
    "\n",
    "For detailed information on the SavedModel format, see the[SavedModel guide (*The SavedModel format on disk*)](https://www.tensorflow.org/guide/saved_model#the_savedmodel_format_on_disk).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How SavedModel handles custom objects\n",
    "\n",
    "When saving the model and its layers, the SavedModel format stores the class name, **call function**, losses, and weights (and the config, if implemented). <font size=3 color=maroon>The call function defines the computation graph of the model/layer.</font>\n",
    "\n",
    "In the absence of the model/layer config, the call function is used to create a model that exists like the original model which can be trained, evaluated, and used for inference.\n",
    "\n",
    "<font size=3 color=maroon>Nevertheless, it is always a good practice to define the `get_config` and `from_config` methods when writing a custom model or layer class. This allows you to easily update the computation later if needed.</font><br>\n",
    "See the section about [Custom objects](#custom-objects) for more information.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: save_model/2_5_try2_SaveModel-format_custom\\assets\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "\n",
      "Original model: <__main__.CustomModel object at 0x00000192FF602520>\n",
      "\n",
      "Model Loaded with custom objects: <__main__.CustomModel object at 0x0000019537401670>\n",
      "\n",
      "Model loaded without the custom object class: <keras.saving.saved_model.load.CustomModel object at 0x000001956C9FA820>\n"
     ]
    }
   ],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"hidden_units\": self.hidden_units}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "model = CustomModel([16, 16, 10])\n",
    "# Build the model by calling it\n",
    "input_arr = tf.random.uniform((1, 5))\n",
    "outputs = model(input_arr)\n",
    "model.save(\"save_model/2_5_try2_SaveModel-format_custom\")\n",
    "\n",
    "## Option 1: Load with the custom_object argument.\n",
    "loaded_1 = keras.models.load_model(\"save_model/2_5_try2_SaveModel-format_custom\", \n",
    "                                   custom_objects={\"CustomModel\": CustomModel})\n",
    "\n",
    "\n",
    "## Option 2: Load without the CustomModel class.\n",
    "\n",
    "# Delete the custom-defined model class to ensure that the loader does not have\n",
    "# access to it.\n",
    "del CustomModel\n",
    "\n",
    "loaded_2 = keras.models.load_model(\"save_model/2_5_try2_SaveModel-format_custom\")\n",
    "np.testing.assert_allclose(loaded_1(input_arr), outputs)\n",
    "np.testing.assert_allclose(loaded_2(input_arr), outputs)\n",
    "\n",
    "print()\n",
    "print(\"Original model:\", model)\n",
    "print()\n",
    "\n",
    "print(\"Model Loaded with custom objects:\", loaded_1)\n",
    "print()\n",
    "\n",
    "print(\"Model loaded without the custom object class:\", loaded_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first loaded model is loaded using the config and `CustomModel` class. The second model is loaded by dynamically creating the model class that acts like the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring the SavedModel\n",
    "\n",
    "*New in TensoFlow 2.4*\n",
    "The argument `save_traces` has been added to `model.save`, which allows you to toggle SavedModel function tracing. Functions are saved to allow the Keras to re-load custom objects without the original class definitons. \n",
    "\n",
    "<font size=3 color=maroon>So when `save_traces=False`, all custom objects must have defined `get_config`/`from_config` methods. When loading, the custom objects must be passed to the `custom_objects` argument. `save_traces=False` reduces the disk space used by the SavedModel and saving time.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=maroon>Keras H5 format</font>\n",
    "\n",
    "Keras also supports saving a single HDF5 file containing the model's architecture, weights values, and `compile()` information.<br>\n",
    "<font size=3 color=maroon>It is a light-weight alternative to SavedModel.</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8865\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1957202fe80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "# Train the model.\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "\n",
    "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
    "model.save(\"save_model/2_5_try3_save_whole_h5/my_h5_model.h5\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "reconstructed_model = keras.models.load_model(\"save_model/2_5_try3_save_whole_h5/my_h5_model.h5\")\n",
    "\n",
    "# Let's check:\n",
    "np.testing.assert_allclose(model.predict(test_input), reconstructed_model.predict(test_input))\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer state, so training can resume:\n",
    "reconstructed_model.fit(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=maroon>Limitations</font>\n",
    "\n",
    "Compared to the SavedModel format, there are two things that don't get included in the H5 file:\n",
    "\n",
    "- **External losses & metrics** added via `model.add_loss()` & `model.add_metric()` are not saved (unlike SavedModel).\n",
    "  If you have such losses & metrics on your model and you want to resume training, you need to add these losses back yourself after loading the model.Note that this does not apply to losses/metrics created *inside* layers via `self.add_loss()` & `self.add_metric()`. As long as the layer gets loaded, these losses & metrics are kept, since they are part of the `call` method of the layer.\n",
    "\n",
    "\n",
    "- The **computation graph of custom objects** such as custom layers is not included in the saved file. At loading time, Keras will need access to the Python classes/functions of these objects in order to reconstruct the model. See [Custom objects](#custom-objects).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon>**Saving the architecture**</font>\n",
    "\n",
    "The **model's configuration** (or **architecture**) specifies what layers the model contains, and how these layers are connected<font size=3 color=maroon>*</font>. If you have the configuration of a model, then the model can be created with a freshly initialized state for the weights and no compilation information.\n",
    "\n",
    "<font size=3 color=maroon>* **Note** this only applies to models defined using the **functional** or **Sequential** apis  **not subclassed** models.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of a Sequential model or Functional API model\n",
    "\n",
    "<font size=3 color=maroon>These types of models are **explicit graphs of layers**: their configuration is always available in a structured form.</font>\n",
    "\n",
    "#### <font size=3 color=maroon>**APIs**</font>\n",
    "\n",
    "- `get_config()` and `from_config()`\n",
    "- `tf.keras.models.model_to_json()` and `tf.keras.models.model_from_json()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=maroon>get_config()</font> and <font color=maroon>from_config()</font>\n",
    "\n",
    "Calling `config = model.get_config()` will return a Python dict containing the configuration of the model. The same model can then be reconstructed via `Sequential.from_config(config)` (for a `Sequential` model) or `Model.from_config(config)` (for a Functional API model).\n",
    "\n",
    "The same workflow also works for any serializable layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>**Layer** example:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(3, activation=\"relu\")\n",
    "layer_config = layer.get_config()\n",
    "new_layer = keras.layers.Dense.from_config(layer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>**Sequential model** example:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
    "config = model.get_config()\n",
    "new_model = keras.Sequential.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>**Functional model** example:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input((32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "new_model = keras.Model.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=maroon>to_json()</font> and <font color=maroon>tf.keras.models.model_from_json()</font>\n",
    "\n",
    "<font size=3>This is similar to `get_config` / `from_config`, except it <font color=maroon>turns the model into a **JSON string**</font>, which can then be loaded without the original model class. <font color=maroon>It is also specific to **models**, it isn't meant for layers.</font></font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.Input((32,)), keras.layers.Dense(1)])\n",
    "json_config = model.to_json()\n",
    "new_model = keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom objects\n",
    "\n",
    "**Models and layers**\n",
    "\n",
    "<font size=3 color=maroon>The architecture of subclassed models and layers are defined in the methods `__init__` and `call`. They are considered Python bytecode, which cannot be serialized into a JSON-compatible config -- you could try serializing the bytecode (e.g. via `pickle`), but it's completely unsafe and means your model cannot be loaded on a different system.\n",
    "\n",
    "In order to save/load a model with custom-defined layers, or a subclassed model, you should overwrite the `get_config` and optionally `from_config` methods. Additionally, you should use register the custom object so that Keras is aware of it.</font>\n",
    "\n",
    "**Custom functions**\n",
    "\n",
    "Custom-defined functions (e.g. activation loss or initialization) <font size=3 color=maroon>do not need a `get_config` method. The function name is sufficient for loading as long as it is registered as a custom object.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the TensorFlow graph only**\n",
    "\n",
    "It's possible to load the TensorFlow graph generated by the Keras. If you do so, you won't need to provide any `custom_objects`. You can do so like this: `(指使用 tf.saved_model.load ？)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: save_model/2_5_try4_load-tf-graph-only\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"save_model/2_5_try4_load-tf-graph-only\")\n",
    "tensorflow_graph = tf.saved_model.load(\"save_model/2_5_try4_load-tf-graph-only\")\n",
    "\n",
    "x = np.random.uniform(size=(4, 32)).astype(np.float32)\n",
    "predicted = tensorflow_graph(x).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>**Note** that this method has several **drawbacks**:\n",
    "* For traceability reasons, you should always have access to the custom objects that were used. You wouldn't want to put in production a model that you cannot re-create.\n",
    "* The object returned by `tf.saved_model.load` **isn't a Keras model**. So it's not as easy to use. For example, you won't have access to `.predict()` or `.fit()`\n",
    "\n",
    "Even if its use is discouraged, it can help you if you're in a tight spot, for example, if you lost the code of your custom objects or have issues loading the model with `tf.keras.models.load_model()`.</font>\n",
    "\n",
    "You can find out more in the [page about `tf.saved_model.load`](https://www.tensorflow.org/api_docs/python/tf/saved_model/load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the config methods\n",
    "\n",
    "<font size=3 color=maroon>Specifications:\n",
    "\n",
    "* `get_config` should return a JSON-serializable dictionary in order to be compatible with the Keras architecture- and model-saving APIs.\n",
    "* `from_config(config)` (`classmethod`) should return a new layer or model object that is created from the config. The default implementation returns `cls(**config)`.</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            return inputs * self.var\n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"a\": self.var.numpy()}\n",
    "\n",
    "    # There's actually no need to define `from_config` here, \n",
    "    # since returning `cls(**config)` is the default behavior.\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "layer = CustomLayer(5)\n",
    "print(layer.var.numpy())\n",
    "\n",
    "layer.var.assign(2)\n",
    "print(layer.var.numpy())\n",
    "\n",
    "serialized_layer = keras.layers.serialize(layer)\n",
    "new_layer = keras.layers.deserialize(serialized_layer, \n",
    "                                     custom_objects={\"CustomLayer\": CustomLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registering the custom object\n",
    "\n",
    "<font size=3 color=maroon>Keras keeps a note of which class generated the config.\n",
    "From the example above, `tf.keras.layers.serialize` generates a serialized form of the custom layer:\n",
    "\n",
    "```\n",
    "{'class_name': 'CustomLayer', 'config': {'a': 2}}\n",
    "```\n",
    "\n",
    "Keras keeps a master list of all built-in layer, model, optimizer, and metric classes, which is used to find the correct class to call `from_config`. If the  class can't be found, then an error is raised (`Value Error: Unknown layer`).\n",
    "\n",
    "There are a few ways to register custom classes to this list:</font>\n",
    "\n",
    "1. Setting `custom_objects` argument in the loading function. (see the example in section above \"Defining the config methods\")\n",
    "2. `tf.keras.utils.custom_object_scope` or `tf.keras.utils.CustomObjectScope`\n",
    "3. `tf.keras.utils.register_keras_serializable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom layer and function example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(CustomLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=\"random_normal\",\n",
    "                                 trainable=True,)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.units,), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomLayer, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "\n",
    "\n",
    "\n",
    "def custom_activation(x):\n",
    "    return tf.nn.tanh(x) ** 2\n",
    "\n",
    "\n",
    "# Make a model with the CustomLayer and custom_activation\n",
    "inputs = keras.Input((32,))\n",
    "x = CustomLayer(32)(inputs)\n",
    "outputs = keras.layers.Activation(custom_activation)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Retrieve the config\n",
    "config = model.get_config()\n",
    "\n",
    "# At loading time, register the custom objects with a `custom_object_scope`:\n",
    "custom_objects = {\"CustomLayer\": CustomLayer, \"custom_activation\": custom_activation}\n",
    "with keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = keras.Model.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory model cloning\n",
    "\n",
    "<font size=3 color=maroon>You can also do in-memory cloning of a model via `tf.keras.models.clone_model()`.\n",
    "This is equivalent to getting the config then recreating the model **from its config** (**so it does not preserve compilation information or layer weights values**). </font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon>**Saving & loading only the model's weights values**</font>\n",
    "\n",
    "<font size=3 color=maroon>You can choose to only save & load a model's weights. This can be useful if:\n",
    "\n",
    "- You **only need the model for inference**: in this case you won't need to restart training, so you don't need the compilation information or optimizer state.\n",
    "- You are **doing transfer learning**: in this case you will be training a new model reusing the state of a prior model, so you don't need the compilation information of the prior model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=maroon>**APIs**</font> for in-memory weight transfer\n",
    "\n",
    "Weights can be copied between different objects by using `get_weights` and `set_weights`:\n",
    "\n",
    "* `tf.keras.layers.Layer.get_weights()`: Returns a list of numpy arrays.\n",
    "* `tf.keras.layers.Layer.set_weights()`: Sets the model weights to the values in the `weights` argument.\n",
    "\n",
    "\n",
    "Examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***① Transfering weights from one layer to another, in memory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer():\n",
    "    layer = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
    "    layer.build((None, 784))\n",
    "    return layer\n",
    "\n",
    "\n",
    "layer_1 = create_layer()\n",
    "layer_2 = create_layer()\n",
    "\n",
    "# Copy weights from layer 1 to layer 2\n",
    "layer_2.set_weights(layer_1.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***② Transfering weights from one model to another model with a\n",
    "compatible architecture, in memory***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple functional model\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "# Define a subclassed model with the same architecture\n",
    "class SubclassedModel(keras.Model):\n",
    "    def __init__(self, output_dim, name=None):\n",
    "        super(SubclassedModel, self).__init__(name=name)\n",
    "        self.output_dim = output_dim\n",
    "        self.dense_1 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")\n",
    "        self.dense_2 = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
    "        self.dense_3 = keras.layers.Dense(output_dim, name=\"predictions\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"output_dim\": self.output_dim, \"name\": self.name}\n",
    "\n",
    "\n",
    "subclassed_model = SubclassedModel(10)\n",
    "# Call the subclassed model once to create the weights.\n",
    "subclassed_model(tf.ones((1, 784)))\n",
    "\n",
    "# Copy weights from functional_model to subclassed_model.\n",
    "subclassed_model.set_weights(functional_model.get_weights())\n",
    "\n",
    "assert len(functional_model.weights) == len(subclassed_model.weights)\n",
    "for a, b in zip(functional_model.weights, subclassed_model.weights):\n",
    "    np.testing.assert_allclose(a.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***③ The case of stateless layers***\n",
    "\n",
    "<font size=3 color=maroon>Because **stateless layers** do not change the order or number of weights, models can have compatible architectures even if there are extra/missing stateless layers.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "\n",
    "# Add a dropout layer, which does not contain any weights.\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model_with_dropout = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "functional_model_with_dropout.set_weights(functional_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=maroon>**APIs**</font> for saving weights to disk & loading them back\n",
    "\n",
    "Weights can be saved to disk by calling `model.save_weights` in the following formats:\n",
    "\n",
    "* TensorFlow Checkpoint\n",
    "* HDF5\n",
    "\n",
    "The default format for `model.save_weights` is TensorFlow checkpoint.\n",
    "\n",
    "There are two ways to specify the save format:\n",
    "\n",
    "1. `save_format` argument: Set the value to `save_format=\"tf\"` or `save_format=\"h5\"`.\n",
    "2. `path` argument: If the path ends with `.h5` or `.hdf5`, then the HDF5 format is used. Other suffixes will result in a TensorFlow checkpoint unless `save_format` is set.\n",
    "\n",
    "There is also an option of retrieving weights as in-memory numpy arrays. Each API has its pros and cons which are detailed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=maroon>TF Checkpoint format</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x195646df070>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Runnable example\n",
    "sequential_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,), name=\"digits\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        keras.layers.Dense(10, name=\"predictions\"),\n",
    "    ])\n",
    "\n",
    "sequential_model.save_weights(\"save_model/2_5_try5_ckpt/ckpt\")\n",
    "load_status = sequential_model.load_weights(\"save_model/2_5_try5_ckpt/ckpt\")\n",
    "\n",
    "# `assert_consumed` can be used as validation that all variable values have been restored from the checkpoint. \n",
    "# See `tf.train.Checkpoint.restore` for other methods in the Status object.\n",
    "load_status.assert_consumed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format details\n",
    "\n",
    "The TensorFlow Checkpoint format saves and restores the weights using object attribute names. For instance, consider the `tf.keras.layers.Dense` layer. The layer contains two weights: `dense.kernel` and `dense.bias`. When the layer is saved to the `tf` format, the resulting checkpoint contains the keys\n",
    "`\"kernel\"` and `\"bias\"` and their corresponding weight values.\n",
    "For more information see [\"Loading mechanics\" in the TF Checkpoint guide](https://www.tensorflow.org/guide/checkpoint#loading_mechanics).\n",
    "\n",
    "<font size=3 color=maroon>**Note that** attribute/graph edge is named after **the name used in parent object, not the name of the variable**. Consider the `CustomLayer` in the example below. The variable `CustomLayer.var` is saved with `\"var\"` as part of key, not `\"var_a\"`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_CHECKPOINTABLE_OBJECT_GRAPH': tf.string,\n",
       " 'layer/var/.ATTRIBUTES/VARIABLE_VALUE': tf.int32,\n",
       " 'save_counter/.ATTRIBUTES/VARIABLE_VALUE': tf.int64}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomLayer(keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "\n",
    "layer = CustomLayer(5)\n",
    "layer_ckpt = tf.train.Checkpoint(layer=layer).save(\"save_model/2_5_try6_var-ckpt/custom_layer\")\n",
    "\n",
    "ckpt_reader = tf.train.load_checkpoint(layer_ckpt)\n",
    "\n",
    "ckpt_reader.get_variable_to_dtype_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer learning example\n",
    "\n",
    "<font size=3 color=maroon>Essentially, as long as two models have the same architecture, they are able to share the same checkpoint.</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pretrained_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " digits (InputLayer)         [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,400\n",
      "Trainable params: 54,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "Model: \"new_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " digits (InputLayer)         [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      " --------------------------------------------------------------------------------\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pretrained (Functional)     (None, 64)                54400     \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1956694d970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "# Extract a portion of the functional model defined in the Setup section.\n",
    "# The following lines produce a new model that excludes the final output layer of the functional model.\n",
    "pretrained = keras.Model(functional_model.inputs, \n",
    "                         functional_model.layers[-1].input, \n",
    "                         name=\"pretrained_model\")\n",
    "\n",
    "# Randomly assign \"trained\" weights.\n",
    "for w in pretrained.weights:\n",
    "    w.assign(tf.random.normal(w.shape))\n",
    "pretrained.save_weights(\"save_model/2_5_try7_transfer-learning-ckpt/pretrained_ckpt\")\n",
    "pretrained.summary()\n",
    "print(\"\\n\\n\", \"-\" * 80)\n",
    "\n",
    "\n",
    "# Assume this is a separate program where only 'pretrained_ckpt' exists.\n",
    "# Create a new functional model with a different output dimension.\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = keras.layers.Dense(5, name=\"predictions\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"new_model\")\n",
    "\n",
    "# Load the weights from pretrained_ckpt into model.\n",
    "model.load_weights(\"save_model/2_5_try7_transfer-learning-ckpt/pretrained_ckpt\")\n",
    "\n",
    "# Check that all of the pretrained weights have been loaded.\n",
    "for a, b in zip(pretrained.weights, model.weights):\n",
    "    np.testing.assert_allclose(a.numpy(), b.numpy())\n",
    "\n",
    "model.summary()\n",
    "print(\"\\n\\n\", \"-\" * 80)\n",
    "\n",
    "\n",
    "\n",
    "# Example 2: Sequential model\n",
    "# Recreate the pretrained model, and load the saved weights.\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "pretrained_model = keras.Model(inputs=inputs, outputs=x, name=\"pretrained\")\n",
    "\n",
    "# Sequential example:\n",
    "model = keras.Sequential([pretrained_model, \n",
    "                          keras.layers.Dense(5, name=\"predictions\")\n",
    "                         ])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "pretrained_model.load_weights(\"save_model/2_5_try7_transfer-learning-ckpt/pretrained_ckpt\")\n",
    "\n",
    "# Warning! Calling `model.load_weights('pretrained_ckpt')` won't throw an error, but will *not* work as expected. \n",
    "# If you inspect the weights, you'll see that none of the weights will have loaded. \n",
    "# `pretrained_model.load_weights()` is the correct method to call.\n",
    "# \n",
    "# 因为 pretrained_model 在 sequential model 当中，它对应的那一层为 pretrained (Functional)，被当作了 functional。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>**It is generally recommended to stick to the same API for building models.** If you switch between Sequential and Functional, or Functional and subclassed, etc., then always rebuild the pre-trained model and load the pre-trained weights to that model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>The next question is, how can weights be saved and loaded to **different models** if the model architectures are quite different?\n",
    "\n",
    "The solution is to use `tf.train.Checkpoint` to save and restore the exact layers/variables.</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_9556/2484022631.py:15: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.kernel = self.add_variable(\"kernel\", shape=(64, 10))\n",
      "C:\\Users\\18617\\AppData\\Local\\Temp/ipykernel_9556/2484022631.py:16: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.bias = self.add_variable(\"bias\", shape=(10,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1956f6959a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a subclassed model that essentially uses functional_model's first and last layers.\n",
    "# First, save the weights of functional_model's first and last dense layers.\n",
    "first_dense = functional_model.layers[1]\n",
    "last_dense = functional_model.layers[-1]\n",
    "ckpt_path = tf.train.Checkpoint(dense=first_dense, \n",
    "                                kernel=last_dense.kernel, \n",
    "                                bias=last_dense.bias)   \\\n",
    "                    .save(\"save_model/2_5_try8_different-models-ckpt/ckpt\")\n",
    "\n",
    "# Define the subclassed model.\n",
    "class ContrivedModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ContrivedModel, self).__init__()\n",
    "        self.first_dense = keras.layers.Dense(64)\n",
    "        self.kernel = self.add_variable(\"kernel\", shape=(64, 10))\n",
    "        self.bias = self.add_variable(\"bias\", shape=(10,))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.first_dense(inputs)\n",
    "        return tf.matmul(x, self.kernel) + self.bias\n",
    "\n",
    "\n",
    "model = ContrivedModel()\n",
    "# Call model on inputs to create the variables of the dense layer.\n",
    "_ = model(tf.ones((1, 784)))\n",
    "\n",
    "# Create a Checkpoint with the same structure as before, and load the weights.\n",
    "tf.train.Checkpoint(dense=model.first_dense, \n",
    "                    kernel=model.kernel, \n",
    "                    bias=model.bias).restore(ckpt_path).assert_consumed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=maroon>HDF5 format</font>\n",
    "\n",
    "<font size=3 color=maroon>The HDF5 format contains weights grouped by layer names. The weights are lists ordered by concatenating the list of trainable weights to the list of non-trainable weights (same as `layer.weights`).\n",
    "Thus, a model can use a hdf5 checkpoint if it has the same layers and trainable statuses as saved in the checkpoint.</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnable example\n",
    "sequential_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,), name=\"digits\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        keras.layers.Dense(10, name=\"predictions\"),\n",
    "    ])\n",
    "\n",
    "# 需要先在路径 ./save_model 下创建文件夹 2_5_try9_h5\n",
    "sequential_model.save_weights(\"save_model/2_5_try9_h5/weights.h5\")\n",
    "sequential_model.load_weights(\"save_model/2_5_try9_h5/weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>Note that changing `layer.trainable` may result in a different `layer.weights` ordering when the model contains **nested layers**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables: ['nested/dense_1/kernel:0', 'nested/dense_1/bias:0', 'nested/dense_2/kernel:0', 'nested/dense_2/bias:0']\n",
      "\n",
      "\n",
      "Changing trainable status of one of the nested layers...\n",
      "\n",
      "\n",
      "variables: ['nested/dense_2/kernel:0', 'nested/dense_2/bias:0', 'nested/dense_1/kernel:0', 'nested/dense_1/bias:0']\n",
      "variable ordering changed: True\n"
     ]
    }
   ],
   "source": [
    "class NestedDenseLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, name=None):\n",
    "        super(NestedDenseLayer, self).__init__(name=name)\n",
    "        self.dense_1 = keras.layers.Dense(units, name=\"dense_1\")\n",
    "        self.dense_2 = keras.layers.Dense(units, name=\"dense_2\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense_2(self.dense_1(inputs))\n",
    "\n",
    "\n",
    "nested_model = keras.Sequential([keras.Input((784,)), NestedDenseLayer(10, \"nested\")])\n",
    "variable_names = [v.name for v in nested_model.weights]\n",
    "print(\"variables: {}\".format(variable_names))\n",
    "print()\n",
    "\n",
    "print(\"\\nChanging trainable status of one of the nested layers...\")\n",
    "nested_model.get_layer(\"nested\").dense_1.trainable = False\n",
    "print()\n",
    "\n",
    "variable_names_2 = [v.name for v in nested_model.weights]\n",
    "print(\"\\nvariables: {}\".format(variable_names_2))\n",
    "print(\"variable ordering changed:\", variable_names != variable_names_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer learning example\n",
    "\n",
    "<font size=3 color=maroon>When loading pretrained weights from HDF5, it is recommended to load the weights into the original checkpointed model, and then extract the desired weights/layers into a new model.</font>\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,725\n",
      "Trainable params: 54,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_functional_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"3_layer_mlp\")\n",
    "\n",
    "\n",
    "functional_model = create_functional_model()\n",
    "functional_model.save_weights(\"save_model/2_5_try10_transfer-learning-h5/pretrained_weights.h5\")\n",
    "# 需要先在路径 ./save_model 下创建文件夹 2_5_try10_transfer-learning-h5\n",
    "\n",
    "# In a separate program:\n",
    "pretrained_model = create_functional_model()\n",
    "pretrained_model.load_weights(\"save_model/2_5_try10_transfer-learning-h5/pretrained_weights.h5\")\n",
    "\n",
    "# Create a new model by extracting layers from the original model:\n",
    "extracted_layers = pretrained_model.layers[:-1]\n",
    "extracted_layers.append(keras.layers.Dense(5, name=\"dense_3\"))\n",
    "model = keras.Sequential(extracted_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfg]",
   "language": "python",
   "name": "conda-env-tfg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "311px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
