{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><font color=maroon size=6><b>Load a pandas DataFrame</b></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>References:</b></font>\n",
    "1. TF2 official tutorials: <a href=\"https://www.tensorflow.org/tutorials\" style=\"text-decoration:none;\">TensorFlow Tutorials</a> \n",
    "    * `TensorFlow > Learn > TensorFlow Core > `Tutorials > <a href=\"https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\" style=\"text-decoration:none;\">Load a pandas DataFrame</a>\n",
    "        * Run in <a href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/pandas_dataframe.ipynb\" style=\"text-decoration:none;\">Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides examples of how to load <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\" class=\"external\">pandas DataFrames</a> into TensorFlow.\n",
    "\n",
    "You will use a small <a href=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\" class=\"external\">heart disease dataset</a> provided by the UCI Machine Learning Repository. There are several hundred rows in the CSV. Each row describes a patient, and each column describes an attribute. You will use this information to predict whether a patient has heart disease, which is a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 500\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the CSV file containing the heart disease dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tf.keras.utils.get_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = tf.keras.utils.get_file('heart.csv', \n",
    "                                   'https://storage.googleapis.com/download.tensorflow.org/data/heart.csv',\n",
    "                                   cache_dir=\"D:/KeepStudy/0_Coding\",\n",
    "                                   cache_subdir=\"0_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV file using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal         object\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will build models to predict the label contained in the `target` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.pop('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A DataFrame as an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>If your data has a uniform datatype, or `dtype`, it's possible to use a pandas DataFrame anywhere you could use a NumPy array. This works because the `pandas.DataFrame` class supports the `__array__` protocol, and TensorFlow's `tf.convert_to_tensor` function accepts objects that support the protocol.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the numeric features from the dataset (skip the categorical features for now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>thalach</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>150</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>108</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>129</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>187</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>172</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  thalach  trestbps  chol  oldpeak\n",
       "0   63      150       145   233      2.3\n",
       "1   67      108       160   286      1.5\n",
       "2   67      129       120   229      2.6\n",
       "3   37      187       130   250      3.5\n",
       "4   41      172       130   204      1.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feature_names = ['age', 'thalach', 'trestbps',  'chol', 'oldpeak']\n",
    "numeric_features = df[numeric_feature_names]\n",
    "numeric_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>The DataFrame can be converted to a NumPy array using the `DataFrame.values` property or `numpy.array(df)`. To convert it to a tensor, use `tf.convert_to_tensor`:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(303, 5), dtype=float64, numpy=\n",
       "array([[ 63. , 150. , 145. , 233. ,   2.3],\n",
       "       [ 67. , 108. , 160. , 286. ,   1.5],\n",
       "       [ 67. , 129. , 120. , 229. ,   2.6],\n",
       "       ...,\n",
       "       [ 65. , 127. , 135. , 254. ,   2.8],\n",
       "       [ 48. , 150. , 130. , 256. ,   0. ],\n",
       "       [ 63. , 154. , 150. , 407. ,   4. ]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, if an object can be converted to a tensor with `tf.convert_to_tensor` it can be passed anywhere you can pass a `tf.Tensor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>A DataFrame, interpreted as a single tensor, can be used directly as an argument to the `Model.fit` method.</font>\n",
    "\n",
    "Below is an example of training a model on the numeric features of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>The first step is to normalize the input ranges. Use a `tf.keras.layers.Normalization` layer for that.\n",
    "\n",
    "To set the layer's mean and standard-deviation before running it be sure to call the `Normalization.adapt` method:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)\n",
    "normalizer.adapt(numeric_features)   # 这个相当于是在训练 normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the layer on the first three rows of the DataFrame to visualize an example of the output from this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[ 0.93383914,  0.03480718,  0.74578077, -0.26008663,  1.0680453 ],\n",
       "       [ 1.3782105 , -1.7806165 ,  1.5923285 ,  0.7573877 ,  0.38022864],\n",
       "       [ 1.3782105 , -0.87290466, -0.6651321 , -0.33687714,  1.3259765 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer(numeric_features.iloc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the normalization layer as the first layer of a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_model():\n",
    "    model = tf.keras.Sequential([normalizer,\n",
    "                                 tf.keras.layers.Dense(10, activation='relu'),\n",
    "                                 tf.keras.layers.Dense(10, activation='relu'),\n",
    "                                 tf.keras.layers.Dense(1)\n",
    "                                ])\n",
    "\n",
    "  \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>When you pass the DataFrame as the `x` argument to `Model.fit`, Keras treats the DataFrame as it would a NumPy array:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "152/152 [==============================] - 2s 3ms/step - loss: 0.6292 - accuracy: 0.7261\n",
      "Epoch 2/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7261\n",
      "Epoch 3/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7261\n",
      "Epoch 4/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7261\n",
      "Epoch 5/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7327\n",
      "Epoch 6/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7591\n",
      "Epoch 7/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7624\n",
      "Epoch 8/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7756\n",
      "Epoch 9/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7921\n",
      "Epoch 10/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7855\n",
      "Epoch 11/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7888\n",
      "Epoch 12/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7987\n",
      "Epoch 13/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7921\n",
      "Epoch 14/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8053\n",
      "Epoch 15/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e422f85ca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_basic_model()\n",
    "\n",
    "model.fit(numeric_features, target, epochs=15, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to apply `tf.data` transformations to a DataFrame of a uniform `dtype`, <font size=3 color=maroon>the `Dataset.from_tensor_slices` method will create a dataset that **iterates over the rows of the DataFrame. Each row is initially a vector of values**.</font> \n",
    "\n",
    "To train a model, you need `(inputs, labels)` pairs, so pass `(features, labels)` and `Dataset.from_tensor_slices` will return the needed pairs of slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(5,), dtype=float64, numpy=array([ 63. , 150. , 145. , 233. ,   2.3])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(5,), dtype=float64, numpy=array([ 67. , 108. , 160. , 286. ,   1.5])>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(5,), dtype=float64, numpy=array([ 67. , 129. , 120. , 229. ,   2.6])>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "numeric_dataset = tf.data.Dataset.from_tensor_slices((numeric_features, target))\n",
    "\n",
    "for row in numeric_dataset.take(3):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_dataset.numpy()\n",
    "#\n",
    "# 报错：AttributeError: 'TensorSliceDataset' object has no attribute 'numpy'\n",
    "\n",
    "\n",
    "\n",
    "# type(numeric_dataset.take(3))\n",
    "#\n",
    "# tensorflow.python.data.ops.dataset_ops.TakeDataset\n",
    "\n",
    "\n",
    "\n",
    "# tf.convert_to_tensor(numeric_dataset.take(3))\n",
    "#\n",
    "# 报错：ValueError: Attempt to convert a value (<TakeDataset shapes: ((5,), ()), types: (tf.float64, tf.int64)>) \n",
    "# with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.TakeDataset'>) to a Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "152/152 [==============================] - 1s 3ms/step - loss: 0.7419 - accuracy: 0.6601\n",
      "Epoch 2/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7261\n",
      "Epoch 3/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7261\n",
      "Epoch 4/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7261\n",
      "Epoch 5/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7261\n",
      "Epoch 6/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7294\n",
      "Epoch 7/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7591\n",
      "Epoch 8/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7624\n",
      "Epoch 9/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7756\n",
      "Epoch 10/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7888\n",
      "Epoch 11/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7822\n",
      "Epoch 12/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7921\n",
      "Epoch 13/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7921\n",
      "Epoch 14/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7921\n",
      "Epoch 15/15\n",
      "152/152 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e43d9ec5b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_batches = numeric_dataset.shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "model = get_basic_model()\n",
    "model.fit(numeric_batches, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A DataFrame as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>When you start dealing with `heterogeneous (由很多种类组成的；各种各样的) data`, it is no longer possible to treat the DataFrame as if it were a single array. TensorFlow tensors require that all elements have the same `dtype`.\n",
    "\n",
    "So, in this case, you need to start treating it as **a dictionary of columns, where each column has a uniform `dtype`**. <br><br>\n",
    "A DataFrame is a lot like a dictionary of arrays, so typically all you need to do is cast the DataFrame to a Python dict. Many important TensorFlow APIs support (nested-)dictionaries of arrays as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.data` input pipelines handle this quite well. <font size=3 color=maroon>All `tf.data` operations handle dictionaries and tuples automatically.</font> So, to make a dataset of dictionary-examples from a DataFrame, just cast it to a dict before slicing it with `Dataset.from_tensor_slices`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0      63\n",
       " 1      67\n",
       " 2      67\n",
       " 3      37\n",
       " 4      41\n",
       "        ..\n",
       " 298    52\n",
       " 299    43\n",
       " 300    65\n",
       " 301    48\n",
       " 302    63\n",
       " Name: age, Length: 303, dtype: int64,\n",
       " 'thalach': 0      150\n",
       " 1      108\n",
       " 2      129\n",
       " 3      187\n",
       " 4      172\n",
       "       ... \n",
       " 298    190\n",
       " 299    136\n",
       " 300    127\n",
       " 301    150\n",
       " 302    154\n",
       " Name: thalach, Length: 303, dtype: int64,\n",
       " 'trestbps': 0      145\n",
       " 1      160\n",
       " 2      120\n",
       " 3      130\n",
       " 4      130\n",
       "       ... \n",
       " 298    118\n",
       " 299    132\n",
       " 300    135\n",
       " 301    130\n",
       " 302    150\n",
       " Name: trestbps, Length: 303, dtype: int64,\n",
       " 'chol': 0      233\n",
       " 1      286\n",
       " 2      229\n",
       " 3      250\n",
       " 4      204\n",
       "       ... \n",
       " 298    186\n",
       " 299    341\n",
       " 300    254\n",
       " 301    256\n",
       " 302    407\n",
       " Name: chol, Length: 303, dtype: int64,\n",
       " 'oldpeak': 0      2.3\n",
       " 1      1.5\n",
       " 2      2.6\n",
       " 3      3.5\n",
       " 4      1.4\n",
       "       ... \n",
       " 298    0.0\n",
       " 299    3.0\n",
       " 300    2.8\n",
       " 301    0.0\n",
       " 302    4.0\n",
       " Name: oldpeak, Length: 303, dtype: float64}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_dict_ds = tf.data.Dataset.from_tensor_slices((dict(numeric_features), target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first three examples from that dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'age': <tf.Tensor: shape=(), dtype=int64, numpy=63>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=150>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=145>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=233>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=2.3>}, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "\n",
      "({'age': <tf.Tensor: shape=(), dtype=int64, numpy=67>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=108>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=160>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=286>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=1.5>}, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "\n",
      "({'age': <tf.Tensor: shape=(), dtype=int64, numpy=67>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=129>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=120>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=229>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=2.6>}, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in numeric_dict_ds.take(3):\n",
    "    print(row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>Typically, Keras models and layers expect a single input tensor, but these classes can accept and return nested structures of dictionaries, tuples and tensors. These structures are known as \"nests\" (refer to the `tf.nest` module for details).</font>\n",
    "\n",
    "There are two equivalent ways you can write a Keras model that accepts a dictionary as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Model-subclass style\n",
    "\n",
    "You write a subclass of `tf.keras.Model` (or `tf.keras.Layer`). You directly handle the inputs, and create the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dict(inputs, fun=tf.stack):\n",
    "    values = []\n",
    "    for key in sorted(inputs.keys()):\n",
    "        values.append(tf.cast(inputs[key], tf.float32))\n",
    "    \n",
    "    return fun(values, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        # Create all the internal layers in init.\n",
    "        super().__init__(self)\n",
    "        \n",
    "        self.normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)\n",
    "        \n",
    "        self.seq = tf.keras.Sequential([self.normalizer,\n",
    "                                        tf.keras.layers.Dense(10, activation='relu'),\n",
    "                                        tf.keras.layers.Dense(10, activation='relu'),\n",
    "                                        tf.keras.layers.Dense(1)\n",
    "                                       ])\n",
    "        \n",
    "    def adapt(self, inputs):\n",
    "        # Stack the inputs and `adapt` the normalization layer.\n",
    "        inputs = stack_dict(inputs)\n",
    "        self.normalizer.adapt(inputs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Stack the inputs\n",
    "        inputs = stack_dict(inputs)\n",
    "        # Run them through all the layers.\n",
    "        result = self.seq(inputs)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "model.adapt(dict(numeric_features))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can accept either a dictionary of columns or a dataset of dictionary-elements for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "152/152 [==============================] - 2s 13ms/step - loss: 0.6327 - accuracy: 0.7393\n",
      "Epoch 2/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.5320 - accuracy: 0.7327\n",
      "Epoch 3/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4816 - accuracy: 0.7492\n",
      "Epoch 4/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4578 - accuracy: 0.7492\n",
      "Epoch 5/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4472 - accuracy: 0.7690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e4252d17f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dict(numeric_features), target, epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4381 - accuracy: 0.7789\n",
      "Epoch 2/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4348 - accuracy: 0.7855\n",
      "Epoch 3/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4323 - accuracy: 0.7888\n",
      "Epoch 4/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4306 - accuracy: 0.8020\n",
      "Epoch 5/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4287 - accuracy: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6c1700a30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_dict_batches = numeric_dict_ds.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "model.fit(numeric_dict_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictions for the first three examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.05580579]],\n",
       "\n",
       "       [[ 0.7148901 ]],\n",
       "\n",
       "       [[ 0.1741641 ]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dict(numeric_features.iloc[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Keras functional style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'thalach': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'thalach')>,\n",
       " 'trestbps': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'trestbps')>,\n",
       " 'chol': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'chol')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'oldpeak')>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "for name, col in numeric_features.items():\n",
    "    inputs[name] = tf.keras.Input(shape=(1,),\n",
    "                                  name=name,\n",
    "                                  dtype=tf.float32)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'tf.concat')>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = stack_dict(inputs, fun=tf.concat)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 5) dtype=float32 (created by layer 'tf.stack')>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = stack_dict(inputs)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=1)\n",
    "normalizer.adapt(stack_dict(dict(numeric_features)))\n",
    "\n",
    "x = normalizer(x)\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, x)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, rankdir=\"LR\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载 Colab 的运行结果图：\n",
    "\n",
    "\n",
    "<img src=\"./images/dataframe_plot_model.png\" width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can train the functional model the same way as the model subclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.6122 - accuracy: 0.7360\n",
      "Epoch 2/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.5462 - accuracy: 0.7327\n",
      "Epoch 3/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.5050 - accuracy: 0.7393\n",
      "Epoch 4/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4770 - accuracy: 0.7492\n",
      "Epoch 5/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4606 - accuracy: 0.7624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6c91a57f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dict(numeric_features), target, epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4497 - accuracy: 0.7657\n",
      "Epoch 2/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4433 - accuracy: 0.7657\n",
      "Epoch 3/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4391 - accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4375 - accuracy: 0.7789\n",
      "Epoch 5/5\n",
      "152/152 [==============================] - 2s 12ms/step - loss: 0.4351 - accuracy: 0.7723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6c1700a90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_dict_batches = numeric_dict_ds.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "model.fit(numeric_dict_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're passing a heterogeneous DataFrame to Keras, each column may need unique preprocessing. You could do this preprocessing directly in the DataFrame, but for a model to work correctly, inputs always need to be preprocessed the same way. So, the best approach is to build the preprocessing into the model. [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) cover many common tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the preprocessing head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset some of the \"integer\" features in the raw data are actually Categorical indices. These indices are not really ordered numeric values (refer to the <a href=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\" class=\"external\">the dataset description</a> for details). \n",
    "\n",
    "<font size=3 color=maroon>Because these are unordered they are inappropriate to feed directly to the model; the model would interpret them as being ordered. To use these inputs you'll need to encode them, either as one-hot vectors or embedding vectors. The same applies to string-categorical features.</font>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<font size=4 color=maroon>**Note**:</font> \n",
    "\n",
    "* If you have many features that need identical preprocessing it's more efficient to concatenate them together before applying the preprocessing.\n",
    "\n",
    "* Binary features on the other hand do not generally need to be encoded or normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by by creating a list of the features that fall into each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_feature_names = ['sex', 'fbs', 'exang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_names = ['cp', 'restecg', 'slope', 'thal', 'ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to build a preprocessing model that will apply appropriate preprocessing to each input and concatenate the results.\n",
    "\n",
    "This section uses the [Keras Functional API](https://www.tensorflow.org/guide/keras/functional) to implement  the preprocessing. You start by creating one `tf.keras.Input` for each column of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "for name, column in df.items():\n",
    "    if type(column[0]) == str:\n",
    "        dtype = tf.string\n",
    "    elif (name in categorical_feature_names or name in binary_feature_names):\n",
    "        dtype = tf.int64\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "\n",
    "    inputs[name] = tf.keras.Input(shape=(), name=name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'age')>,\n",
       " 'sex': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'sex')>,\n",
       " 'cp': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'cp')>,\n",
       " 'trestbps': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'trestbps')>,\n",
       " 'chol': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'chol')>,\n",
       " 'fbs': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'fbs')>,\n",
       " 'restecg': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'restecg')>,\n",
       " 'thalach': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'thalach')>,\n",
       " 'exang': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'exang')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'oldpeak')>,\n",
       " 'slope': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'slope')>,\n",
       " 'ca': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'ca')>,\n",
       " 'thal': <KerasTensor: shape=(None,) dtype=string (created by layer 'thal')>}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=maroon size=3>For each input you'll apply some transformations using Keras layers and TensorFlow ops. Each feature starts as a batch of scalars (`shape=(batch,)`). The output for each  should be a batch of `tf.float32` vectors (`shape=(batch, n)`). The last step will concatenate all those vectors together.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary inputs\n",
    "\n",
    "<font color=maroon size=3>Since the binary inputs don't need any preprocessing, just add the vector axis, cast them to `float32` and add them to the list of preprocessed inputs:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_10')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_11')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_12')>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = []\n",
    "\n",
    "for name in binary_feature_names:\n",
    "    inp = inputs[name]\n",
    "    inp = inp[:, tf.newaxis]\n",
    "    float_value = tf.cast(inp, tf.float32)\n",
    "    preprocessed.append(float_value)\n",
    "\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric inputs\n",
    "\n",
    "Like in the earlier section you'll want to run these numeric inputs through a `tf.keras.layers.Normalization` layer before using them. The difference is that this time they're input as a dict. The code below collects the numeric features from the DataFrame, stacks them together and passes those to the `Normalization.adapt` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)\n",
    "normalizer.adapt(stack_dict(dict(numeric_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below stacks the numeric features and runs them through the normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_10')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_11')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_12')>,\n",
       " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'normalization_3')>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {}\n",
    "for name in numeric_feature_names:\n",
    "    numeric_inputs[name]=inputs[name]\n",
    "\n",
    "numeric_inputs = stack_dict(numeric_inputs)\n",
    "numeric_normalized = normalizer(numeric_inputs)\n",
    "\n",
    "preprocessed.append(numeric_normalized)\n",
    "\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use categorical features you'll first need to encode them into either binary vectors or embeddings. Since these features only contain a small number of categories, convert the inputs directly to one-hot vectors using the `output_mode='one_hot'` option, supported by both the `tf.keras.layers.StringLookup` and `tf.keras.layers.IntegerLookup` layers.\n",
    "\n",
    "Here is an example of how these layers work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = ['a','b','c']\n",
    "# lookup = tf.keras.layers.StringLookup(vocabulary=vocab, \n",
    "#                                       output_mode='one_hot')\n",
    "#\n",
    "# lookup(['c','a','a','b','zzz'])\n",
    "# 报错：AttributeError: module 'tensorflow.keras.layers' has no attribute 'StringLookup'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tf.keras.layers.experimental.preprocessing.StringLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = ['a','b','c']\n",
    "# lookup = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=vocab, \n",
    "#                                                                  output_mode='one_hot')\n",
    "#\n",
    "# lookup(['c','a','a','b','zzz'])\n",
    "# 报错：ValueError: The output_mode argument of layer StringLookup received an invalid value one_hot. \n",
    "# Allowed values are: or one of the following values: ('int', 'binary', 'count', 'tf-idf').\n",
    "# 但是上述 output_mode 的 value 并没有 one-hot 类型的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个 cell 的参考链接：\n",
    "# https://www.tensorflow.org/guide/migrate/migrating_feature_columns#one-hot_encoding_string_data_with_a_vocabulary\n",
    "\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "\n",
    "def call_feature_columns(feature_columns, inputs):\n",
    "    # This is a convenient way to call a `feature_column` outside of an estimator to display its output.\n",
    "    feature_layer = tf1.keras.layers.DenseFeatures(feature_columns)\n",
    "    \n",
    "    return feature_layer(inputs)\n",
    "\n",
    "\n",
    "vocab_col = tf1.feature_column \\\n",
    "               .categorical_column_with_vocabulary_list('my_try',\n",
    "                                                        vocabulary_list=['a','b','c'],\n",
    "                                                        num_oov_buckets=2)\n",
    "\n",
    "indicator_col = tf1.feature_column.indicator_column(vocab_col)\n",
    "call_feature_columns(indicator_col, {'my_try': ['c','a','a','b','zzz']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tf1.feature_column.categorical_column_with_vocabulary_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = [1,4,7,99]\n",
    "# lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "# lookup([-1,4,1])\n",
    "\n",
    "# 与上面同样的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tf1.feature_column.categorical_column_with_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这个 cell 的参考链接：\n",
    "# https://www.tensorflow.org/guide/migrate/migrating_feature_columns#one-hot_encoding_integer_ids\n",
    "\n",
    "\n",
    "categorical_col = tf1.feature_column \\\n",
    "                     .categorical_column_with_identity('my_try', num_buckets=10, default_value=9)\n",
    "\n",
    "indicator_col = tf1.feature_column.indicator_column(categorical_col)\n",
    "call_feature_columns(indicator_col, {'my_try': [1,4,7,99]})\n",
    "\n",
    "#vocab = [1,4,7,99]\n",
    "#lookup = tf.keras.layers.experimental.preprocessing.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "#\n",
    "#lookup([-1,4,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for name in categorical_feature_names:\n",
    "    vocab = sorted(set(df[name]))\n",
    "    print(f'name: {name}')\n",
    "    print(f'vocab: {vocab}\\n')\n",
    "\n",
    "    if type(vocab[0]) is str:\n",
    "        lookup = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "    else:\n",
    "        lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "\n",
    "    x = inputs[name][:, tf.newaxis]\n",
    "    x = lookup(x)\n",
    "    preprocessed.append(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: cp\n",
      "vocab: [0, 1, 2, 3, 4]\n",
      "进入 integer\n",
      "\n",
      "name: restecg\n",
      "vocab: [0, 1, 2]\n",
      "进入 integer\n",
      "\n",
      "name: slope\n",
      "vocab: [1, 2, 3]\n",
      "进入 integer\n",
      "\n",
      "name: thal\n",
      "vocab: ['1', '2', 'fixed', 'normal', 'reversible']\n",
      "进入 string\n",
      "\n",
      "name: ca\n",
      "vocab: [0, 1, 2, 3]\n",
      "进入 integer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 平平自己编写\n",
    "p = []\n",
    "for name in categorical_feature_names:\n",
    "    vocab = sorted(set(df[name]))\n",
    "    print(f'name: {name}')\n",
    "    print(f'vocab: {vocab}')\n",
    "\n",
    "    if type(vocab[0]) is str:\n",
    "        print(\"进入 string\")\n",
    "        # lookup = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "        \n",
    "        key = 'string'\n",
    "        string_col = tf1.feature_column \\\n",
    "                       .categorical_column_with_vocabulary_list('string',\n",
    "                                                                vocabulary_list=vocab,\n",
    "                                                                num_oov_buckets=1)\n",
    "\n",
    "        indicator_col = tf1.feature_column.indicator_column(string_col)\n",
    "        # call_feature_columns(indicator_col, {'string': vocab})\n",
    "    else:\n",
    "        print(\"进入 integer\")\n",
    "        # lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "        \n",
    "        key = 'integer'\n",
    "        integer_col = tf1.feature_column \\\n",
    "                             .categorical_column_with_identity('integer',\n",
    "                                                               num_buckets=len(vocab)+1)\n",
    "\n",
    "        indicator_col = tf1.feature_column.indicator_column(integer_col)\n",
    "        # call_feature_columns(indicator_col, {'integer': vocab})\n",
    "\n",
    "\n",
    "    x = inputs[name][:, tf.newaxis]\n",
    "    # x = lookup(x)\n",
    "    # x = call_feature_columns(indicator_col, {key: vocab})\n",
    "    x = tf1.keras.layers.DenseFeatures(indicator_col)\n",
    "    p.append(x)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.feature_column.dense_features.DenseFeatures at 0x1e6e09bd0d0>,\n",
       " <tensorflow.python.keras.feature_column.dense_features.DenseFeatures at 0x1e6e0925ca0>,\n",
       " <tensorflow.python.keras.feature_column.dense_features.DenseFeatures at 0x1e43d9c92b0>,\n",
       " <tensorflow.python.keras.feature_column.dense_features.DenseFeatures at 0x1e6e08dc6d0>,\n",
       " <tensorflow.python.keras.feature_column.dense_features.DenseFeatures at 0x1e6e0936f10>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>从上面的输出看，变量 preprocessed 的最后几个元素都不是 Tensor 类型，不能通过后续的处理，所以通过 tf1.feature_column 的方法来进行 one-hot encoding 对于本 notebook 索要解决的问题来说，并不适用。\n",
    "\n",
    "只能另求他法。如下：</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([4, 2, 2, 3, 1], dtype=int64)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['a','b','c']\n",
    "lookup = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=vocab, \n",
    "                                                                 output_mode='int')\n",
    "\n",
    "lookup(['c','a','a','b','zzz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['a','b','c']\n",
    "lookup = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=vocab, \n",
    "                                                                 output_mode='int')\n",
    "\n",
    "# arr = lookup(['c','a','a','b','zzz']).numpy()    # 这句也可以\n",
    "arr = lookup(np.array(['c','a','a','b','zzz'])).numpy()\n",
    "d1 = arr.shape[0]\n",
    "d2 = max(len(set(vocab)), len(set(arr)))\n",
    "z = np.zeros((d1, d2))\n",
    "z[range(d1), arr-1] = 1\n",
    "tf.convert_to_tensor(z, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tf.keras.layers.experimental.preprocessing.StringLookup)\n",
    "# help(tf.keras.layers.experimental.preprocessing.IntegerLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = [1,4,7,99]\n",
    "# lookup = tf.keras.layers.experimental.preprocessing.IntegerLookup(vocabulary=vocab,\n",
    "#                                                                   output_mode='int')\n",
    "# \n",
    "# lookup([-1,4,1])\n",
    "#\n",
    "# lookup([-1,4,1]) 这一句报错：AttributeError: 'list' object has no attribute 'dtype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = [1,4,7,99]\n",
    "# vocab = np.array(vocab)\n",
    "lookup = tf.keras.layers.experimental.preprocessing.IntegerLookup(vocabulary=vocab,\n",
    "                                                                  output_mode='int')\n",
    "\n",
    "# lookup(np.array([-1,4,1]))\n",
    "\n",
    "arr = lookup(np.array([-1,4,1])).numpy()\n",
    "\n",
    "d1 = arr.shape[0]\n",
    "d2 = max(len(set(vocab)), len(set(vocab)|set([-1,4,1])))\n",
    "z = np.zeros((d1, d2))\n",
    "z[range(d1), arr-1] = 1\n",
    "tf.convert_to_tensor(z, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(2, 2) dtype=int32 (created by layer 'c_ki')>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.constant([[1,2],[3,4]])\n",
    "\n",
    "c_ki = tf.keras.Input(tensor=c, name='c_ki')\n",
    "c_ki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KerasTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18396/3429371275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc_ki\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'KerasTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "c_ki(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp', 'restecg', 'slope', 'thal', 'ca']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'age')>,\n",
       " 'sex': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'sex')>,\n",
       " 'cp': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'cp')>,\n",
       " 'trestbps': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'trestbps')>,\n",
       " 'chol': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'chol')>,\n",
       " 'fbs': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'fbs')>,\n",
       " 'restecg': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'restecg')>,\n",
       " 'thalach': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'thalach')>,\n",
       " 'exang': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'exang')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'oldpeak')>,\n",
       " 'slope': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'slope')>,\n",
       " 'ca': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'ca')>,\n",
       " 'thal': <KerasTensor: shape=(None,) dtype=string (created by layer 'thal')>}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2 = {}\n",
    "for name, column in df.items():\n",
    "    if type(column[0]) == str:\n",
    "        dtype = tf.string\n",
    "    elif (name in categorical_feature_names or name in binary_feature_names):\n",
    "        dtype = tf.int64\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "\n",
    "    inputs2[name] = tf.keras.Input(shape=(), name=name, dtype=dtype)\n",
    "\n",
    "inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: cp\n",
      "vocab: [0, 1, 2, 3, 4]\n",
      "进入 int\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.int64, name='cp'), name='cp', description=\"created by layer 'cp'\")\n",
      "<dtype: 'int64'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), name='integer_lookup_43/None_lookup_table_find/LookupTableFindV2:0', description=\"created by layer 'integer_lookup_43'\")\n",
      "\n",
      "name: restecg\n",
      "vocab: [0, 1, 2]\n",
      "进入 int\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.int64, name='restecg'), name='restecg', description=\"created by layer 'restecg'\")\n",
      "<dtype: 'int64'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), name='integer_lookup_44/None_lookup_table_find/LookupTableFindV2:0', description=\"created by layer 'integer_lookup_44'\")\n",
      "\n",
      "name: slope\n",
      "vocab: [1, 2, 3]\n",
      "进入 int\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.int64, name='slope'), name='slope', description=\"created by layer 'slope'\")\n",
      "<dtype: 'int64'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), name='integer_lookup_45/None_lookup_table_find/LookupTableFindV2:0', description=\"created by layer 'integer_lookup_45'\")\n",
      "\n",
      "name: thal\n",
      "vocab: ['1', '2', 'fixed', 'normal', 'reversible']\n",
      "进入 str\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='thal'), name='thal', description=\"created by layer 'thal'\")\n",
      "<dtype: 'int64'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), name='string_lookup_12/None_lookup_table_find/LookupTableFindV2:0', description=\"created by layer 'string_lookup_12'\")\n",
      "\n",
      "name: ca\n",
      "vocab: [0, 1, 2, 3]\n",
      "进入 int\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.int64, name='ca'), name='ca', description=\"created by layer 'ca'\")\n",
      "<dtype: 'int64'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.int64, name=None), name='integer_lookup_46/None_lookup_table_find/LookupTableFindV2:0', description=\"created by layer 'integer_lookup_46'\")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'integer_lookup_43')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'integer_lookup_44')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'integer_lookup_45')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'string_lookup_12')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'integer_lookup_46')>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "for name in categorical_feature_names:\n",
    "    vocab = sorted(set(df[name]))\n",
    "    print(f'name: {name}')\n",
    "    print(f'vocab: {vocab}')\n",
    "\n",
    "    \n",
    "    if type(vocab[0]) is str:\n",
    "        print(\"进入 str\")\n",
    "        lookup = tf.keras.layers.experimental.preprocessing\\\n",
    "                                .StringLookup(vocabulary=vocab, output_mode='int')\n",
    "    else:\n",
    "        print(\"进入 int\")\n",
    "        # vocab.insert(1, -1)\n",
    "        lookup = tf.keras.layers.experimental.preprocessing.IntegerLookup(vocabulary=vocab,\n",
    "                                                                          mask_token=None,\n",
    "                                                                          # oov_token=-1,\n",
    "                                                                          output_mode='int')\n",
    "    \n",
    "    print(inputs[name])\n",
    "    x = inputs[name][:, tf.newaxis]\n",
    "    x = lookup(x)\n",
    "    print(x)\n",
    "    print(x)\n",
    "    # preprocessed.append(x)\n",
    "    p.append(x)\n",
    "    print()\n",
    "\n",
    "\n",
    "#arr = lookup(np.array([-1,4,1])).numpy()\n",
    "#\n",
    "#d1 = arr.shape[0]\n",
    "#d2 = max(len(set(vocab)), len(set(vocab)|set([-1,4,1])))\n",
    "#z = np.zeros((d1, d2))\n",
    "#z[range(d1), arr-1] = 1\n",
    "#tf.convert_to_tensor(z, dtype=tf.float32)\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble the preprocessing head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point `preprocessed` is just a Python list of all the preprocessing results, each result has a shape of `(batch_size, depth)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=int64 (created by layer 'integer_lookup_17')>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessed.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_10')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_11')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'tf.cast_12')>,\n",
       " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'normalization_3')>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all the preprocessed features along the `depth` axis, so each dictionary-example is converted into a single vector. The vector contains categorical features, numeric features, and categorical one-hot features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesssed_result = tf.concat(preprocessed, axis=-1)\n",
    "preprocesssed_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a model out of that calculation so it can be reused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tf.keras.Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = tf.keras.Model(inputs, preprocesssed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(preprocessor, rankdir=\"LR\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是 Colab 运行结果图：\n",
    "\n",
    "\n",
    "<img src=\"./images/dataframe_plot_model_preprocessor.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor, use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html\" class=\"external\">DataFrame.iloc</a> accessor to slice the first example from the DataFrame. Then convert it to a dictionary and pass the dictionary to the preprocessor. The result is a single vector containing the binary features, normalized numeric features and the one-hot categorical features, in that order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor(dict(df.iloc[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the main body of the model. Use the same configuration as in the previous example: A couple of `Dense` rectified-linear layers and a `Dense(1)` output layer for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = tf.keras.Sequential([tf.keras.layers.Dense(10, activation='relu'),\n",
    "                            tf.keras.layers.Dense(10, activation='relu'),\n",
    "                            tf.keras.layers.Dense(1)\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put the two pieces together using the Keras functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'age')>,\n",
       " 'sex': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'sex')>,\n",
       " 'cp': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'cp')>,\n",
       " 'trestbps': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'trestbps')>,\n",
       " 'chol': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'chol')>,\n",
       " 'fbs': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'fbs')>,\n",
       " 'restecg': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'restecg')>,\n",
       " 'thalach': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'thalach')>,\n",
       " 'exang': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'exang')>,\n",
       " 'oldpeak': <KerasTensor: shape=(None,) dtype=float32 (created by layer 'oldpeak')>,\n",
       " 'slope': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'slope')>,\n",
       " 'ca': <KerasTensor: shape=(None,) dtype=int64 (created by layer 'ca')>,\n",
       " 'thal': <KerasTensor: shape=(None,) dtype=string (created by layer 'thal')>}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessor(inputs)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = body(x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs, result)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model expects a dictionary of inputs. The simplest way to pass it the data is to convert the DataFrame to a dict and pass that dict as the `x` argument to `Model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dict(df), target, epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tf.data` works as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((dict(df), target))\n",
    "\n",
    "ds = ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "for x, y in ds.take(1):\n",
    "    pprint.pprint(x)\n",
    "    print()\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfg]",
   "language": "python",
   "name": "conda-env-tfg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
