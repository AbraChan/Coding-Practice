{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center><font color=maroon size=6><b>Introduction</b></font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4><b>References:</b></font>\n",
    "1. TF2 official tutorials: <a href=\"https://www.tensorflow.org/datasets\" style=\"text-decoration:none;\">TensorFlow Datasets</a> \n",
    "    * `TensorFlow > Resources > `Datasets > Guide > <a href=\"https://www.tensorflow.org/datasets/overview\" style=\"text-decoration:none;\">Introduction</a>\n",
    "        * Run in <a href=\"https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb\" style=\"text-decoration:none;\">Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Datasets\n",
    "\n",
    "<font size=3 color=maroon>TFDS provides a collection of ready-to-use datasets for use with TensorFlow, Jax, and other Machine Learning frameworks.</font>\n",
    "\n",
    "<font size=3 color=maroon>It handles downloading and preparing the data deterministically and constructing a `tf.data.Dataset` (or `np.array`).</font>\n",
    "\n",
    "<font size=3 color=maroon>**Note**: Do not confuse [TFDS](https://www.tensorflow.org/datasets) (this ***library***) with `tf.data` (TensorFlow ***API*** to build efficient data pipelines). TFDS is a high level wrapper around `tf.data`. If you're not familiar with this API, we encourage you to read [the official tf.data guide](https://www.tensorflow.org/guide/data) first.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "<font size=3 color=maroon>TFDS exists in two packages:\n",
    "\n",
    "* `pip install tensorflow-datasets`: The stable version, released every few months.\n",
    "* `pip install tfds-nightly`: Released every day, contains the last versions of the datasets.\n",
    "\n",
    "This colab uses `tfds-nightly`:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q tfds-nightly tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\envs\\tfg\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find available datasets\n",
    "\n",
    "All dataset builders are subclass of `tfds.core.DatasetBuilder`. To get the list of available builders, use `tfds.list_builders()` or look at our [catalog](https://www.tensorflow.org/datasets/catalog/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'arc',\n",
       " 'asset',\n",
       " 'assin2',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'bee_dataset',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'blimp',\n",
       " 'booksum',\n",
       " 'bool_q',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cardiotox',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'cs_restaurants',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'd4rl_adroit_door',\n",
       " 'd4rl_adroit_hammer',\n",
       " 'd4rl_adroit_pen',\n",
       " 'd4rl_adroit_relocate',\n",
       " 'd4rl_antmaze',\n",
       " 'd4rl_mujoco_ant',\n",
       " 'd4rl_mujoco_halfcheetah',\n",
       " 'd4rl_mujoco_hopper',\n",
       " 'd4rl_mujoco_walker2d',\n",
       " 'dart',\n",
       " 'davis',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'diamonds',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'doc_nli',\n",
       " 'dolphin_number_word',\n",
       " 'domainnet',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'efron_morris75',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'gem',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gov_report',\n",
       " 'gpt3',\n",
       " 'gref',\n",
       " 'groove',\n",
       " 'grounded_scan',\n",
       " 'gsm8k',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'i_naturalist2018',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_multilabel',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_lt',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_sketch',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'istella',\n",
       " 'kddcup99',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'math_qa',\n",
       " 'mctaco',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'mslr_web',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'ogbg_molpcba',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'pass',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'penguins',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'protein_net',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quality',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'ref_coco',\n",
       " 'resisc45',\n",
       " 'rlu_atari',\n",
       " 'rlu_atari_checkpoints',\n",
       " 'rlu_atari_checkpoints_ordered',\n",
       " 'rlu_dmlab_explore_object_rewards_few',\n",
       " 'rlu_dmlab_explore_object_rewards_many',\n",
       " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
       " 'rlu_dmlab_rooms_watermaze',\n",
       " 'rlu_dmlab_seekavoid_arena01',\n",
       " 'rlu_rwrl',\n",
       " 'robomimic_ph',\n",
       " 'robonet',\n",
       " 'robosuite_panda_pick_place_can',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'schema_guided_dialogue',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'scrolls',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'smartwatch_gestures',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'squad_question_generation',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'star_cfq',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'summscreen',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'symmetric_solids',\n",
       " 'tao',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vctk',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_auto',\n",
       " 'wiki_bio',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wit',\n",
       " 'wit_kaggle',\n",
       " 'wmt13_translate',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_xnli',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no',\n",
       " 'youtube_vis']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset\n",
    "\n",
    "### tfds.load\n",
    "\n",
    "<font size=3 color=maroon>The easiest way of loading a dataset is `tfds.load`. It will:\n",
    "\n",
    "1. Download the data and save it as [`tfrecord`](https://www.tensorflow.org/tutorials/load_data/tfrecord) files.\n",
    "2. Load the `tfrecord` and create the `tf.data.Dataset`.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                                                         | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:00<00:02,  1.17 url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:00<00:02,  1.17 url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|                                                                | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:00<00:02,  1.17 url/s]\u001b[A\u001b[A\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:00<00:02,  1.17 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                              | 0/9 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:00<00:02,  1.17 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|████████████████▎                                                | 1/4 [00:00<00:02,  1.17 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:00<00:00,  2.39 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:00<00:00,  2.39 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  50%|████████████████████████████                            | 1/2 [00:00<00:00,  1.15 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:00<00:00,  2.39 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|                                                                             | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.36 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:02<00:00,  2.39 url/s]\u001b[A\n",
      "Dl Size...:  10%|██████▉                                                              | 1/10 [00:02<00:23,  2.63s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|████████████████████████████████▌                                | 2/4 [00:02<00:00,  2.39 url/s]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [00:02<00:21,  2.63s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:03<00:01,  1.41s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [00:03<00:21,  2.63s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:03<00:01,  1.41s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [00:03<00:21,  2.63s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|█████████████████████████████████████▎                  | 2/3 [00:03<00:00,  2.36 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:03<00:01,  1.41s/ url]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|█████████████▊                                                       | 2/10 [00:03<00:21,  2.63s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:03<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...:  30%|████████████████████▋                                                | 3/10 [00:03<00:08,  1.16s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:04<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...:  40%|███████████████████████████▌                                         | 4/10 [00:04<00:06,  1.12s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:05<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...:  50%|██████████████████████████████████▌                                  | 5/10 [00:05<00:05,  1.05s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:06<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...:  60%|█████████████████████████████████████████▍                           | 6/10 [00:06<00:03,  1.03 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:07<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...:  70%|████████████████████████████████████████████████▎                    | 7/10 [00:07<00:02,  1.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:08<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...:  80%|███████████████████████████████████████████████████████▏             | 8/10 [00:08<00:01,  1.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:08<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...:  90%|██████████████████████████████████████████████████████████████       | 9/10 [00:08<00:00,  1.20 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  1.44s/ file]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|████████████████████████████████████████████████▊                | 3/4 [00:09<00:01,  1.41s/ url]\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:09<00:00,  1.24 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  3.44s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.24 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  3.44s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.24 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction completed...:  75%|██████████████████████████████████████████              | 3/4 [00:10<00:01,  1.44s/ file]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  3.44s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.24 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  2.60s/ file]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.04s/ MiB]\n",
      "Dl Completed...: 100%|█████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  2.60s/ url]\n",
      "Generating splits...:   0%|                                                                 | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 1 examples [00:01,  1.40s/ examples]\u001b[A\n",
      "Generating train examples...: 174 examples [00:01, 160.50 examples/s]\u001b[A\n",
      "Generating train examples...: 363 examples [00:01, 359.04 examples/s]\u001b[A\n",
      "Generating train examples...: 545 examples [00:01, 564.16 examples/s]\u001b[A\n",
      "Generating train examples...: 722 examples [00:01, 766.27 examples/s]\u001b[A\n",
      "Generating train examples...: 899 examples [00:01, 960.38 examples/s]\u001b[A\n",
      "Generating train examples...: 1093 examples [00:02, 1148.57 examples/s]\u001b[A\n",
      "Generating train examples...: 1268 examples [00:02, 1285.99 examples/s]\u001b[A\n",
      "Generating train examples...: 1444 examples [00:02, 1403.91 examples/s]\u001b[A\n",
      "Generating train examples...: 1621 examples [00:02, 1496.13 examples/s]\u001b[A\n",
      "Generating train examples...: 1795 examples [00:02, 1562.37 examples/s]\u001b[A\n",
      "Generating train examples...: 1973 examples [00:02, 1620.65 examples/s]\u001b[A\n",
      "Generating train examples...: 2148 examples [00:02, 1653.60 examples/s]\u001b[A\n",
      "Generating train examples...: 2323 examples [00:02, 1676.63 examples/s]\u001b[A\n",
      "Generating train examples...: 2500 examples [00:02, 1700.64 examples/s]\u001b[A\n",
      "Generating train examples...: 2675 examples [00:02, 1715.00 examples/s]\u001b[A\n",
      "Generating train examples...: 2850 examples [00:03, 1720.25 examples/s]\u001b[A\n",
      "Generating train examples...: 3035 examples [00:03, 1737.69 examples/s]\u001b[A\n",
      "Generating train examples...: 3222 examples [00:03, 1755.52 examples/s]\u001b[A\n",
      "Generating train examples...: 3399 examples [00:03, 1757.74 examples/s]\u001b[A\n",
      "Generating train examples...: 3576 examples [00:03, 1751.02 examples/s]\u001b[A\n",
      "Generating train examples...: 3752 examples [00:03, 1743.37 examples/s]\u001b[A\n",
      "Generating train examples...: 3930 examples [00:03, 1750.95 examples/s]\u001b[A\n",
      "Generating train examples...: 4115 examples [00:03, 1753.86 examples/s]\u001b[A\n",
      "Generating train examples...: 4295 examples [00:03, 1764.03 examples/s]\u001b[A\n",
      "Generating train examples...: 4472 examples [00:03, 1757.24 examples/s]\u001b[A\n",
      "Generating train examples...: 4648 examples [00:04, 1752.87 examples/s]\u001b[A\n",
      "Generating train examples...: 4824 examples [00:04, 1744.63 examples/s]\u001b[A\n",
      "Generating train examples...: 4999 examples [00:04, 1741.04 examples/s]\u001b[A\n",
      "Generating train examples...: 5177 examples [00:04, 1747.44 examples/s]\u001b[A\n",
      "Generating train examples...: 5371 examples [00:04, 1757.36 examples/s]\u001b[A\n",
      "Generating train examples...: 5547 examples [00:04, 1748.73 examples/s]\u001b[A\n",
      "Generating train examples...: 5722 examples [00:04, 1743.84 examples/s]\u001b[A\n",
      "Generating train examples...: 5916 examples [00:04, 1750.60 examples/s]\u001b[A\n",
      "Generating train examples...: 6099 examples [00:04, 1755.24 examples/s]\u001b[A\n",
      "Generating train examples...: 6277 examples [00:04, 1757.58 examples/s]\u001b[A\n",
      "Generating train examples...: 6455 examples [00:05, 1760.97 examples/s]\u001b[A\n",
      "Generating train examples...: 6632 examples [00:05, 1763.24 examples/s]\u001b[A\n",
      "Generating train examples...: 6809 examples [00:05, 1755.01 examples/s]\u001b[A\n",
      "Generating train examples...: 6985 examples [00:05, 1756.33 examples/s]\u001b[A\n",
      "Generating train examples...: 7176 examples [00:05, 1761.15 examples/s]\u001b[A\n",
      "Generating train examples...: 7353 examples [00:05, 1755.68 examples/s]\u001b[A\n",
      "Generating train examples...: 7529 examples [00:05, 1751.79 examples/s]\u001b[A\n",
      "Generating train examples...: 7706 examples [00:05, 1755.65 examples/s]\u001b[A\n",
      "Generating train examples...: 7882 examples [00:05, 1751.75 examples/s]\u001b[A\n",
      "Generating train examples...: 8058 examples [00:05, 1749.01 examples/s]\u001b[A\n",
      "Generating train examples...: 8234 examples [00:06, 1747.76 examples/s]\u001b[A\n",
      "Generating train examples...: 8409 examples [00:06, 1743.09 examples/s]\u001b[A\n",
      "Generating train examples...: 8585 examples [00:06, 1743.09 examples/s]\u001b[A\n",
      "Generating train examples...: 8763 examples [00:06, 1750.84 examples/s]\u001b[A\n",
      "Generating train examples...: 8939 examples [00:06, 1743.33 examples/s]\u001b[A\n",
      "Generating train examples...: 9114 examples [00:06, 1745.11 examples/s]\u001b[A\n",
      "Generating train examples...: 9299 examples [00:06, 1752.20 examples/s]\u001b[A\n",
      "Generating train examples...: 9475 examples [00:06, 1746.44 examples/s]\u001b[A\n",
      "Generating train examples...: 9650 examples [00:06, 1747.34 examples/s]\u001b[A\n",
      "Generating train examples...: 9830 examples [00:07, 1752.09 examples/s]\u001b[A\n",
      "Generating train examples...: 10006 examples [00:07, 1746.26 examples/s]\u001b[A\n",
      "Generating train examples...: 10181 examples [00:07, 1742.20 examples/s]\u001b[A\n",
      "Generating train examples...: 10362 examples [00:07, 1743.16 examples/s]\u001b[A\n",
      "Generating train examples...: 10537 examples [00:07, 1741.19 examples/s]\u001b[A\n",
      "Generating train examples...: 10714 examples [00:07, 1744.56 examples/s]\u001b[A\n",
      "Generating train examples...: 10893 examples [00:07, 1749.92 examples/s]\u001b[A\n",
      "Generating train examples...: 11069 examples [00:07, 1750.58 examples/s]\u001b[A\n",
      "Generating train examples...: 11245 examples [00:07, 1748.19 examples/s]\u001b[A\n",
      "Generating train examples...: 11421 examples [00:07, 1746.51 examples/s]\u001b[A\n",
      "Generating train examples...: 11596 examples [00:08, 1741.20 examples/s]\u001b[A\n",
      "Generating train examples...: 11771 examples [00:08, 1743.82 examples/s]\u001b[A\n",
      "Generating train examples...: 11952 examples [00:08, 1747.31 examples/s]\u001b[A\n",
      "Generating train examples...: 12127 examples [00:08, 1740.85 examples/s]\u001b[A\n",
      "Generating train examples...: 12302 examples [00:08, 1738.25 examples/s]\u001b[A\n",
      "Generating train examples...: 12476 examples [00:08, 1738.76 examples/s]\u001b[A\n",
      "Generating train examples...: 12651 examples [00:08, 1737.10 examples/s]\u001b[A\n",
      "Generating train examples...: 12826 examples [00:08, 1740.77 examples/s]\u001b[A\n",
      "Generating train examples...: 13001 examples [00:08, 1743.53 examples/s]\u001b[A\n",
      "Generating train examples...: 13176 examples [00:08, 1735.10 examples/s]\u001b[A\n",
      "Generating train examples...: 13350 examples [00:09, 1731.55 examples/s]\u001b[A\n",
      "Generating train examples...: 13526 examples [00:09, 1734.71 examples/s]\u001b[A\n",
      "Generating train examples...: 13702 examples [00:09, 1738.55 examples/s]\u001b[A\n",
      "Generating train examples...: 13876 examples [00:09, 1738.97 examples/s]\u001b[A\n",
      "Generating train examples...: 14050 examples [00:09, 1734.10 examples/s]\u001b[A\n",
      "Generating train examples...: 14226 examples [00:09, 1736.67 examples/s]\u001b[A\n",
      "Generating train examples...: 14400 examples [00:09, 1737.66 examples/s]\u001b[A\n",
      "Generating train examples...: 14574 examples [00:09, 1733.34 examples/s]\u001b[A\n",
      "Generating train examples...: 14763 examples [00:09, 1745.11 examples/s]\u001b[A\n",
      "Generating train examples...: 14938 examples [00:09, 1746.17 examples/s]\u001b[A\n",
      "Generating train examples...: 15116 examples [00:10, 1751.03 examples/s]\u001b[A\n",
      "Generating train examples...: 15292 examples [00:10, 1753.69 examples/s]\u001b[A\n",
      "Generating train examples...: 15486 examples [00:10, 1766.62 examples/s]\u001b[A\n",
      "Generating train examples...: 15677 examples [00:10, 1767.87 examples/s]\u001b[A\n",
      "Generating train examples...: 15854 examples [00:10, 1762.82 examples/s]\u001b[A\n",
      "Generating train examples...: 16031 examples [00:10, 1764.76 examples/s]\u001b[A\n",
      "Generating train examples...: 16209 examples [00:10, 1764.05 examples/s]\u001b[A\n",
      "Generating train examples...: 16392 examples [00:10, 1768.46 examples/s]\u001b[A\n",
      "Generating train examples...: 16569 examples [00:10, 1764.54 examples/s]\u001b[A\n",
      "Generating train examples...: 16746 examples [00:10, 1760.93 examples/s]\u001b[A\n",
      "Generating train examples...: 16924 examples [00:11, 1761.37 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train examples...: 17108 examples [00:11, 1763.76 examples/s]\u001b[A\n",
      "Generating train examples...: 17295 examples [00:11, 1755.97 examples/s]\u001b[A\n",
      "Generating train examples...: 17471 examples [00:11, 1752.03 examples/s]\u001b[A\n",
      "Generating train examples...: 17650 examples [00:11, 1756.72 examples/s]\u001b[A\n",
      "Generating train examples...: 17837 examples [00:11, 1755.25 examples/s]\u001b[A\n",
      "Generating train examples...: 18027 examples [00:11, 1758.16 examples/s]\u001b[A\n",
      "Generating train examples...: 18207 examples [00:11, 1764.16 examples/s]\u001b[A\n",
      "Generating train examples...: 18398 examples [00:11, 1761.82 examples/s]\u001b[A\n",
      "Generating train examples...: 18583 examples [00:12, 1757.64 examples/s]\u001b[A\n",
      "Generating train examples...: 18762 examples [00:12, 1759.57 examples/s]\u001b[A\n",
      "Generating train examples...: 18938 examples [00:12, 1610.09 examples/s]\u001b[A\n",
      "Generating train examples...: 19105 examples [00:12, 1597.64 examples/s]\u001b[A\n",
      "Generating train examples...: 19289 examples [00:12, 1634.98 examples/s]\u001b[A\n",
      "Generating train examples...: 19472 examples [00:12, 1667.80 examples/s]\u001b[A\n",
      "Generating train examples...: 19666 examples [00:12, 1699.05 examples/s]\u001b[A\n",
      "Generating train examples...: 19852 examples [00:12, 1715.97 examples/s]\u001b[A\n",
      "Generating train examples...: 20028 examples [00:12, 1727.18 examples/s]\u001b[A\n",
      "Generating train examples...: 20202 examples [00:13, 1594.20 examples/s]\u001b[A\n",
      "Generating train examples...: 20368 examples [00:13, 1598.60 examples/s]\u001b[A\n",
      "Generating train examples...: 20560 examples [00:13, 1656.50 examples/s]\u001b[A\n",
      "Generating train examples...: 20746 examples [00:13, 1697.55 examples/s]\u001b[A\n",
      "Generating train examples...: 20932 examples [00:13, 1726.41 examples/s]\u001b[A\n",
      "Generating train examples...: 21117 examples [00:13, 1743.64 examples/s]\u001b[A\n",
      "Generating train examples...: 21302 examples [00:13, 1755.62 examples/s]\u001b[A\n",
      "Generating train examples...: 21487 examples [00:13, 1764.63 examples/s]\u001b[A\n",
      "Generating train examples...: 21673 examples [00:13, 1773.61 examples/s]\u001b[A\n",
      "Generating train examples...: 21858 examples [00:13, 1776.50 examples/s]\u001b[A\n",
      "Generating train examples...: 22042 examples [00:14, 1775.25 examples/s]\u001b[A\n",
      "Generating train examples...: 22236 examples [00:14, 1778.53 examples/s]\u001b[A\n",
      "Generating train examples...: 22422 examples [00:14, 1781.70 examples/s]\u001b[A\n",
      "Generating train examples...: 22609 examples [00:14, 1791.21 examples/s]\u001b[A\n",
      "Generating train examples...: 22794 examples [00:14, 1789.10 examples/s]\u001b[A\n",
      "Generating train examples...: 22979 examples [00:14, 1788.07 examples/s]\u001b[A\n",
      "Generating train examples...: 23168 examples [00:14, 1787.86 examples/s]\u001b[A\n",
      "Generating train examples...: 23354 examples [00:14, 1790.63 examples/s]\u001b[A\n",
      "Generating train examples...: 23540 examples [00:14, 1791.26 examples/s]\u001b[A\n",
      "Generating train examples...: 23727 examples [00:14, 1796.44 examples/s]\u001b[A\n",
      "Generating train examples...: 23913 examples [00:15, 1796.34 examples/s]\u001b[A\n",
      "Generating train examples...: 24099 examples [00:15, 1795.53 examples/s]\u001b[A\n",
      "Generating train examples...: 24286 examples [00:15, 1798.20 examples/s]\u001b[A\n",
      "Generating train examples...: 24473 examples [00:15, 1801.27 examples/s]\u001b[A\n",
      "Generating train examples...: 24659 examples [00:15, 1799.38 examples/s]\u001b[A\n",
      "Generating train examples...: 24845 examples [00:15, 1790.85 examples/s]\u001b[A\n",
      "Generating train examples...: 25031 examples [00:15, 1790.75 examples/s]\u001b[A\n",
      "Generating train examples...: 25217 examples [00:15, 1792.14 examples/s]\u001b[A\n",
      "Generating train examples...: 25403 examples [00:15, 1792.54 examples/s]\u001b[A\n",
      "Generating train examples...: 25591 examples [00:16, 1793.79 examples/s]\u001b[A\n",
      "Generating train examples...: 25777 examples [00:16, 1795.05 examples/s]\u001b[A\n",
      "Generating train examples...: 25967 examples [00:16, 1795.63 examples/s]\u001b[A\n",
      "Generating train examples...: 26154 examples [00:16, 1798.39 examples/s]\u001b[A\n",
      "Generating train examples...: 26339 examples [00:16, 1794.20 examples/s]\u001b[A\n",
      "Generating train examples...: 26521 examples [00:16, 1784.06 examples/s]\u001b[A\n",
      "Generating train examples...: 26709 examples [00:16, 1787.57 examples/s]\u001b[A\n",
      "Generating train examples...: 26895 examples [00:16, 1788.45 examples/s]\u001b[A\n",
      "Generating train examples...: 27081 examples [00:16, 1790.86 examples/s]\u001b[A\n",
      "Generating train examples...: 27268 examples [00:16, 1795.08 examples/s]\u001b[A\n",
      "Generating train examples...: 27454 examples [00:17, 1795.71 examples/s]\u001b[A\n",
      "Generating train examples...: 27641 examples [00:17, 1791.60 examples/s]\u001b[A\n",
      "Generating train examples...: 27825 examples [00:17, 1784.55 examples/s]\u001b[A\n",
      "Generating train examples...: 28012 examples [00:17, 1784.94 examples/s]\u001b[A\n",
      "Generating train examples...: 28191 examples [00:17, 1781.00 examples/s]\u001b[A\n",
      "Generating train examples...: 28370 examples [00:17, 1777.59 examples/s]\u001b[A\n",
      "Generating train examples...: 28555 examples [00:17, 1759.61 examples/s]\u001b[A\n",
      "Generating train examples...: 28741 examples [00:17, 1769.97 examples/s]\u001b[A\n",
      "Generating train examples...: 28930 examples [00:17, 1779.23 examples/s]\u001b[A\n",
      "Generating train examples...: 29116 examples [00:18, 1783.16 examples/s]\u001b[A\n",
      "Generating train examples...: 29304 examples [00:18, 1784.71 examples/s]\u001b[A\n",
      "Generating train examples...: 29489 examples [00:18, 1784.40 examples/s]\u001b[A\n",
      "Generating train examples...: 29675 examples [00:18, 1788.19 examples/s]\u001b[A\n",
      "Generating train examples...: 29861 examples [00:18, 1790.60 examples/s]\u001b[A\n",
      "Generating train examples...: 30044 examples [00:18, 1784.07 examples/s]\u001b[A\n",
      "Generating train examples...: 30229 examples [00:18, 1784.88 examples/s]\u001b[A\n",
      "Generating train examples...: 30412 examples [00:18, 1777.63 examples/s]\u001b[A\n",
      "Generating train examples...: 30597 examples [00:18, 1776.58 examples/s]\u001b[A\n",
      "Generating train examples...: 30781 examples [00:18, 1774.34 examples/s]\u001b[A\n",
      "Generating train examples...: 30964 examples [00:19, 1770.56 examples/s]\u001b[A\n",
      "Generating train examples...: 31153 examples [00:19, 1770.83 examples/s]\u001b[A\n",
      "Generating train examples...: 31339 examples [00:19, 1777.00 examples/s]\u001b[A\n",
      "Generating train examples...: 31526 examples [00:19, 1783.46 examples/s]\u001b[A\n",
      "Generating train examples...: 31715 examples [00:19, 1790.76 examples/s]\u001b[A\n",
      "Generating train examples...: 31902 examples [00:19, 1794.80 examples/s]\u001b[A\n",
      "Generating train examples...: 32092 examples [00:19, 1795.22 examples/s]\u001b[A\n",
      "Generating train examples...: 32279 examples [00:19, 1792.50 examples/s]\u001b[A\n",
      "Generating train examples...: 32464 examples [00:19, 1790.21 examples/s]\u001b[A\n",
      "Generating train examples...: 32652 examples [00:19, 1786.00 examples/s]\u001b[A\n",
      "Generating train examples...: 32836 examples [00:20, 1784.85 examples/s]\u001b[A\n",
      "Generating train examples...: 33020 examples [00:20, 1779.66 examples/s]\u001b[A\n",
      "Generating train examples...: 33207 examples [00:20, 1787.05 examples/s]\u001b[A\n",
      "Generating train examples...: 33393 examples [00:20, 1789.17 examples/s]\u001b[A\n",
      "Generating train examples...: 33572 examples [00:20, 1787.36 examples/s]\u001b[A\n",
      "Generating train examples...: 33751 examples [00:20, 1767.26 examples/s]\u001b[A\n",
      "Generating train examples...: 33938 examples [00:20, 1760.46 examples/s]\u001b[A\n",
      "Generating train examples...: 34125 examples [00:20, 1769.43 examples/s]\u001b[A\n",
      "Generating train examples...: 34311 examples [00:20, 1776.58 examples/s]\u001b[A\n",
      "Generating train examples...: 34496 examples [00:21, 1777.67 examples/s]\u001b[A\n",
      "Generating train examples...: 34679 examples [00:21, 1773.31 examples/s]\u001b[A\n",
      "Generating train examples...: 34865 examples [00:21, 1768.61 examples/s]\u001b[A\n",
      "Generating train examples...: 35048 examples [00:21, 1767.21 examples/s]\u001b[A\n",
      "Generating train examples...: 35232 examples [00:21, 1764.29 examples/s]\u001b[A\n",
      "Generating train examples...: 35417 examples [00:21, 1771.12 examples/s]\u001b[A\n",
      "Generating train examples...: 35603 examples [00:21, 1778.31 examples/s]\u001b[A\n",
      "Generating train examples...: 35789 examples [00:21, 1782.83 examples/s]\u001b[A\n",
      "Generating train examples...: 35975 examples [00:21, 1787.35 examples/s]\u001b[A\n",
      "Generating train examples...: 36161 examples [00:21, 1783.34 examples/s]\u001b[A\n",
      "Generating train examples...: 36341 examples [00:22, 1754.47 examples/s]\u001b[A\n",
      "Generating train examples...: 36525 examples [00:22, 1758.89 examples/s]\u001b[A\n",
      "Generating train examples...: 36710 examples [00:22, 1764.55 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train examples...: 36896 examples [00:22, 1767.91 examples/s]\u001b[A\n",
      "Generating train examples...: 37083 examples [00:22, 1772.00 examples/s]\u001b[A\n",
      "Generating train examples...: 37267 examples [00:22, 1773.46 examples/s]\u001b[A\n",
      "Generating train examples...: 37451 examples [00:22, 1775.46 examples/s]\u001b[A\n",
      "Generating train examples...: 37637 examples [00:22, 1781.61 examples/s]\u001b[A\n",
      "Generating train examples...: 37824 examples [00:22, 1781.35 examples/s]\u001b[A\n",
      "Generating train examples...: 38010 examples [00:23, 1786.94 examples/s]\u001b[A\n",
      "Generating train examples...: 38196 examples [00:23, 1783.61 examples/s]\u001b[A\n",
      "Generating train examples...: 38375 examples [00:23, 1785.00 examples/s]\u001b[A\n",
      "Generating train examples...: 38554 examples [00:23, 1777.11 examples/s]\u001b[A\n",
      "Generating train examples...: 38739 examples [00:23, 1762.70 examples/s]\u001b[A\n",
      "Generating train examples...: 38935 examples [00:23, 1769.50 examples/s]\u001b[A\n",
      "Generating train examples...: 39121 examples [00:23, 1776.39 examples/s]\u001b[A\n",
      "Generating train examples...: 39307 examples [00:23, 1782.02 examples/s]\u001b[A\n",
      "Generating train examples...: 39493 examples [00:23, 1786.77 examples/s]\u001b[A\n",
      "Generating train examples...: 39680 examples [00:23, 1788.88 examples/s]\u001b[A\n",
      "Generating train examples...: 39866 examples [00:24, 1791.63 examples/s]\u001b[A\n",
      "Generating train examples...: 40052 examples [00:24, 1793.29 examples/s]\u001b[A\n",
      "Generating train examples...: 40237 examples [00:24, 1789.67 examples/s]\u001b[A\n",
      "Generating train examples...: 40421 examples [00:24, 1785.27 examples/s]\u001b[A\n",
      "Generating train examples...: 40602 examples [00:24, 1772.22 examples/s]\u001b[A\n",
      "Generating train examples...: 40787 examples [00:24, 1770.58 examples/s]\u001b[A\n",
      "Generating train examples...: 40972 examples [00:24, 1775.72 examples/s]\u001b[A\n",
      "Generating train examples...: 41157 examples [00:24, 1776.56 examples/s]\u001b[A\n",
      "Generating train examples...: 41342 examples [00:24, 1771.11 examples/s]\u001b[A\n",
      "Generating train examples...: 41527 examples [00:24, 1774.31 examples/s]\u001b[A\n",
      "Generating train examples...: 41712 examples [00:25, 1777.71 examples/s]\u001b[A\n",
      "Generating train examples...: 41897 examples [00:25, 1780.38 examples/s]\u001b[A\n",
      "Generating train examples...: 42078 examples [00:25, 1781.32 examples/s]\u001b[A\n",
      "Generating train examples...: 42263 examples [00:25, 1781.75 examples/s]\u001b[A\n",
      "Generating train examples...: 42447 examples [00:25, 1779.43 examples/s]\u001b[A\n",
      "Generating train examples...: 42633 examples [00:25, 1778.81 examples/s]\u001b[A\n",
      "Generating train examples...: 42817 examples [00:25, 1776.98 examples/s]\u001b[A\n",
      "Generating train examples...: 43001 examples [00:25, 1776.53 examples/s]\u001b[A\n",
      "Generating train examples...: 43188 examples [00:25, 1779.75 examples/s]\u001b[A\n",
      "Generating train examples...: 43374 examples [00:26, 1778.44 examples/s]\u001b[A\n",
      "Generating train examples...: 43558 examples [00:26, 1778.30 examples/s]\u001b[A\n",
      "Generating train examples...: 43748 examples [00:26, 1781.47 examples/s]\u001b[A\n",
      "Generating train examples...: 43934 examples [00:26, 1785.99 examples/s]\u001b[A\n",
      "Generating train examples...: 44119 examples [00:26, 1787.42 examples/s]\u001b[A\n",
      "Generating train examples...: 44304 examples [00:26, 1787.41 examples/s]\u001b[A\n",
      "Generating train examples...: 44483 examples [00:26, 1786.93 examples/s]\u001b[A\n",
      "Generating train examples...: 44662 examples [00:26, 1771.74 examples/s]\u001b[A\n",
      "Generating train examples...: 44846 examples [00:26, 1750.27 examples/s]\u001b[A\n",
      "Generating train examples...: 45031 examples [00:26, 1761.56 examples/s]\u001b[A\n",
      "Generating train examples...: 45217 examples [00:27, 1769.85 examples/s]\u001b[A\n",
      "Generating train examples...: 45401 examples [00:27, 1771.20 examples/s]\u001b[A\n",
      "Generating train examples...: 45584 examples [00:27, 1770.08 examples/s]\u001b[A\n",
      "Generating train examples...: 45767 examples [00:27, 1768.70 examples/s]\u001b[A\n",
      "Generating train examples...: 45954 examples [00:27, 1774.25 examples/s]\u001b[A\n",
      "Generating train examples...: 46141 examples [00:27, 1776.54 examples/s]\u001b[A\n",
      "Generating train examples...: 46326 examples [00:27, 1779.79 examples/s]\u001b[A\n",
      "Generating train examples...: 46504 examples [00:27, 1774.74 examples/s]\u001b[A\n",
      "Generating train examples...: 46682 examples [00:27, 1763.22 examples/s]\u001b[A\n",
      "Generating train examples...: 46866 examples [00:27, 1754.12 examples/s]\u001b[A\n",
      "Generating train examples...: 47050 examples [00:28, 1761.12 examples/s]\u001b[A\n",
      "Generating train examples...: 47236 examples [00:28, 1766.84 examples/s]\u001b[A\n",
      "Generating train examples...: 47421 examples [00:28, 1773.08 examples/s]\u001b[A\n",
      "Generating train examples...: 47607 examples [00:28, 1778.52 examples/s]\u001b[A\n",
      "Generating train examples...: 47792 examples [00:28, 1782.50 examples/s]\u001b[A\n",
      "Generating train examples...: 47975 examples [00:28, 1777.86 examples/s]\u001b[A\n",
      "Generating train examples...: 48161 examples [00:28, 1776.79 examples/s]\u001b[A\n",
      "Generating train examples...: 48344 examples [00:28, 1771.22 examples/s]\u001b[A\n",
      "Generating train examples...: 48528 examples [00:28, 1767.92 examples/s]\u001b[A\n",
      "Generating train examples...: 48710 examples [00:29, 1763.15 examples/s]\u001b[A\n",
      "Generating train examples...: 48901 examples [00:29, 1767.30 examples/s]\u001b[A\n",
      "Generating train examples...: 49088 examples [00:29, 1771.78 examples/s]\u001b[A\n",
      "Generating train examples...: 49275 examples [00:29, 1775.66 examples/s]\u001b[A\n",
      "Generating train examples...: 49460 examples [00:29, 1776.90 examples/s]\u001b[A\n",
      "Generating train examples...: 49646 examples [00:29, 1782.00 examples/s]\u001b[A\n",
      "Generating train examples...: 49832 examples [00:29, 1784.52 examples/s]\u001b[A\n",
      "Generating train examples...: 50018 examples [00:29, 1787.94 examples/s]\u001b[A\n",
      "Generating train examples...: 50202 examples [00:29, 1784.45 examples/s]\u001b[A\n",
      "Generating train examples...: 50386 examples [00:29, 1782.45 examples/s]\u001b[A\n",
      "Generating train examples...: 50573 examples [00:30, 1779.73 examples/s]\u001b[A\n",
      "Generating train examples...: 50757 examples [00:30, 1775.37 examples/s]\u001b[A\n",
      "Generating train examples...: 50941 examples [00:30, 1774.71 examples/s]\u001b[A\n",
      "Generating train examples...: 51127 examples [00:30, 1781.33 examples/s]\u001b[A\n",
      "Generating train examples...: 51312 examples [00:30, 1782.65 examples/s]\u001b[A\n",
      "Generating train examples...: 51496 examples [00:30, 1782.16 examples/s]\u001b[A\n",
      "Generating train examples...: 51681 examples [00:30, 1779.98 examples/s]\u001b[A\n",
      "Generating train examples...: 51868 examples [00:30, 1787.85 examples/s]\u001b[A\n",
      "Generating train examples...: 52053 examples [00:30, 1786.59 examples/s]\u001b[A\n",
      "Generating train examples...: 52242 examples [00:31, 1790.56 examples/s]\u001b[A\n",
      "Generating train examples...: 52431 examples [00:31, 1793.11 examples/s]\u001b[A\n",
      "Generating train examples...: 52618 examples [00:31, 1788.91 examples/s]\u001b[A\n",
      "Generating train examples...: 52804 examples [00:31, 1787.56 examples/s]\u001b[A\n",
      "Generating train examples...: 52990 examples [00:31, 1787.40 examples/s]\u001b[A\n",
      "Generating train examples...: 53178 examples [00:31, 1773.15 examples/s]\u001b[A\n",
      "Generating train examples...: 53358 examples [00:31, 1759.02 examples/s]\u001b[A\n",
      "Generating train examples...: 53543 examples [00:31, 1764.95 examples/s]\u001b[A\n",
      "Generating train examples...: 53729 examples [00:31, 1767.56 examples/s]\u001b[A\n",
      "Generating train examples...: 53916 examples [00:31, 1772.33 examples/s]\u001b[A\n",
      "Generating train examples...: 54101 examples [00:32, 1775.63 examples/s]\u001b[A\n",
      "Generating train examples...: 54286 examples [00:32, 1778.60 examples/s]\u001b[A\n",
      "Generating train examples...: 54472 examples [00:32, 1781.09 examples/s]\u001b[A\n",
      "Generating train examples...: 54658 examples [00:32, 1780.38 examples/s]\u001b[A\n",
      "Generating train examples...: 54843 examples [00:32, 1778.57 examples/s]\u001b[A\n",
      "Generating train examples...: 55029 examples [00:32, 1782.85 examples/s]\u001b[A\n",
      "Generating train examples...: 55208 examples [00:32, 1776.55 examples/s]\u001b[A\n",
      "Generating train examples...: 55386 examples [00:32, 1758.18 examples/s]\u001b[A\n",
      "Generating train examples...: 55574 examples [00:32, 1755.89 examples/s]\u001b[A\n",
      "Generating train examples...: 55758 examples [00:32, 1760.46 examples/s]\u001b[A\n",
      "Generating train examples...: 55942 examples [00:33, 1765.43 examples/s]\u001b[A\n",
      "Generating train examples...: 56133 examples [00:33, 1770.14 examples/s]\u001b[A\n",
      "Generating train examples...: 56318 examples [00:33, 1773.81 examples/s]\u001b[A\n",
      "Generating train examples...: 56506 examples [00:33, 1783.88 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train examples...: 56690 examples [00:33, 1780.40 examples/s]\u001b[A\n",
      "Generating train examples...: 56878 examples [00:33, 1785.32 examples/s]\u001b[A\n",
      "Generating train examples...: 57064 examples [00:33, 1766.13 examples/s]\u001b[A\n",
      "Generating train examples...: 57242 examples [00:33, 1758.44 examples/s]\u001b[A\n",
      "Generating train examples...: 57428 examples [00:33, 1767.87 examples/s]\u001b[A\n",
      "Generating train examples...: 57613 examples [00:34, 1772.33 examples/s]\u001b[A\n",
      "Generating train examples...: 57808 examples [00:34, 1782.16 examples/s]\u001b[A\n",
      "Generating train examples...: 57994 examples [00:34, 1784.04 examples/s]\u001b[A\n",
      "Generating train examples...: 58180 examples [00:34, 1789.08 examples/s]\u001b[A\n",
      "Generating train examples...: 58368 examples [00:34, 1793.15 examples/s]\u001b[A\n",
      "Generating train examples...: 58554 examples [00:34, 1793.95 examples/s]\u001b[A\n",
      "Generating train examples...: 58738 examples [00:34, 1787.96 examples/s]\u001b[A\n",
      "Generating train examples...: 58921 examples [00:34, 1780.99 examples/s]\u001b[A\n",
      "Generating train examples...: 59105 examples [00:34, 1774.16 examples/s]\u001b[A\n",
      "Generating train examples...: 59290 examples [00:34, 1777.40 examples/s]\u001b[A\n",
      "Generating train examples...: 59476 examples [00:35, 1777.61 examples/s]\u001b[A\n",
      "Generating train examples...: 59666 examples [00:35, 1779.41 examples/s]\u001b[A\n",
      "Generating train examples...: 59852 examples [00:35, 1782.86 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:   \u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:  1\u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:  2\u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:  3\u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:  5\u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:  6\u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:  8\u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-train.tfrecord*...:  9\u001b[A\n",
      "Generating splits...:  50%|████████████████████████████▌                            | 1/2 [00:36<00:36, 36.20s/ splits]\u001b[A\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 167 examples [00:00, 1621.92 examples/s]\u001b[A\n",
      "Generating test examples...: 351 examples [00:00, 1709.70 examples/s]\u001b[A\n",
      "Generating test examples...: 533 examples [00:00, 1711.39 examples/s]\u001b[A\n",
      "Generating test examples...: 719 examples [00:00, 1736.19 examples/s]\u001b[A\n",
      "Generating test examples...: 905 examples [00:00, 1752.42 examples/s]\u001b[A\n",
      "Generating test examples...: 1091 examples [00:00, 1768.19 examples/s]\u001b[A\n",
      "Generating test examples...: 1277 examples [00:00, 1778.14 examples/s]\u001b[A\n",
      "Generating test examples...: 1463 examples [00:00, 1783.62 examples/s]\u001b[A\n",
      "Generating test examples...: 1652 examples [00:00, 1789.42 examples/s]\u001b[A\n",
      "Generating test examples...: 1838 examples [00:01, 1791.26 examples/s]\u001b[A\n",
      "Generating test examples...: 2025 examples [00:01, 1794.83 examples/s]\u001b[A\n",
      "Generating test examples...: 2211 examples [00:01, 1794.86 examples/s]\u001b[A\n",
      "Generating test examples...: 2397 examples [00:01, 1795.42 examples/s]\u001b[A\n",
      "Generating test examples...: 2584 examples [00:01, 1799.69 examples/s]\u001b[A\n",
      "Generating test examples...: 2770 examples [00:01, 1798.44 examples/s]\u001b[A\n",
      "Generating test examples...: 2959 examples [00:01, 1797.75 examples/s]\u001b[A\n",
      "Generating test examples...: 3146 examples [00:01, 1801.27 examples/s]\u001b[A\n",
      "Generating test examples...: 3331 examples [00:01, 1798.07 examples/s]\u001b[A\n",
      "Generating test examples...: 3518 examples [00:01, 1800.99 examples/s]\u001b[A\n",
      "Generating test examples...: 3705 examples [00:02, 1800.84 examples/s]\u001b[A\n",
      "Generating test examples...: 3891 examples [00:02, 1798.05 examples/s]\u001b[A\n",
      "Generating test examples...: 4081 examples [00:02, 1798.90 examples/s]\u001b[A\n",
      "Generating test examples...: 4267 examples [00:02, 1792.59 examples/s]\u001b[A\n",
      "Generating test examples...: 4454 examples [00:02, 1795.22 examples/s]\u001b[A\n",
      "Generating test examples...: 4637 examples [00:02, 1790.60 examples/s]\u001b[A\n",
      "Generating test examples...: 4826 examples [00:02, 1794.90 examples/s]\u001b[A\n",
      "Generating test examples...: 5013 examples [00:02, 1798.45 examples/s]\u001b[A\n",
      "Generating test examples...: 5209 examples [00:02, 1795.21 examples/s]\u001b[A\n",
      "Generating test examples...: 5395 examples [00:03, 1790.35 examples/s]\u001b[A\n",
      "Generating test examples...: 5579 examples [00:03, 1785.57 examples/s]\u001b[A\n",
      "Generating test examples...: 5765 examples [00:03, 1788.59 examples/s]\u001b[A\n",
      "Generating test examples...: 5950 examples [00:03, 1785.71 examples/s]\u001b[A\n",
      "Generating test examples...: 6135 examples [00:03, 1786.12 examples/s]\u001b[A\n",
      "Generating test examples...: 6320 examples [00:03, 1787.59 examples/s]\u001b[A\n",
      "Generating test examples...: 6507 examples [00:03, 1786.82 examples/s]\u001b[A\n",
      "Generating test examples...: 6694 examples [00:03, 1793.10 examples/s]\u001b[A\n",
      "Generating test examples...: 6879 examples [00:03, 1790.66 examples/s]\u001b[A\n",
      "Generating test examples...: 7065 examples [00:03, 1792.06 examples/s]\u001b[A\n",
      "Generating test examples...: 7250 examples [00:04, 1791.38 examples/s]\u001b[A\n",
      "Generating test examples...: 7434 examples [00:04, 1787.09 examples/s]\u001b[A\n",
      "Generating test examples...: 7621 examples [00:04, 1787.32 examples/s]\u001b[A\n",
      "Generating test examples...: 7805 examples [00:04, 1781.54 examples/s]\u001b[A\n",
      "Generating test examples...: 7987 examples [00:04, 1773.89 examples/s]\u001b[A\n",
      "Generating test examples...: 8172 examples [00:04, 1771.83 examples/s]\u001b[A\n",
      "Generating test examples...: 8357 examples [00:04, 1775.75 examples/s]\u001b[A\n",
      "Generating test examples...: 8542 examples [00:04, 1777.30 examples/s]\u001b[A\n",
      "Generating test examples...: 8722 examples [00:04, 1741.37 examples/s]\u001b[A\n",
      "Generating test examples...: 8906 examples [00:04, 1746.43 examples/s]\u001b[A\n",
      "Generating test examples...: 9091 examples [00:05, 1756.79 examples/s]\u001b[A\n",
      "Generating test examples...: 9277 examples [00:05, 1761.67 examples/s]\u001b[A\n",
      "Generating test examples...: 9458 examples [00:05, 1755.51 examples/s]\u001b[A\n",
      "Generating test examples...: 9643 examples [00:05, 1757.95 examples/s]\u001b[A\n",
      "Generating test examples...: 9828 examples [00:05, 1765.24 examples/s]\u001b[A\n",
      "                                                                      \u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-test.tfrecord*...:   0\u001b[A\n",
      "Shuffling D:\\KeepStudy\\0_Coding\\0_dataset\\tensorflow_datasets\\mnist\\3.0.1.incomplete80L76R\\mnist-test.tfrecord*...:  81\u001b[A\n",
      "                                                                                                                       \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "<_OptionsDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "ds = tfds.load('mnist', \n",
    "               split='train', \n",
    "               shuffle_files=True,\n",
    "               data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\")\n",
    "\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "# 用于验证自己前面下载过的一个 mnist 数据集，在路径 D:/KeepStudy/0_Coding/0_dataset/ 之下。\n",
    "# 从运行结果来看，初步判断这两个数据集是一样的。\n",
    "ds = tfds.load('mnist', \n",
    "               split='train', \n",
    "               shuffle_files=True,\n",
    "               data_dir=\"D:/KeepStudy/0_Coding/0_dataset/\")\n",
    "\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common arguments:\n",
    "\n",
    "*   `split=`: Which split to read (e.g. `'train'`, `['train', 'test']`, `'train[80%:]'`,...). See our [split API guide](https://www.tensorflow.org/datasets/splits).\n",
    "*   `shuffle_files=`: <font color=maroon>Control whether to shuffle the files between each epoch (**TFDS store big datasets in multiple smaller files**).</font>\n",
    "*   `data_dir=`: Location where the dataset is saved (\n",
    "defaults to `~/tensorflow_datasets/`)\n",
    "*   `with_info=True`: Returns the `tfds.core.DatasetInfo` containing dataset metadata\n",
    "*   `download=False`: Disable download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfds.builder\n",
    "\n",
    "<font size=3 color=maroon>`tfds.load` is a thin wrapper around `tfds.core.DatasetBuilder`. You can get the same output using the `tfds.core.DatasetBuilder` API:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "builder = tfds.builder('mnist')\n",
    "# 1. Create the tfrecord files (no-op if already exists)\n",
    "# 锐平：下载下来的文件组织形式与 tfds.load('mnist') 下载下来的不一样\n",
    "builder.download_and_prepare(download_dir=\n",
    "                             \"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/mnist_builer\")\n",
    "\n",
    "# 2. Load the `tf.data.Dataset`\n",
    "ds = builder.as_dataset(split='train', shuffle_files=True)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tfds build` CLI\n",
    "\n",
    "<font size=3 color=maroon>If you want to generate a specific dataset, you can use the [`tfds` command line](https://www.tensorflow.org/datasets/cli). \n",
    "\n",
    "For example:</font>\n",
    "\n",
    "```sh\n",
    "tfds build mnist\n",
    "```\n",
    "\n",
    "See [the doc](https://www.tensorflow.org/datasets/cli) for available flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As dict\n",
    "\n",
    "<font size=3 color=maroon>By default, the `tf.data.Dataset` object contains a `dict` of `tf.Tensor`s:</font>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'label']\n",
      "(28, 28, 1) tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ds = tfds.load('mnist', \n",
    "               split='train', \n",
    "               data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets\")\n",
    "\n",
    "ds = ds.take(1)      # Only take a single example\n",
    "\n",
    "for example in ds:   # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    print(list(example.keys()))\n",
    "    image = example[\"image\"]\n",
    "    label = example[\"label\"]\n",
    "    print(image.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>To find out the `dict` key names and structure, look at the dataset documentation in [our catalog](https://www.tensorflow.org/datasets/catalog/overview#all_datasets).<br><br>\n",
    "For example: [mnist documentation](https://www.tensorflow.org/datasets/catalog/mnist).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As tuple (`as_supervised=True`)\n",
    "\n",
    "<font size=3 color=maroon>By using `as_supervised=True`, you can get a tuple `(features, label)` instead for supervised datasets.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1) tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ds = tfds.load('mnist', \n",
    "               split='train', \n",
    "               as_supervised=True,\n",
    "               data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\")\n",
    "\n",
    "ds = ds.take(1)\n",
    "\n",
    "for image, label in ds:  # example is (image, label)\n",
    "    print(image.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As numpy (`tfds.as_numpy`)\n",
    "\n",
    "Uses `tfds.as_numpy` to convert:\n",
    "\n",
    "*   `tf.Tensor` -> `np.array`\n",
    "*   `tf.data.Dataset` -> `Iterator[Tree[np.array]]` (`Tree` can be arbitrary nested `Dict`, `Tuple`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'> 4\n"
     ]
    }
   ],
   "source": [
    "ds = tfds.load('mnist', \n",
    "               split='train', \n",
    "               as_supervised=True,\n",
    "               data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\")\n",
    "\n",
    "ds = ds.take(1)\n",
    "\n",
    "for image, label in tfds.as_numpy(ds):\n",
    "    print(type(image), type(label), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As batched tf.Tensor (`batch_size=-1`)\n",
    "\n",
    "<font size=3 color=maroon>By using `batch_size=-1`, you can load the full dataset in a single batch.\n",
    "\n",
    "This can be combined with `as_supervised=True` and `tfds.as_numpy` to get the the data as `(np.array, np.array)`:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "image, label = tfds.as_numpy(tfds.load('mnist',\n",
    "                                       split='test',\n",
    "                                       batch_size=-1,\n",
    "                                       as_supervised=True,\n",
    "                                       data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\"))\n",
    "\n",
    "print(type(image), image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>Be careful that your dataset can fit in memory, and that all examples have the same shape.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark your datasets\n",
    "\n",
    "<font size=3 color=maroon>Benchmarking a dataset is a simple `tfds.benchmark` call on any iterable (e.g. `tf.data.Dataset`, `tfds.as_numpy`,...).</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:00<00:00, 2373.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 73405.56 ex/sec (total: 60000 ex, 0.82 sec)\n",
      "Examples/sec (First only) 1229.33 ex/sec (total: 32 ex, 0.03 sec)\n",
      "Examples/sec (First excluded) 75779.72 ex/sec (total: 59968 ex, 0.79 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1875/1875 [00:00<00:00, 12330.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 361599.57 ex/sec (total: 60000 ex, 0.17 sec)\n",
      "Examples/sec (First only) 2555.54 ex/sec (total: 32 ex, 0.01 sec)\n",
      "Examples/sec (First excluded) 390906.32 ex/sec (total: 59968 ex, 0.15 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>0.165929</td>\n",
       "      <td>60000</td>\n",
       "      <td>361599.571866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.012522</td>\n",
       "      <td>32</td>\n",
       "      <td>2555.543133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>0.153408</td>\n",
       "      <td>59968</td>\n",
       "      <td>390906.317549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=             duration  num_examples            avg\n",
       "first+lasts  0.165929         60000  361599.571866\n",
       "first        0.012522            32    2555.543133\n",
       "lasts        0.153408         59968  390906.317549, raw_stats=                     duration\n",
       "start_time        3059.181794\n",
       "first_batch_time  3059.194316\n",
       "end_time          3059.347723\n",
       "num_iter          1875.000000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tfds.load('mnist', \n",
    "               split='train',\n",
    "               data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\")\n",
    "\n",
    "ds = ds.batch(32).prefetch(1)\n",
    "\n",
    "tfds.benchmark(ds, batch_size=32)\n",
    "tfds.benchmark(ds, batch_size=32)  # Second epoch much faster due to auto-caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>\n",
    "    \n",
    "* Do not forget to normalize the results per batch size with the `batch_size=` kwarg.\n",
    "<br><br>\n",
    "* In the summary, the first warmup batch is separated from the other ones to capture `tf.data.Dataset` extra setup time (e.g. buffers initialization,...).\n",
    "<br><br>\n",
    "* Notice how the second iteration is much faster due to [TFDS auto-caching](https://www.tensorflow.org/datasets/performances#auto-caching).\n",
    "<br><br>\n",
    "* `tfds.benchmark` returns a `tfds.core.BenchmarkResult` which can be inspected for further analysis.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build end-to-end pipeline\n",
    "\n",
    "To go further, you can look:\n",
    "\n",
    "*   Our [end-to-end Keras example](https://www.tensorflow.org/datasets/keras_example) to see a full training pipeline (with batching, shuffling,...).\n",
    "*   Our [performance guide](https://www.tensorflow.org/datasets/performances) to improve the speed of your pipelines (tip: use `tfds.benchmark(ds)` to benchmark your datasets).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "### tfds.as_dataframe\n",
    "\n",
    "<font size=3 color=maroon>`tf.data.Dataset` objects can be converted to [`pandas.DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) with `tfds.as_dataframe` to be visualized on [Colab](https://colab.research.google.com).\n",
    "\n",
    "* Add the `tfds.core.DatasetInfo` as second argument of `tfds.as_dataframe` to visualize images, audio, texts, videos,...\n",
    "* Use `ds.take(x)` to only display the first `x` examples. `pandas.DataFrame` will load the full dataset in-memory, and can be very expensive to display.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_fd2ba\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd2ba_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_fd2ba_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd2ba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fd2ba_row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fd2ba_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd2ba_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fd2ba_row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGOyAc/5KJlxyjIv+/TPEJan9798HWRgH3YhQBoZHj3HpfP/vVxQuOYF//54ieGjGNjEwXMalkeHbv3+eeCTfseAy1oCVYeofXBp3/f8lgUtO/su/azhtnPLvXwJOycv//uGU0//5bx1OySP//hngkuN5+u8tG4oIkj/VJBmO/8Il6cvAMBunlSIvX3DjlKQmAACHtTHZmy2LVAAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fd2ba_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd2ba_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fd2ba_row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nM3QvyuEARzH8feVniSFiTBcKf8A85ESNqwkdbeY5NdmY/UXiM0z+Ad0SXZ1g0vJjw0Xi86pc13eD8NleJ47q3zG76tv3x/wJxk+jQ7bf8NldT9obdNl1fWW1nGh6mtLPIm0oJVWlvuIvOvMWx1qtqWa0U2aULNNNnCtT+MQapi0waK6CoR6mcS8Wuhq4Fqj1PZjU5NQnX0DUine433dD1qZBwjOrM/EsVc9AmCj6c5MWT8XADjX2mgMi+otABN1k0/YVncAFu/VLWLbPgNBduRxLBMQHe/FZ+Zs5EtLm8kP9F81MHrZTScNelZK6sFcXzP9o3wDadaKxdoXqEQAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fd2ba_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd2ba_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fd2ba_row3_col0\" class=\"data row3 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA40lEQVR4nGNgGJpg//8OdCEWKM2obvgv/++6/zcZnJQebPuNqkjvLxI4IIgiJ3/v79/3b//9/fvv7993f/9NQzE2TZ6hc8J3JwYGBgaGK7cYeJE12n79+1cCxlH9+/cVB5LOlxy/pryHSUYyMO78gSR5W/vzU7gxfAz/cfq36fvfDw445Fr+/P3bg12KMebb37+7WbDKKSz89/fvNRmscjpb//79u0YBq5z0yb9//2bhcEvXv78fs1ixyzX//PsuHYc+gbvwAMcEmX//3kFzJxOc9YCRoesJLp3sx9+p4JIjGQAAnrpmBs0pxioAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fd2ba_row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
       "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
       "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      0\n",
       "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds, info = tfds.load('mnist', \n",
    "                     split='train', \n",
    "                     with_info=True,\n",
    "                     data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\")\n",
    "\n",
    "tfds.as_dataframe(ds.take(4), info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfds.show_examples\n",
    "\n",
    "<font size=3 color=maroon>`tfds.show_examples` returns a `matplotlib.figure.Figure` (only image datasets supported now):</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds, info = tfds.load('mnist', \n",
    "                     split='train', \n",
    "                     with_info=True,\n",
    "                     data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\")\n",
    "\n",
    "fig = tfds.show_examples(ds, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the dataset metadata\n",
    "\n",
    "<font size=3 color=maroon>All builders include a `tfds.core.DatasetInfo` object containing the dataset metadata.\n",
    "\n",
    "It can be accessed through:<br><br>\n",
    "\n",
    "*   The `tfds.load` API:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('mnist', \n",
    "                     with_info=True,\n",
    "                     data_dir=\"D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_path='D:/KeepStudy/0_Coding/0_dataset/tensorflow_datasets/mnist\\\\3.0.1',\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>\n",
    "\n",
    "*   The `tfds.core.DatasetBuilder` API:\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = tfds.builder('mnist')\n",
    "info = builder.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_path='C:\\\\Users\\\\18617\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info\n",
    "# 注意到下面的 data_path 与上面 tfds.load() 的方式不一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=maroon>The dataset info contains additional informations about the dataset (version, citation, homepage, description,...).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features metadata (label names, image shape,...)\n",
    "\n",
    "Access the `tfds.features.FeatureDict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of classes, label names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(info.features[\"label\"].num_classes)\n",
    "print(info.features[\"label\"].names)\n",
    "print(info.features[\"label\"].int2str(7))   # Human readable version (8 -> 'cat')\n",
    "print(info.features[\"label\"].str2int('7'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes, dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': (28, 28, 1), 'label': ()}\n",
      "{'image': tf.uint8, 'label': tf.int64}\n",
      "(28, 28, 1)\n",
      "<dtype: 'uint8'>\n"
     ]
    }
   ],
   "source": [
    "print(info.features.shape)\n",
    "print(info.features.dtype)\n",
    "print(info.features['image'].shape)\n",
    "print(info.features['image'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split metadata (e.g. split names, number of examples,...)\n",
    "\n",
    "Access the `tfds.core.SplitDict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <SplitInfo num_examples=60000, num_shards=1>, 'test': <SplitInfo num_examples=10000, num_shards=1>}\n"
     ]
    }
   ],
   "source": [
    "print(info.splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test']\n"
     ]
    }
   ],
   "source": [
    "print(list(info.splits.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info on individual split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "['mnist-train.tfrecord-00000-of-00001']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(info.splits['train'].num_examples)\n",
    "print(info.splits['train'].filenames)\n",
    "print(info.splits['train'].num_shards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also works with the subsplit API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n",
      "[FileInstruction(filename='mnist-train.tfrecord-00000-of-00001', skip=9000, take=36000, num_examples=36000)]\n"
     ]
    }
   ],
   "source": [
    "print(info.splits['train[15%:75%]'].num_examples)\n",
    "print(info.splits['train[15%:75%]'].file_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Manual download (if download fails)\n",
    "\n",
    "If download fails for some reason (e.g. offline,...). You can always manually download the data yourself and place it in the `manual_dir` (defaults to `~/tensorflow_datasets/download/manual/`.\n",
    "\n",
    "To find out which urls to download, look into:\n",
    "\n",
    " * For new datasets (implemented as folder): [`tensorflow_datasets/`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/)`<type>/<dataset_name>/checksums.tsv`. <br>\n",
    " \n",
    "   For example: [`tensorflow_datasets/text/bool_q/checksums.tsv`](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/text/bool_q/checksums.tsv).\n",
    "\n",
    "   You can find the dataset source location in [our catalog](https://www.tensorflow.org/datasets/catalog/overview).\n",
    "\n",
    "\n",
    " * For old datasets: [`tensorflow_datasets/url_checksums/<dataset_name>.txt`](https://github.com/tensorflow/datasets/tree/master/tensorflow_datasets/url_checksums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing `NonMatchingChecksumError`\n",
    "\n",
    "TFDS ensure determinism by validating the checksums of downloaded urls.<br>\n",
    "If `NonMatchingChecksumError` is raised, might indicate:\n",
    "\n",
    "  * The website may be down (e.g. `503 status code`). Please check the url.\n",
    "  * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See [bug](https://github.com/tensorflow/datasets/issues/1482)\n",
    "  * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated. Please open a new Github issue or PR:\n",
    "     * Register the new checksums with `tfds build --register_checksums`\n",
    "     * Eventually update the dataset generation code.\n",
    "     * Update the dataset `VERSION`\n",
    "     * Update the dataset `RELEASE_NOTES`: What caused the checksums to change ? Did some examples changed ?\n",
    "     * Make sure the dataset can still be built.\n",
    "     * Send us a PR\n",
    "\n",
    "Note: You can also inspect the downloaded file in `~/tensorflow_datasets/download/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "If you're using `tensorflow-datasets` for a paper, please include the following citation, in addition to any citation specific to the used datasets (which can be found in the [dataset catalog](https://www.tensorflow.org/datasets/catalog/overview)).\n",
    "\n",
    "```\n",
    "@misc{TFDS,\n",
    "  title = { {TensorFlow Datasets}, A collection of ready-to-use datasets},\n",
    "  howpublished = {\\url{https://www.tensorflow.org/datasets}},\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfg]",
   "language": "python",
   "name": "conda-env-tfg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
