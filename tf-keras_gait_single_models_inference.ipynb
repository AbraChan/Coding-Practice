{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**References**:\n* `JOSEPH JOSIA`'s notebook: <a href=\"https://www.kaggle.com/code/takanashihumbert/gait-single-models-inference/notebook\" style=\"text-decoration:none\">Gait Single Models [inference]</a>\n* `JOSEPH JOSIA`'s post: <a href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/415975\" style=\"text-decoration:none\">21st place solution: Conv1d with denoising</a>","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport gc\nimport glob\nimport pickle\nimport joblib\n\nfrom tqdm.auto import tqdm\nfrom time import perf_counter\nfrom collections import defaultdict as dd\n# from os.path import basename, dirname, join, exists\n\nimport math\nimport numpy as np\nimport pandas as pd\n\nimport pywt\nimport scipy\n\nfrom scipy import signal\nfrom scipy.signal import butter\nfrom scipy.special import expit\nfrom statsmodels.robust import mad\n\nfrom functools import partial\nfrom numpy.random import default_rng\n\nfrom colorama import Fore, Back, Style\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedGroupKFold\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.cluster import KMeans\n\nimport catboost as ctb\nimport xgboost as xgb\nimport lightgbm as lgb\n\nimport tensorflow as tf\nprint(f\"TF version: {tf.__version__}\")\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:05.416058Z","iopub.execute_input":"2023-06-09T08:49:05.416470Z","iopub.status.idle":"2023-06-09T08:49:10.346131Z","shell.execute_reply.started":"2023-06-09T08:49:05.416437Z","shell.execute_reply":"2023-06-09T08:49:10.344813Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"TF version: 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"def madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.347936Z","iopub.execute_input":"2023-06-09T08:49:10.348752Z","iopub.status.idle":"2023-06-09T08:49:10.353513Z","shell.execute_reply.started":"2023-06-09T08:49:10.348694Z","shell.execute_reply":"2023-06-09T08:49:10.352760Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def wavelet_denoising_1(x, wavelet='db4', level=1):\n    coeffs = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * madev(coeffs[-level])\n    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n    coeffs[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeffs[1:])\n    result = pywt.waverec(coeffs, wavelet, mode='per')\n    if len(x)%2==1:\n        result = result[:-1]\n    return result\n\n\n\n\ndef wavelet_denoising_2(x, wavelet='db4'):\n    coeffs = pywt.wavedec(x, wavelet, mode=\"per\")\n    coeffs[len(coeffs)-1] *= 0\n    coeffs[len(coeffs)-2] *= 0\n    result = pywt.waverec(coeffs, wavelet, mode='per')\n    if len(x)%2==1:\n        result = result[:-1]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.354943Z","iopub.execute_input":"2023-06-09T08:49:10.355490Z","iopub.status.idle":"2023-06-09T08:49:10.367695Z","shell.execute_reply.started":"2023-06-09T08:49:10.355453Z","shell.execute_reply":"2023-06-09T08:49:10.366622Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def sgn(num):\n    if(num > 0.0):\n        return 1.0\n    elif(num == 0.0):\n        return 0.0\n    else:\n        return -1.0","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.370159Z","iopub.execute_input":"2023-06-09T08:49:10.370488Z","iopub.status.idle":"2023-06-09T08:49:10.378725Z","shell.execute_reply.started":"2023-06-09T08:49:10.370453Z","shell.execute_reply":"2023-06-09T08:49:10.377842Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def wavelet_denoising_3(x, wavelet='dB10'):\n    ca3, cd3, cd2, cd1 = pywt.wavedec(x, wavelet, level=3, mode=\"per\")  # 3层小波分解\n\n    abs_cd1 = np.abs(np.array(cd1))\n    median_cd1 = np.median(abs_cd1)\n\n    length0 = len(x)\n    sigma = (1.0 / 0.6745) * median_cd1\n    lamda = sigma * math.sqrt(2.0 * math.log(float(length0), math.e))\n    usecoeffs = []\n    usecoeffs.append(ca3)\n\n    length1 = len(cd1)\n    for k in range(length1):\n        if (abs(cd1[k]) >= lamda/np.log2(2)):\n            cd1[k] = sgn(cd1[k]) * (abs(cd1[k]) - lamda/np.log2(2))\n        else:\n            cd1[k] = 0.0\n    \n    length2 = len(cd2)\n    for k in range(length2):\n        if (abs(cd2[k]) >= lamda/np.log2(3)):\n            cd2[k] = sgn(cd2[k]) * (abs(cd2[k]) - lamda/np.log2(3))\n        else:\n            cd2[k] = 0.0\n\n    length3 = len(cd3)\n    for k in range(length3):\n        if (abs(cd3[k]) >= lamda/np.log2(4)):\n            cd3[k] = sgn(cd3[k]) * (abs(cd3[k]) - lamda/np.log2(4))\n        else:\n            cd3[k] = 0.0\n    \n    \n    usecoeffs.append(cd3)\n    usecoeffs.append(cd2)\n    usecoeffs.append(cd1)\n    result = pywt.waverec(usecoeffs, wavelet, mode=\"per\") #信号重构\n    \n    if len(x)%2==1:\n        result = result[:-1]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.380100Z","iopub.execute_input":"2023-06-09T08:49:10.380396Z","iopub.status.idle":"2023-06-09T08:49:10.392842Z","shell.execute_reply.started":"2023-06-09T08:49:10.380366Z","shell.execute_reply":"2023-06-09T08:49:10.391923Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<br>","metadata":{}},{"cell_type":"code","source":"# Constants\nBASE_DIR = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction\"\nTRAIN_DIR = os.path.join(BASE_DIR, \"train\")\nTEST_DIR = os.path.join(BASE_DIR, \"test\")\n\nIS_PUBLIC = len(glob.glob(os.path.join(TEST_DIR, \"*/*.csv\")))==2","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.394068Z","iopub.execute_input":"2023-06-09T08:49:10.395030Z","iopub.status.idle":"2023-06-09T08:49:10.412443Z","shell.execute_reply.started":"2023-06-09T08:49:10.395000Z","shell.execute_reply":"2023-06-09T08:49:10.411101Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"IS_PUBLIC","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.413843Z","iopub.execute_input":"2023-06-09T08:49:10.414933Z","iopub.status.idle":"2023-06-09T08:49:10.423516Z","shell.execute_reply.started":"2023-06-09T08:49:10.414891Z","shell.execute_reply":"2023-06-09T08:49:10.422397Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"class Config:\n    train_sub_dirs = [os.path.join(TRAIN_DIR, \"defog\"),\n                      os.path.join(TRAIN_DIR, \"tdcsfog\")\n                     ]\n    \n    metadata_paths = [os.path.join(BASE_DIR, \"defog_metadata.csv\"),\n                      os.path.join(BASE_DIR, \"tdcsfog_metadata.csv\")\n                     ]\n    \n    splits = 5\n    batch_size = 1024\n    \n    defog_window_size = 200\n    defog_window_future = 50\n    defog_window_past = defog_window_size - defog_window_future\n    tdcsfog_window_size = 256\n    tdcsfog_window_future = 64\n    tdcsfog_window_past = tdcsfog_window_size - tdcsfog_window_future\n    \n    wx = 3\n    \n    model_dropout = 0.2\n    model_hidden = 128\n    model_nblocks = 2\n    \n    lr = 0.0002\n    num_epochs = 5\n    \n    feature_list = ['Time_frac', 'AccV', 'AccML', 'AccAP', 'V_ML', 'V_AP', 'ML_AP']\n    label_list = ['StartHesitation', 'Turn', 'Walking', 'Normal']\n    \n    n_features = len(feature_list)\n    n_labels = len(label_list)    \n    \ncfg = Config()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.425099Z","iopub.execute_input":"2023-06-09T08:49:10.425440Z","iopub.status.idle":"2023-06-09T08:49:10.436140Z","shell.execute_reply.started":"2023-06-09T08:49:10.425403Z","shell.execute_reply":"2023-06-09T08:49:10.435083Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class FOGSequence(tf.keras.utils.Sequence):\n    def __init__(self, df_paths, module, cfg=cfg, split=\"train\"):\n        \n        _time = perf_counter()\n        \n        self.rng = default_rng(42)\n        self.cfg = cfg\n        self.split = split\n        self.module = module\n        \n        if self.module=='defog':\n            self.past_pad = self.cfg.wx * (self.cfg.defog_window_past-1)\n            self.future_pad = self.cfg.wx * self.cfg.defog_window_future\n        else:\n            self.past_pad = self.cfg.wx * (self.cfg.tdcsfog_window_past-1)\n            self.future_pad = self.cfg.wx * self.cfg.tdcsfog_window_future\n        \n        \n        if self.split == \"test\":\n            self.Ids = []\n            self.Time_frac = []\n            \n        _values = [self._read(f) for f in df_paths]\n        \n        self.mapping = []\n        _length = 0\n        for _value in _values:\n            _shape = _value.shape[0]\n            self.mapping.extend(range(_length+self.past_pad, _length+_shape-self.future_pad))\n            _length += _shape\n            \n        self.values = np.concatenate(_values, axis=0)\n        self.mapping = np.array(self.mapping)\n        if self.split != \"test\":\n            # Keep only vaild and task rows\n            _valid_pos = self.values[self.mapping, self.valid_position] > 0\n            _task_pos = self.values[self.mapping, self.task_position] > 0\n            self.mapping = self.mapping[_valid_pos&_task_pos]\n        self.length = self.mapping.shape[0]\n        \n        if split==\"train\":\n            print(f\"Train Dataset of size {self.length:,} initialized in {perf_counter() - _time:.3f} secs!\")\n            \n        if split==\"valid\":\n            print(f\"Valid Dataset of size {self.length:,} initialized in {perf_counter() - _time:.3f} secs!\") \n        gc.collect()\n\n    \n    \n    def _read(self, path):\n        _is_tdcs = os.path.basename(os.path.dirname(path)).startswith('tdcs')\n        df = pd.read_csv(path)\n        #########\n        df['Time_frac'] = (df.index/df.index.max()).values\n        \n        if self.split == \"test\":\n            _ids = basename(path).split('.')[0] + '_' + df.Time.astype(str)\n            self.Ids.extend(_ids.tolist())\n            self.Time_frac.extend(df.Time_frac.tolist())\n            return self._df_to_array(df, self.cfg.feature_list)\n        \n        _cols = [*self.cfg.feature_list, *self.cfg.label_list, 'Valid', 'Task']\n        self.valid_position = self.cfg.n_features + self.cfg.n_labels\n        self.task_position = self.valid_position + 1\n        \n        if _is_tdcs:\n            # Fill Valid and Task columns for tdcsfog\n            df['Valid'] = 1\n            df['Task'] = 1\n            \n        return self._df_to_array(df, _cols)\n    \n    \n    \n    def _df_to_array(self, df, cols):\n        # Pads past and future rows to dataframe values for indexing\n        df['AccV'] = wavelet_denoising_2(df['AccV'], wavelet='db4')\n        df['AccML'] = wavelet_denoising_2(df['AccML'], wavelet='db4')\n        df['AccAP'] = wavelet_denoising_2(df['AccAP'], wavelet='db4')\n        df['V_ML'] = df['AccV'] - df['AccML']\n        df['V_AP'] = df['AccV'] - df['AccAP']\n        df['ML_AP'] = df['AccML'] - df['AccAP']\n        \n        df['AccV'] = (df['AccV'] - df['AccV'].mean()) / df['AccV'].std()\n        df['AccML'] = (df['AccML'] - df['AccML'].mean()) / df['AccML'].std()\n        df['AccAP'] = (df['AccAP'] - df['AccAP'].mean()) / df['AccAP'].std()\n        df['V_ML'] = (df['V_ML'] - df['V_ML'].mean()) / df['V_ML'].std()\n        df['V_AP'] = (df['V_AP'] - df['V_AP'].mean()) / df['V_AP'].std()\n        df['ML_AP'] = (df['ML_AP'] - df['ML_AP'].mean()) / df['ML_AP'].std()\n        \n        _values = df[cols].values.astype(np.float32)  # np.float32\n        \n        return np.pad(_values, ((self.past_pad, self.future_pad),(0,0)), 'edge')\n    \n    \n    \n    def __len__(self):\n        \n        return int(np.ceil(self.length / self.cfg.batch_size))\n    \n    \n    \n    def __getitem__(self, idx):\n        \n        if self.split == \"train\":\n            # Onlt train set has randomly selected batches\n            _idxs = self.rng.choice(self.mapping, size=self.cfg.batch_size, replace=False)\n        else:\n            _idxs = self._get_indices(idx)\n            \n        # For test return only features\n        if self.split == \"test\":\n            return self._get_X(_idxs)\n        # For train and val splits return y also\n        \n        return self._get_X_y(_idxs)\n    \n    \n    \n    def _get_indices(self, idx):\n        _low = idx * self.cfg.batch_size\n        # Cap high at self.length so overflow does not occur\n        _high = min(_low + self.cfg.batch_size, self.length)\n        \n        return self.mapping[_low:_high]\n    \n    \n    \n    def _get_X(self, indices):\n        if self.module=='defog':\n            _X = np.empty((len(indices), self.cfg.defog_window_size, self.cfg.n_features), dtype=np.float32)\n        else:\n            _X = np.empty((len(indices), self.cfg.tdcsfog_window_size, self.cfg.n_features), dtype=np.float32)\n        for i, idx in enumerate(indices):\n            _X[i] = self.values[idx-self.past_pad:idx+self.future_pad+1:self.cfg.wx, :self.cfg.n_features]\n            \n        return _X\n    \n    \n    \n    def _get_X_y(self, indices):\n        if self.module=='defog':\n            _X = np.empty((len(indices), self.cfg.defog_window_size, self.cfg.n_features), dtype=np.float32)\n        else:\n            _X = np.empty((len(indices), self.cfg.tdcsfog_window_size, self.cfg.n_features), dtype=np.float32)\n        for i, idx in enumerate(indices):\n            _X[i] = self.values[idx-self.past_pad: idx+self.future_pad+1:self.cfg.wx, :self.cfg.n_features]\n            \n        return _X, self.values[indices, self.cfg.n_features:self.cfg.n_features+self.cfg.n_labels]","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.437648Z","iopub.execute_input":"2023-06-09T08:49:10.438318Z","iopub.status.idle":"2023-06-09T08:49:10.466318Z","shell.execute_reply.started":"2023-06-09T08:49:10.438279Z","shell.execute_reply":"2023-06-09T08:49:10.465131Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"```python\ndef get_model(module, checkpoint_path = None):\n    if module=='defog':\n        window_size = cfg.defog_window_size\n    else:\n        window_size = cfg.tdcsfog_window_size\n        \n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.Input(shape=(window_size, cfg.n_features), dtype='float32'))\n    for i in range(cfg.model_nblocks):\n        model.add(tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=i+1, kernel_size=16-6*i, padding=\"same\"))\n        model.add(tf.keras.layers.BatchNormalization())\n        model.add(tf.keras.layers.ReLU())\n        model.add(tf.keras.layers.Dropout(cfg.model_dropout))\n    model.add(tf.keras.layers.GlobalAveragePooling1D())\n    model.add(tf.keras.layers.Dense(cfg.n_labels, activation='sigmoid'))\n    \n    if checkpoint_path is not None:\n        model.load_weights(checkpoint_path)\n    \n    model.compile(tf.keras.optimizers.Adam(learning_rate=cfg.lr), \n                  loss = tf.keras.losses.BinaryCrossentropy()\n                 )\n    \n    return model\n\n\n\ntf.keras.backend.clear_session()\nget_model('defog').summary()\n\n```","metadata":{}},{"cell_type":"code","source":"# Model adapted from https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n\ndef get_model(module, checkpoint_path = None):\n    if module == 'defog':\n        window_size = cfg.defog_window_size\n    else:\n        window_size = cfg.tdcsfog_window_size\n    \n    \n    inputs = tf.keras.Input(shape=(window_size, cfg.n_features), dtype='float32')\n    \n    \n    left = tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=1, kernel_size=4, padding=\"same\", \n                                  kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n    left = tf.keras.layers.BatchNormalization()(left)\n    \n    \n    right = tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=3, kernel_size=8, padding=\"same\", \n                                   kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n    right = tf.keras.layers.BatchNormalization()(right)\n    \n    \n    mid = tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=5, kernel_size=16, padding=\"same\", \n                                 kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n    mid = tf.keras.layers.BatchNormalization()(mid)\n    \n    \n    conb = tf.keras.layers.Concatenate(axis=1)([left, mid, right])\n    conb = tf.keras.layers.ReLU()(conb)\n    #conb = tf.keras.layers.GlobalAveragePooling1D()(conb)\n    conb = tf.keras.layers.Flatten()(conb)\n    conb = tf.keras.layers.Dropout(0.2)(conb)\n    outputs = tf.keras.layers.Dense(cfg.n_labels, activation='sigmoid')(conb)\n    \n    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n\n    if checkpoint_path is not None:\n        model.load_weights(checkpoint_path)\n        \n    model.compile(tf.keras.optimizers.Adam(learning_rate=cfg.lr), \n                  loss = tf.keras.losses.BinaryCrossentropy(),\n                 )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.469521Z","iopub.execute_input":"2023-06-09T08:49:10.469963Z","iopub.status.idle":"2023-06-09T08:49:10.483061Z","shell.execute_reply.started":"2023-06-09T08:49:10.469922Z","shell.execute_reply":"2023-06-09T08:49:10.482137Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"get_model('defog').summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:49:10.484052Z","iopub.execute_input":"2023-06-09T08:49:10.484905Z","iopub.status.idle":"2023-06-09T08:49:10.756558Z","shell.execute_reply.started":"2023-06-09T08:49:10.484875Z","shell.execute_reply":"2023-06-09T08:49:10.751966Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 200, 7)]     0           []                               \n                                                                                                  \n conv1d (Conv1D)                (None, 200, 128)     3712        ['input_1[0][0]']                \n                                                                                                  \n conv1d_2 (Conv1D)              (None, 40, 128)      14464       ['input_1[0][0]']                \n                                                                                                  \n conv1d_1 (Conv1D)              (None, 67, 128)      7296        ['input_1[0][0]']                \n                                                                                                  \n batch_normalization (BatchNorm  (None, 200, 128)    512         ['conv1d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 40, 128)     512         ['conv1d_2[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 67, 128)     512         ['conv1d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n concatenate (Concatenate)      (None, 307, 128)     0           ['batch_normalization[0][0]',    \n                                                                  'batch_normalization_2[0][0]',  \n                                                                  'batch_normalization_1[0][0]']  \n                                                                                                  \n re_lu (ReLU)                   (None, 307, 128)     0           ['concatenate[0][0]']            \n                                                                                                  \n flatten (Flatten)              (None, 39296)        0           ['re_lu[0][0]']                  \n                                                                                                  \n dropout (Dropout)              (None, 39296)        0           ['flatten[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 4)            157188      ['dropout[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 184,196\nTrainable params: 183,428\nNon-trainable params: 768\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br>\n<br>\n\n\nThe author used `StratifiedGroupKFold(y=labels, group=Subject)`. CV is around 0.32-0.34.\n\n\n## conv1d model","metadata":{"execution":{"iopub.status.busy":"2023-06-09T08:02:49.584401Z","iopub.execute_input":"2023-06-09T08:02:49.585763Z","iopub.status.idle":"2023-06-09T08:02:49.590520Z","shell.execute_reply.started":"2023-06-09T08:02:49.585697Z","shell.execute_reply":"2023-06-09T08:02:49.589405Z"}}},{"cell_type":"code","source":"# defog_ver23/\n#    fold0_model_04.h5,  fold1_model_03.h5,  fold2_model_05.h5,  fold3_model_05.h5,  fold4_model_03.h5\n# tdcsfog_ver23/\n#    fold0_model_01.h5,  fold1_model_02.h5,  fold2_model_05.h5,  fold3_model_05.h5,  fold4_model_05.h5\n\n\nmodel_paths = {'defog': [f for f in glob.glob(\"/kaggle/input/gait-cov1d-models/defog_ver23/*.h5\")],\n               'tdcsfog': [f for f in glob.glob(\"/kaggle/input/gait-cov1d-models/tdcsfog_ver23/*.h5\")],\n              }\ndisplay(model_paths)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntest_defog_paths = glob.glob(join(TEST_DIR, \"defog/*.csv\"))\ntest_tdcsfog_paths = glob.glob(join(TEST_DIR, \"tdcsfog/*.csv\"))\n\ntest_ds_dict = {'defog': FOGSequence(test_defog_paths, module='defog', split=\"test\"), \n                'tdcsfog': FOGSequence(test_tdcsfog_paths, module='tdcsfog', split=\"test\")\n               }\n\n# Get test predictions\ndf_list = []\nfor module, test_ds in test_ds_dict.items():\n    y_pred_list = []\n    for model_path in tqdm(model_paths[module]):\n        model = get_model(module, model_path)\n        y_pred_list.append(model.predict(test_ds, verbose=0, batch_size=256))\n        \n    y_pred = np.mean(y_pred_list, axis=0)\n    df_list.append(pd.DataFrame({'Id': test_ds.Ids, \n                                 'module': [module]*len(y_pred), \n                                 'Time_frac': test_ds.Time_frac, \n                                 'StartHesitation': y_pred[:,0], \n                                 'Turn': y_pred[:,1], \n                                 'Walking': y_pred[:,2]}\n                               ))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate Prediction to DataFrames\nsubmission = pd.concat(df_list)\n\n#submission.loc[((submission.Time_frac<0.01)|(submission.Time_frac>0.99))&(submission.module=='tdcsfog'), 'Walking'] = 0\n#submission.loc[(submission.Time_frac<0.01)&(submission.module=='tdcsfog'), 'Turn'] = 0\n#submission.loc[(submission.Time_frac<0.01)&(submission.module=='defog'), 'Turn'] = 0\n\n# Only keep Ids in sample_submission\nsample_submission = pd.read_csv(join(BASE_DIR, \"sample_submission.csv\"))\nsubmission = pd.merge(sample_submission[['Id']], submission, how='left', on='Id').fillna(0.0)\nsubmission[['Id','StartHesitation','Turn','Walking']].to_csv(\"submission.csv\", index=False, float_format='%.5f') # round to 5 decimal places while keeping point notation\n\ndisplay(submission.head())\ndisplay(submission.tail())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del test_ds_dict\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]}]}