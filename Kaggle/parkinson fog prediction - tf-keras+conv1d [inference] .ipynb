{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reference**:\n",
    "* `Kaggle Competition`: <a href=\"https://www.kaggle.com/competitions/amp-parkinsons-disease-progression-prediction\" style=\"text-decoration:none\">AMP®-Parkinson's Disease Progression Prediction</a>\n",
    "* \n",
    "* `JOSEPH JOSIA`'s notebook: <a href=\"https://www.kaggle.com/code/takanashihumbert/gait-single-models-inference/notebook\" style=\"text-decoration:none\">Gait Single Models [inference]</a>\n",
    "* `JOSEPH JOSIA`'s post: <a href=\"https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/415975\" style=\"text-decoration:none\">21st place solution: Conv1d with denoising</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:05.416470Z",
     "iopub.status.busy": "2023-06-09T08:49:05.416058Z",
     "iopub.status.idle": "2023-06-09T08:49:10.346131Z",
     "shell.execute_reply": "2023-06-09T08:49:10.344813Z",
     "shell.execute_reply.started": "2023-06-09T08:49:05.416437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from time import perf_counter\n",
    "from collections import defaultdict as dd\n",
    "# from os.path import basename, dirname, join, exists\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pywt\n",
    "import scipy\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import butter\n",
    "from scipy.special import expit\n",
    "from statsmodels.robust import mad\n",
    "\n",
    "from functools import partial\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import catboost as ctb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"TF version: {tf.__version__}\")\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.348752Z",
     "iopub.status.busy": "2023-06-09T08:49:10.347936Z",
     "iopub.status.idle": "2023-06-09T08:49:10.353513Z",
     "shell.execute_reply": "2023-06-09T08:49:10.352760Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.348694Z"
    }
   },
   "outputs": [],
   "source": [
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.355490Z",
     "iopub.status.busy": "2023-06-09T08:49:10.354943Z",
     "iopub.status.idle": "2023-06-09T08:49:10.367695Z",
     "shell.execute_reply": "2023-06-09T08:49:10.366622Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.355453Z"
    }
   },
   "outputs": [],
   "source": [
    "def wavelet_denoising_1(x, wavelet='db4', level=1):\n",
    "    coeffs = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/0.6745) * madev(coeffs[-level])\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "    coeffs[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeffs[1:])\n",
    "    result = pywt.waverec(coeffs, wavelet, mode='per')\n",
    "    if len(x)%2==1:\n",
    "        result = result[:-1]\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wavelet_denoising_2(x, wavelet='db4'):\n",
    "    coeffs = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    coeffs[len(coeffs)-1] *= 0\n",
    "    coeffs[len(coeffs)-2] *= 0\n",
    "    result = pywt.waverec(coeffs, wavelet, mode='per')\n",
    "    if len(x)%2==1:\n",
    "        result = result[:-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.370488Z",
     "iopub.status.busy": "2023-06-09T08:49:10.370159Z",
     "iopub.status.idle": "2023-06-09T08:49:10.378725Z",
     "shell.execute_reply": "2023-06-09T08:49:10.377842Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.370453Z"
    }
   },
   "outputs": [],
   "source": [
    "def sgn(num):\n",
    "    if(num > 0.0):\n",
    "        return 1.0\n",
    "    elif(num == 0.0):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.380396Z",
     "iopub.status.busy": "2023-06-09T08:49:10.380100Z",
     "iopub.status.idle": "2023-06-09T08:49:10.392842Z",
     "shell.execute_reply": "2023-06-09T08:49:10.391923Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.380366Z"
    }
   },
   "outputs": [],
   "source": [
    "def wavelet_denoising_3(x, wavelet='dB10'):\n",
    "    ca3, cd3, cd2, cd1 = pywt.wavedec(x, wavelet, level=3, mode=\"per\")  # 3层小波分解\n",
    "\n",
    "    abs_cd1 = np.abs(np.array(cd1))\n",
    "    median_cd1 = np.median(abs_cd1)\n",
    "\n",
    "    length0 = len(x)\n",
    "    sigma = (1.0 / 0.6745) * median_cd1\n",
    "    lamda = sigma * math.sqrt(2.0 * math.log(float(length0), math.e))\n",
    "    usecoeffs = []\n",
    "    usecoeffs.append(ca3)\n",
    "\n",
    "    length1 = len(cd1)\n",
    "    for k in range(length1):\n",
    "        if (abs(cd1[k]) >= lamda/np.log2(2)):\n",
    "            cd1[k] = sgn(cd1[k]) * (abs(cd1[k]) - lamda/np.log2(2))\n",
    "        else:\n",
    "            cd1[k] = 0.0\n",
    "    \n",
    "    length2 = len(cd2)\n",
    "    for k in range(length2):\n",
    "        if (abs(cd2[k]) >= lamda/np.log2(3)):\n",
    "            cd2[k] = sgn(cd2[k]) * (abs(cd2[k]) - lamda/np.log2(3))\n",
    "        else:\n",
    "            cd2[k] = 0.0\n",
    "\n",
    "    length3 = len(cd3)\n",
    "    for k in range(length3):\n",
    "        if (abs(cd3[k]) >= lamda/np.log2(4)):\n",
    "            cd3[k] = sgn(cd3[k]) * (abs(cd3[k]) - lamda/np.log2(4))\n",
    "        else:\n",
    "            cd3[k] = 0.0\n",
    "    \n",
    "    \n",
    "    usecoeffs.append(cd3)\n",
    "    usecoeffs.append(cd2)\n",
    "    usecoeffs.append(cd1)\n",
    "    result = pywt.waverec(usecoeffs, wavelet, mode=\"per\") #信号重构\n",
    "    \n",
    "    if len(x)%2==1:\n",
    "        result = result[:-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.395030Z",
     "iopub.status.busy": "2023-06-09T08:49:10.394068Z",
     "iopub.status.idle": "2023-06-09T08:49:10.412443Z",
     "shell.execute_reply": "2023-06-09T08:49:10.411101Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.395000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "BASE_DIR = \"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
    "\n",
    "IS_PUBLIC = len(glob.glob(os.path.join(TEST_DIR, \"*/*.csv\")))==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.414933Z",
     "iopub.status.busy": "2023-06-09T08:49:10.413843Z",
     "iopub.status.idle": "2023-06-09T08:49:10.423516Z",
     "shell.execute_reply": "2023-06-09T08:49:10.422397Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.414891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS_PUBLIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.425440Z",
     "iopub.status.busy": "2023-06-09T08:49:10.425099Z",
     "iopub.status.idle": "2023-06-09T08:49:10.436140Z",
     "shell.execute_reply": "2023-06-09T08:49:10.435083Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.425403Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_sub_dirs = [os.path.join(TRAIN_DIR, \"defog\"),\n",
    "                      os.path.join(TRAIN_DIR, \"tdcsfog\")\n",
    "                     ]\n",
    "    \n",
    "    metadata_paths = [os.path.join(BASE_DIR, \"defog_metadata.csv\"),\n",
    "                      os.path.join(BASE_DIR, \"tdcsfog_metadata.csv\")\n",
    "                     ]\n",
    "    \n",
    "    splits = 5\n",
    "    batch_size = 1024\n",
    "    \n",
    "    defog_window_size = 200\n",
    "    defog_window_future = 50\n",
    "    defog_window_past = defog_window_size - defog_window_future\n",
    "    tdcsfog_window_size = 256\n",
    "    tdcsfog_window_future = 64\n",
    "    tdcsfog_window_past = tdcsfog_window_size - tdcsfog_window_future\n",
    "    \n",
    "    wx = 3\n",
    "    \n",
    "    model_dropout = 0.2\n",
    "    model_hidden = 128\n",
    "    model_nblocks = 2\n",
    "    \n",
    "    lr = 0.0002\n",
    "    num_epochs = 5\n",
    "    \n",
    "    feature_list = ['Time_frac', 'AccV', 'AccML', 'AccAP', 'V_ML', 'V_AP', 'ML_AP']\n",
    "    label_list = ['StartHesitation', 'Turn', 'Walking', 'Normal']\n",
    "    \n",
    "    n_features = len(feature_list)\n",
    "    n_labels = len(label_list)    \n",
    "    \n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.438318Z",
     "iopub.status.busy": "2023-06-09T08:49:10.437648Z",
     "iopub.status.idle": "2023-06-09T08:49:10.466318Z",
     "shell.execute_reply": "2023-06-09T08:49:10.465131Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.438279Z"
    }
   },
   "outputs": [],
   "source": [
    "class FOGSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df_paths, module, cfg=cfg, split=\"train\"):\n",
    "        \n",
    "        _time = perf_counter()\n",
    "        \n",
    "        self.rng = default_rng(42)\n",
    "        self.cfg = cfg\n",
    "        self.split = split\n",
    "        self.module = module\n",
    "        \n",
    "        if self.module=='defog':\n",
    "            self.past_pad = self.cfg.wx * (self.cfg.defog_window_past-1)\n",
    "            self.future_pad = self.cfg.wx * self.cfg.defog_window_future\n",
    "        else:\n",
    "            self.past_pad = self.cfg.wx * (self.cfg.tdcsfog_window_past-1)\n",
    "            self.future_pad = self.cfg.wx * self.cfg.tdcsfog_window_future\n",
    "        \n",
    "        \n",
    "        if self.split == \"test\":\n",
    "            self.Ids = []\n",
    "            self.Time_frac = []\n",
    "            \n",
    "        _values = [self._read(f) for f in df_paths]\n",
    "        \n",
    "        self.mapping = []\n",
    "        _length = 0\n",
    "        for _value in _values:\n",
    "            _shape = _value.shape[0]\n",
    "            self.mapping.extend(range(_length+self.past_pad, _length+_shape-self.future_pad))\n",
    "            _length += _shape\n",
    "            \n",
    "        self.values = np.concatenate(_values, axis=0)\n",
    "        self.mapping = np.array(self.mapping)\n",
    "        if self.split != \"test\":\n",
    "            # Keep only vaild and task rows\n",
    "            _valid_pos = self.values[self.mapping, self.valid_position] > 0\n",
    "            _task_pos = self.values[self.mapping, self.task_position] > 0\n",
    "            self.mapping = self.mapping[_valid_pos&_task_pos]\n",
    "        self.length = self.mapping.shape[0]\n",
    "        \n",
    "        if split==\"train\":\n",
    "            print(f\"Train Dataset of size {self.length:,} initialized in {perf_counter() - _time:.3f} secs!\")\n",
    "            \n",
    "        if split==\"valid\":\n",
    "            print(f\"Valid Dataset of size {self.length:,} initialized in {perf_counter() - _time:.3f} secs!\") \n",
    "        gc.collect()\n",
    "\n",
    "    \n",
    "    \n",
    "    def _read(self, path):\n",
    "        _is_tdcs = os.path.basename(os.path.dirname(path)).startswith('tdcs')\n",
    "        df = pd.read_csv(path)\n",
    "        #########\n",
    "        df['Time_frac'] = (df.index/df.index.max()).values\n",
    "        \n",
    "        if self.split == \"test\":\n",
    "            _ids = basename(path).split('.')[0] + '_' + df.Time.astype(str)\n",
    "            self.Ids.extend(_ids.tolist())\n",
    "            self.Time_frac.extend(df.Time_frac.tolist())\n",
    "            return self._df_to_array(df, self.cfg.feature_list)\n",
    "        \n",
    "        _cols = [*self.cfg.feature_list, *self.cfg.label_list, 'Valid', 'Task']\n",
    "        self.valid_position = self.cfg.n_features + self.cfg.n_labels\n",
    "        self.task_position = self.valid_position + 1\n",
    "        \n",
    "        if _is_tdcs:\n",
    "            # Fill Valid and Task columns for tdcsfog\n",
    "            df['Valid'] = 1\n",
    "            df['Task'] = 1\n",
    "            \n",
    "        return self._df_to_array(df, _cols)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _df_to_array(self, df, cols):\n",
    "        # Pads past and future rows to dataframe values for indexing\n",
    "        df['AccV'] = wavelet_denoising_2(df['AccV'], wavelet='db4')\n",
    "        df['AccML'] = wavelet_denoising_2(df['AccML'], wavelet='db4')\n",
    "        df['AccAP'] = wavelet_denoising_2(df['AccAP'], wavelet='db4')\n",
    "        df['V_ML'] = df['AccV'] - df['AccML']\n",
    "        df['V_AP'] = df['AccV'] - df['AccAP']\n",
    "        df['ML_AP'] = df['AccML'] - df['AccAP']\n",
    "        \n",
    "        df['AccV'] = (df['AccV'] - df['AccV'].mean()) / df['AccV'].std()\n",
    "        df['AccML'] = (df['AccML'] - df['AccML'].mean()) / df['AccML'].std()\n",
    "        df['AccAP'] = (df['AccAP'] - df['AccAP'].mean()) / df['AccAP'].std()\n",
    "        df['V_ML'] = (df['V_ML'] - df['V_ML'].mean()) / df['V_ML'].std()\n",
    "        df['V_AP'] = (df['V_AP'] - df['V_AP'].mean()) / df['V_AP'].std()\n",
    "        df['ML_AP'] = (df['ML_AP'] - df['ML_AP'].mean()) / df['ML_AP'].std()\n",
    "        \n",
    "        _values = df[cols].values.astype(np.float32)  # np.float32\n",
    "        \n",
    "        return np.pad(_values, ((self.past_pad, self.future_pad),(0,0)), 'edge')\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return int(np.ceil(self.length / self.cfg.batch_size))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.split == \"train\":\n",
    "            # Onlt train set has randomly selected batches\n",
    "            _idxs = self.rng.choice(self.mapping, size=self.cfg.batch_size, replace=False)\n",
    "        else:\n",
    "            _idxs = self._get_indices(idx)\n",
    "            \n",
    "        # For test return only features\n",
    "        if self.split == \"test\":\n",
    "            return self._get_X(_idxs)\n",
    "        # For train and val splits return y also\n",
    "        \n",
    "        return self._get_X_y(_idxs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _get_indices(self, idx):\n",
    "        _low = idx * self.cfg.batch_size\n",
    "        # Cap high at self.length so overflow does not occur\n",
    "        _high = min(_low + self.cfg.batch_size, self.length)\n",
    "        \n",
    "        return self.mapping[_low:_high]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _get_X(self, indices):\n",
    "        if self.module=='defog':\n",
    "            _X = np.empty((len(indices), self.cfg.defog_window_size, self.cfg.n_features), dtype=np.float32)\n",
    "        else:\n",
    "            _X = np.empty((len(indices), self.cfg.tdcsfog_window_size, self.cfg.n_features), dtype=np.float32)\n",
    "        for i, idx in enumerate(indices):\n",
    "            _X[i] = self.values[idx-self.past_pad:idx+self.future_pad+1:self.cfg.wx, :self.cfg.n_features]\n",
    "            \n",
    "        return _X\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _get_X_y(self, indices):\n",
    "        if self.module=='defog':\n",
    "            _X = np.empty((len(indices), self.cfg.defog_window_size, self.cfg.n_features), dtype=np.float32)\n",
    "        else:\n",
    "            _X = np.empty((len(indices), self.cfg.tdcsfog_window_size, self.cfg.n_features), dtype=np.float32)\n",
    "        for i, idx in enumerate(indices):\n",
    "            _X[i] = self.values[idx-self.past_pad: idx+self.future_pad+1:self.cfg.wx, :self.cfg.n_features]\n",
    "            \n",
    "        return _X, self.values[indices, self.cfg.n_features:self.cfg.n_features+self.cfg.n_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_model(module, checkpoint_path = None):\n",
    "    if module=='defog':\n",
    "        window_size = cfg.defog_window_size\n",
    "    else:\n",
    "        window_size = cfg.tdcsfog_window_size\n",
    "        \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(window_size, cfg.n_features), dtype='float32'))\n",
    "    for i in range(cfg.model_nblocks):\n",
    "        model.add(tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=i+1, kernel_size=16-6*i, padding=\"same\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "        model.add(tf.keras.layers.Dropout(cfg.model_dropout))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "    model.add(tf.keras.layers.Dense(cfg.n_labels, activation='sigmoid'))\n",
    "    \n",
    "    if checkpoint_path is not None:\n",
    "        model.load_weights(checkpoint_path)\n",
    "    \n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=cfg.lr), \n",
    "                  loss = tf.keras.losses.BinaryCrossentropy()\n",
    "                 )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "get_model('defog').summary()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.469963Z",
     "iopub.status.busy": "2023-06-09T08:49:10.469521Z",
     "iopub.status.idle": "2023-06-09T08:49:10.483061Z",
     "shell.execute_reply": "2023-06-09T08:49:10.482137Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.469922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model adapted from https://keras.io/examples/timeseries/timeseries_classification_from_scratch/\n",
    "\n",
    "def get_model(module, checkpoint_path = None):\n",
    "    if module == 'defog':\n",
    "        window_size = cfg.defog_window_size\n",
    "    else:\n",
    "        window_size = cfg.tdcsfog_window_size\n",
    "    \n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(window_size, cfg.n_features), dtype='float32')\n",
    "    \n",
    "    \n",
    "    left = tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=1, kernel_size=4, padding=\"same\", \n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n",
    "    left = tf.keras.layers.BatchNormalization()(left)\n",
    "    \n",
    "    \n",
    "    right = tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=3, kernel_size=8, padding=\"same\", \n",
    "                                   kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n",
    "    right = tf.keras.layers.BatchNormalization()(right)\n",
    "    \n",
    "    \n",
    "    mid = tf.keras.layers.Conv1D(filters=cfg.model_hidden, strides=5, kernel_size=16, padding=\"same\", \n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n",
    "    mid = tf.keras.layers.BatchNormalization()(mid)\n",
    "    \n",
    "    \n",
    "    conb = tf.keras.layers.Concatenate(axis=1)([left, mid, right])\n",
    "    conb = tf.keras.layers.ReLU()(conb)\n",
    "    #conb = tf.keras.layers.GlobalAveragePooling1D()(conb)\n",
    "    conb = tf.keras.layers.Flatten()(conb)\n",
    "    conb = tf.keras.layers.Dropout(0.2)(conb)\n",
    "    outputs = tf.keras.layers.Dense(cfg.n_labels, activation='sigmoid')(conb)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    if checkpoint_path is not None:\n",
    "        model.load_weights(checkpoint_path)\n",
    "        \n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=cfg.lr), \n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:49:10.484905Z",
     "iopub.status.busy": "2023-06-09T08:49:10.484052Z",
     "iopub.status.idle": "2023-06-09T08:49:10.756558Z",
     "shell.execute_reply": "2023-06-09T08:49:10.751966Z",
     "shell.execute_reply.started": "2023-06-09T08:49:10.484875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 7)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 200, 128)     3712        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 40, 128)      14464       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 67, 128)      7296        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 200, 128)    512         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 40, 128)     512         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 67, 128)     512         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 307, 128)     0           ['batch_normalization[0][0]',    \n",
      "                                                                  'batch_normalization_2[0][0]',  \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 307, 128)     0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 39296)        0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 39296)        0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            157188      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 184,196\n",
      "Trainable params: 183,428\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_model('defog').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T08:02:49.585763Z",
     "iopub.status.busy": "2023-06-09T08:02:49.584401Z",
     "iopub.status.idle": "2023-06-09T08:02:49.590520Z",
     "shell.execute_reply": "2023-06-09T08:02:49.589405Z",
     "shell.execute_reply.started": "2023-06-09T08:02:49.585697Z"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "The author used `StratifiedGroupKFold(y=labels, group=Subject)`. CV is around 0.32-0.34.\n",
    "\n",
    "\n",
    "## conv1d model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defog_ver23/\n",
    "#    fold0_model_04.h5,  fold1_model_03.h5,  fold2_model_05.h5,  fold3_model_05.h5,  fold4_model_03.h5\n",
    "# tdcsfog_ver23/\n",
    "#    fold0_model_01.h5,  fold1_model_02.h5,  fold2_model_05.h5,  fold3_model_05.h5,  fold4_model_05.h5\n",
    "\n",
    "\n",
    "model_paths = {'defog': [f for f in glob.glob(\"/kaggle/input/gait-cov1d-models/defog_ver23/*.h5\")],\n",
    "               'tdcsfog': [f for f in glob.glob(\"/kaggle/input/gait-cov1d-models/tdcsfog_ver23/*.h5\")],\n",
    "              }\n",
    "display(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_defog_paths = glob.glob(join(TEST_DIR, \"defog/*.csv\"))\n",
    "test_tdcsfog_paths = glob.glob(join(TEST_DIR, \"tdcsfog/*.csv\"))\n",
    "\n",
    "test_ds_dict = {'defog': FOGSequence(test_defog_paths, module='defog', split=\"test\"), \n",
    "                'tdcsfog': FOGSequence(test_tdcsfog_paths, module='tdcsfog', split=\"test\")\n",
    "               }\n",
    "\n",
    "# Get test predictions\n",
    "df_list = []\n",
    "for module, test_ds in test_ds_dict.items():\n",
    "    y_pred_list = []\n",
    "    for model_path in tqdm(model_paths[module]):\n",
    "        model = get_model(module, model_path)\n",
    "        y_pred_list.append(model.predict(test_ds, verbose=0, batch_size=256))\n",
    "        \n",
    "    y_pred = np.mean(y_pred_list, axis=0)\n",
    "    df_list.append(pd.DataFrame({'Id': test_ds.Ids, \n",
    "                                 'module': [module]*len(y_pred), \n",
    "                                 'Time_frac': test_ds.Time_frac, \n",
    "                                 'StartHesitation': y_pred[:,0], \n",
    "                                 'Turn': y_pred[:,1], \n",
    "                                 'Walking': y_pred[:,2]}\n",
    "                               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Prediction to DataFrames\n",
    "submission = pd.concat(df_list)\n",
    "\n",
    "#submission.loc[((submission.Time_frac<0.01)|(submission.Time_frac>0.99))&(submission.module=='tdcsfog'), 'Walking'] = 0\n",
    "#submission.loc[(submission.Time_frac<0.01)&(submission.module=='tdcsfog'), 'Turn'] = 0\n",
    "#submission.loc[(submission.Time_frac<0.01)&(submission.module=='defog'), 'Turn'] = 0\n",
    "\n",
    "# Only keep Ids in sample_submission\n",
    "sample_submission = pd.read_csv(join(BASE_DIR, \"sample_submission.csv\"))\n",
    "submission = pd.merge(sample_submission[['Id']], submission, how='left', on='Id').fillna(0.0)\n",
    "submission[['Id','StartHesitation','Turn','Walking']].to_csv(\"submission.csv\", index=False, float_format='%.5f') # round to 5 decimal places while keeping point notation\n",
    "\n",
    "display(submission.head())\n",
    "display(submission.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_ds_dict\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
