{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThis notebook is copied from <a href=\"https://www.kaggle.com/code/larsmadsen/tf-keras-inception-resnet-v2-97-acc\" style=\"text-decoration:none\">LMADSEN</a>. And I made a few modifications according to the prompts in the referenced notebook and my coding style. I also rearranged the code layout for my personal coding taste. \n\nThanks **LMADSEN** for sharing his/her excellent work so that I had this opportunity to know the Inception-ResNet model and to learn how to implement it using tf.keras.","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:05.789924Z","iopub.execute_input":"2023-04-29T08:52:05.790323Z","iopub.status.idle":"2023-04-29T08:52:07.724823Z","shell.execute_reply.started":"2023-04-29T08:52:05.790238Z","shell.execute_reply":"2023-04-29T08:52:07.723797Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Check the version of tensorflow and make sure that the GPU is available\nprint(tf.__version__)\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n\n# tf.config.experimental.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:07.726782Z","iopub.execute_input":"2023-04-29T08:52:07.727123Z","iopub.status.idle":"2023-04-29T08:52:07.770490Z","shell.execute_reply.started":"2023-04-29T08:52:07.727094Z","shell.execute_reply":"2023-04-29T08:52:07.769374Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.4.1\nNum GPUs Available:  1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<br>\n\n# Define Some Constants.\n\nThese are number of epochs to train, images per batch, image width and height in pixels and the names of each class/species for the submission file","metadata":{}},{"cell_type":"code","source":"nb_epoch     = 40\nbatch_size   = 16\nwidth        = 299\nheight       = 299\nspecies_list = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \n                \"Common wheat\", \"Fat Hen\", \"Loose Silky-bent\", \"Maize\", \n                \"Scentless Mayweed\", \"Shepherds Purse\", \n                \"Small-flowered Cranesbill\", \"Sugar beet\"]","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:07.772153Z","iopub.execute_input":"2023-04-29T08:52:07.772842Z","iopub.status.idle":"2023-04-29T08:52:07.778857Z","shell.execute_reply.started":"2023-04-29T08:52:07.772799Z","shell.execute_reply":"2023-04-29T08:52:07.777855Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n# Define the Model\n\nDefine the neural network. We use the build-in module for Inception-ResNet V2 in tf.keras.\n\nWe don't import the output layer, however as we don't have 1000 different categories. Instead we add a few layers for our 12 catagories.","metadata":{}},{"cell_type":"code","source":"def define_model(width, height):\n    model_input = tf.keras.layers.Input(shape=(width, height, 3), name='image_input')\n    model_main = tf.keras.applications.inception_resnet_v2\\\n                                      .InceptionResNetV2(include_top=False,\n                                                         weights='imagenet')(model_input)\n    model_dense1 = tf.keras.layers.Flatten()(model_main)\n    model_dense2 = tf.keras.layers.Dense(128, activation='relu')(model_dense1)\n    model_out = tf.keras.layers.Dense(12, activation=\"softmax\")(model_dense2)\n\n    model = tf.keras.models.Model(model_input,  model_out)\n    \n    optimizer = tf.keras.optimizers.Adam(lr=0.00004, beta_1=0.9, beta_2=0.999)\n    model.compile(loss=\"categorical_crossentropy\", \n                  optimizer=optimizer,\n                  metrics=[\"accuracy\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:07.780481Z","iopub.execute_input":"2023-04-29T08:52:07.781136Z","iopub.status.idle":"2023-04-29T08:52:07.789678Z","shell.execute_reply.started":"2023-04-29T08:52:07.781098Z","shell.execute_reply":"2023-04-29T08:52:07.788842Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n# Define Data Generator\n\nNext, the code for the data generators that take care of traversing through the directories with images and augmenting the images as needed for training.","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/plant-seedlings-classification/\"","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:07.792202Z","iopub.execute_input":"2023-04-29T08:52:07.792936Z","iopub.status.idle":"2023-04-29T08:52:07.799249Z","shell.execute_reply.started":"2023-04-29T08:52:07.792869Z","shell.execute_reply":"2023-04-29T08:52:07.798560Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def define_generators():\n    train_datagen = tf.keras.preprocessing\\\n                      .image.ImageDataGenerator(\n                                rotation_range=360,\n                                width_shift_range=0.3,\n                                height_shift_range=0.3,\n                                shear_range=0.3,\n                                zoom_range=0.5,\n                                vertical_flip=True,\n                                horizontal_flip=True,\n                                \n                                validation_split=0.2,\n                                # validation_split=0.0,\n                                # change to use validation instead of training on entire training set\n                                )\n\n    train_generator = train_datagen.flow_from_directory(\n                                        # directory='/kaggle/input/plant-seedlings-classification/train',\n                                        directory=data_dir + \"train\",\n                                        target_size=(width, height),\n                                        batch_size=batch_size,\n                                        color_mode='rgb',\n                                        class_mode=\"categorical\",\n                                        subset='training',\n                                        )\n\n    \n    validation_generator = train_datagen.flow_from_directory(\n                                           # directory='/kaggle/input/plant-seedlings-classification/train',\n                                           directory=data_dir + \"train\",\n                                           target_size=(width, height),\n                                           batch_size=batch_size,\n                                           color_mode='rgb',\n                                           class_mode=\"categorical\",\n                                           subset='validation',\n                                           )\n\n    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n\n    test_generator = test_datagen.flow_from_directory(\n                                         # directory='/kaggle/input/plant-seedlings-classification/',\n                                         directory=data_dir,\n                                         classes=['test'],\n                                         target_size=(width, height),\n                                         batch_size=1,\n                                         color_mode='rgb',\n                                         shuffle=False,\n                                         class_mode='categorical')\n\n    return train_generator, validation_generator, test_generator","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:07.801010Z","iopub.execute_input":"2023-04-29T08:52:07.801695Z","iopub.status.idle":"2023-04-29T08:52:07.810483Z","shell.execute_reply.started":"2023-04-29T08:52:07.801656Z","shell.execute_reply":"2023-04-29T08:52:07.809872Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n# Define the Checkpoint\n\nDefine the checkpoint save callback on validation accuracy.\n\nIt is not currently used, but you can if you want to work on the model with the highest accuracy instead of the last training epoch.","metadata":{}},{"cell_type":"code","source":"def define_callbacks():\n    save_callback = tf.keras.callbacks.ModelCheckpoint(filepath='model.h5',\n                                                       monitor='val_acc',\n                                                       save_best_only=True,\n                                                       verbose=1\n                                                      )\n\n    return save_callback","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:07.813648Z","iopub.execute_input":"2023-04-29T08:52:07.814151Z","iopub.status.idle":"2023-04-29T08:52:07.824659Z","shell.execute_reply.started":"2023-04-29T08:52:07.814120Z","shell.execute_reply":"2023-04-29T08:52:07.823390Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<br>\n\n# Train the Model\n\nNow, define the model and fit it with the training data.","metadata":{}},{"cell_type":"code","source":"model = define_model(width, height)\nmodel.summary()\n\ntrain_generator, validation_generator, test_generator = define_generators()\n\n\nsave_callback = define_callbacks()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:07.827154Z","iopub.execute_input":"2023-04-29T08:52:07.828073Z","iopub.status.idle":"2023-04-29T08:52:19.432631Z","shell.execute_reply.started":"2023-04-29T08:52:07.827992Z","shell.execute_reply":"2023-04-29T08:52:19.431460Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n219062272/219055592 [==============================] - 1s 0us/step\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nimage_input (InputLayer)     [(None, 299, 299, 3)]     0         \n_________________________________________________________________\ninception_resnet_v2 (Functio (None, None, None, 1536)  54336736  \n_________________________________________________________________\nflatten (Flatten)            (None, 98304)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               12583040  \n_________________________________________________________________\ndense_1 (Dense)              (None, 12)                1548      \n=================================================================\nTotal params: 66,921,324\nTrainable params: 66,860,780\nNon-trainable params: 60,544\n_________________________________________________________________\nFound 3803 images belonging to 12 classes.\nFound 947 images belonging to 12 classes.\nFound 794 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(train_generator,\n          epochs=nb_epoch,\n          steps_per_epoch=train_generator.samples // batch_size,\n          validation_data= validation_generator,\n          validation_steps=validation_generator.samples // batch_size,\n          callbacks=[save_callback]  # UNCOMMENT THIS LINE TO SAVE BEST VAL_ACC MODEL\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T08:52:19.434014Z","iopub.execute_input":"2023-04-29T08:52:19.434379Z","iopub.status.idle":"2023-04-29T10:47:01.502235Z","shell.execute_reply.started":"2023-04-29T08:52:19.434331Z","shell.execute_reply":"2023-04-29T10:47:01.501176Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/40\n237/237 [==============================] - 267s 1s/step - loss: 2.0377 - accuracy: 0.3275 - val_loss: 0.8539 - val_accuracy: 0.7489\nEpoch 2/40\n237/237 [==============================] - 181s 764ms/step - loss: 0.6304 - accuracy: 0.7770 - val_loss: 0.9059 - val_accuracy: 0.8422\nEpoch 3/40\n237/237 [==============================] - 175s 737ms/step - loss: 0.4396 - accuracy: 0.8494 - val_loss: 0.5371 - val_accuracy: 0.8729\nEpoch 4/40\n237/237 [==============================] - 173s 728ms/step - loss: 0.3578 - accuracy: 0.8859 - val_loss: 0.5418 - val_accuracy: 0.8676\nEpoch 5/40\n237/237 [==============================] - 172s 726ms/step - loss: 0.2583 - accuracy: 0.9093 - val_loss: 0.4764 - val_accuracy: 0.9057\nEpoch 6/40\n237/237 [==============================] - 175s 737ms/step - loss: 0.2127 - accuracy: 0.9211 - val_loss: 0.2922 - val_accuracy: 0.9258\nEpoch 7/40\n237/237 [==============================] - 173s 729ms/step - loss: 0.2054 - accuracy: 0.9297 - val_loss: 0.3766 - val_accuracy: 0.9174\nEpoch 8/40\n237/237 [==============================] - 172s 727ms/step - loss: 0.1939 - accuracy: 0.9346 - val_loss: 0.3550 - val_accuracy: 0.9280\nEpoch 9/40\n237/237 [==============================] - 170s 719ms/step - loss: 0.1809 - accuracy: 0.9386 - val_loss: 0.5161 - val_accuracy: 0.9174\nEpoch 10/40\n237/237 [==============================] - 168s 707ms/step - loss: 0.1233 - accuracy: 0.9570 - val_loss: 0.5155 - val_accuracy: 0.9184\nEpoch 11/40\n237/237 [==============================] - 170s 715ms/step - loss: 0.1437 - accuracy: 0.9506 - val_loss: 0.2900 - val_accuracy: 0.9386\nEpoch 12/40\n237/237 [==============================] - 175s 740ms/step - loss: 0.1353 - accuracy: 0.9517 - val_loss: 0.2412 - val_accuracy: 0.9386\nEpoch 13/40\n237/237 [==============================] - 176s 740ms/step - loss: 0.1508 - accuracy: 0.9441 - val_loss: 0.3236 - val_accuracy: 0.9364\nEpoch 14/40\n237/237 [==============================] - 171s 723ms/step - loss: 0.1184 - accuracy: 0.9617 - val_loss: 0.4598 - val_accuracy: 0.9333\nEpoch 15/40\n237/237 [==============================] - 169s 710ms/step - loss: 0.1091 - accuracy: 0.9635 - val_loss: 0.2988 - val_accuracy: 0.9470\nEpoch 16/40\n237/237 [==============================] - 167s 704ms/step - loss: 0.1361 - accuracy: 0.9547 - val_loss: 0.2032 - val_accuracy: 0.9576\nEpoch 17/40\n237/237 [==============================] - 167s 703ms/step - loss: 0.1028 - accuracy: 0.9612 - val_loss: 0.1924 - val_accuracy: 0.9502\nEpoch 18/40\n237/237 [==============================] - 170s 717ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.1802 - val_accuracy: 0.9523\nEpoch 19/40\n237/237 [==============================] - 167s 704ms/step - loss: 0.1136 - accuracy: 0.9576 - val_loss: 0.2409 - val_accuracy: 0.9439\nEpoch 20/40\n237/237 [==============================] - 167s 705ms/step - loss: 0.0951 - accuracy: 0.9650 - val_loss: 0.1488 - val_accuracy: 0.9587\nEpoch 21/40\n237/237 [==============================] - 168s 710ms/step - loss: 0.0757 - accuracy: 0.9758 - val_loss: 0.3228 - val_accuracy: 0.9386\nEpoch 22/40\n237/237 [==============================] - 167s 705ms/step - loss: 0.1241 - accuracy: 0.9599 - val_loss: 0.3650 - val_accuracy: 0.9195\nEpoch 23/40\n237/237 [==============================] - 167s 706ms/step - loss: 0.1064 - accuracy: 0.9675 - val_loss: 0.2473 - val_accuracy: 0.9534\nEpoch 24/40\n237/237 [==============================] - 169s 712ms/step - loss: 0.1327 - accuracy: 0.9539 - val_loss: 0.2650 - val_accuracy: 0.9364\nEpoch 25/40\n237/237 [==============================] - 167s 703ms/step - loss: 0.0938 - accuracy: 0.9683 - val_loss: 0.1674 - val_accuracy: 0.9640\nEpoch 26/40\n237/237 [==============================] - 167s 705ms/step - loss: 0.0835 - accuracy: 0.9699 - val_loss: 0.1907 - val_accuracy: 0.9439\nEpoch 27/40\n237/237 [==============================] - 168s 709ms/step - loss: 0.0779 - accuracy: 0.9716 - val_loss: 0.1663 - val_accuracy: 0.9597\nEpoch 28/40\n237/237 [==============================] - 168s 709ms/step - loss: 0.0762 - accuracy: 0.9734 - val_loss: 0.2670 - val_accuracy: 0.9492\nEpoch 29/40\n237/237 [==============================] - 168s 709ms/step - loss: 0.0739 - accuracy: 0.9729 - val_loss: 0.2409 - val_accuracy: 0.9502\nEpoch 30/40\n237/237 [==============================] - 168s 709ms/step - loss: 0.0723 - accuracy: 0.9799 - val_loss: 0.2976 - val_accuracy: 0.9439\nEpoch 31/40\n237/237 [==============================] - 168s 709ms/step - loss: 0.0902 - accuracy: 0.9689 - val_loss: 0.1841 - val_accuracy: 0.9597\nEpoch 32/40\n237/237 [==============================] - 167s 705ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 0.2928 - val_accuracy: 0.9534\nEpoch 33/40\n237/237 [==============================] - 167s 706ms/step - loss: 0.0703 - accuracy: 0.9797 - val_loss: 0.2783 - val_accuracy: 0.9502\nEpoch 34/40\n237/237 [==============================] - 169s 710ms/step - loss: 0.0825 - accuracy: 0.9727 - val_loss: 0.3424 - val_accuracy: 0.9502\nEpoch 35/40\n237/237 [==============================] - 167s 705ms/step - loss: 0.0757 - accuracy: 0.9745 - val_loss: 0.2571 - val_accuracy: 0.9566\nEpoch 36/40\n237/237 [==============================] - 167s 706ms/step - loss: 0.0833 - accuracy: 0.9729 - val_loss: 0.2103 - val_accuracy: 0.9619\nEpoch 37/40\n237/237 [==============================] - 170s 716ms/step - loss: 0.0708 - accuracy: 0.9798 - val_loss: 0.2909 - val_accuracy: 0.9608\nEpoch 38/40\n237/237 [==============================] - 168s 709ms/step - loss: 0.0561 - accuracy: 0.9814 - val_loss: 0.3231 - val_accuracy: 0.9523\nEpoch 39/40\n237/237 [==============================] - 167s 704ms/step - loss: 0.0615 - accuracy: 0.9767 - val_loss: 0.1690 - val_accuracy: 0.9661\nEpoch 40/40\n237/237 [==============================] - 168s 711ms/step - loss: 0.0698 - accuracy: 0.9746 - val_loss: 0.2279 - val_accuracy: 0.9555\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x73aa96f382d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"<br>\n\n# Predict and Submission\n\nCool, now we (hopefully) have a model that can predict the species!\n\nCall it to get the predictions, and create a pandas dataframe with the species names of the highest probabilities. finally save the dataframe as the submission file.","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_generator, steps=test_generator.samples)\n\nclass_list = []\n\nfor i in range(0, predictions.shape[0]):\n    y_class = predictions[i, :].argmax(axis=-1)\n    class_list += [species_list[y_class]]\n\nsubmission = pd.DataFrame()\nsubmission['file'] = test_generator.filenames\nsubmission['file'] = submission['file'].str.replace(r'test\\\\', '')\nsubmission['species'] = class_list\n\nsubmission.to_csv('./Inception-ResNet.csv', index=False)\n\nprint('Submission file generated. All done.')","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:48:06.747166Z","iopub.execute_input":"2023-04-29T10:48:06.747543Z","iopub.status.idle":"2023-04-29T10:48:29.567493Z","shell.execute_reply.started":"2023-04-29T10:48:06.747508Z","shell.execute_reply":"2023-04-29T10:48:29.566461Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Submission file generated. All done.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}